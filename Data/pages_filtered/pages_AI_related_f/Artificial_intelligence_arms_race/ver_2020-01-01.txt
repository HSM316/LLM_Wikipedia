An artificial intelligence arms race is a competition between two or more states to have its military forces equipped with the best "artificial intelligence" (AI). Since the mid-2010s, many analysts have argued that such a global arms race for better artificial intelligence has already begun.

 Stances toward military artificial intelligence 
 Russia 
alt=A cartoon centipede reads books and types on a laptop.|Putin (seated, center) at National Knowledge Day, 2017
Russian General Viktor Bondarev, commander-in-chief of the Russian air force, has stated that as early as February 2017, Russia has been working on AI-guided missiles that can decide to switch targets mid-flight. Reports by state-sponsored Russian media on potential military uses of AI increased in mid-2017. In May 2017, the CEO of Russia's Kronstadt Group, a defense contractor, stated that "there already exist completely autonomous AI operation systems that provide the means for UAV clusters, when they fulfill missions autonomously, sharing tasks between them, and interact", and that it is inevitable that "swarms of drones" will one day fly over combat zones. Russia has been testing several autonomous and semi-autonomous combat systems, such as Kalashnikov's "neural net" combat module, with a machine gun, a camera, and an AI that its makers claim can make its own targeting judgements without human intervention. In September 2017, during a National Knowledge Day address to over a million students in 16,000 Russian schools, Russian President Vladimir Putin stated "Artificial intelligence is the future, not only for Russia but for all humankind... Whoever becomes the leader in this sphere will become the ruler of the world".

The Russian government has strongly rejected any ban on lethal autonomous weapons systems, suggesting that such a ban could be ignored.

 China 

According to a February 2019 report by Gregory C. Allen of the Center for a New American Security, "China’s leadership – including President Xi Jinping – believes that being at the forefront in AI technology is critical to the future of global military and economic power competition." Chinese military officials have said that their goal is to incorporate commercial AI technology to "narrow the gap between the Chinese military and global advanced powers." The close ties between Silicon Valley and China, and the open nature of the American research community, has made the West's most advanced AI technology easily available to China; in addition, Chinese industry has numerous home-grown AI accomplishments of its own, such as Baidu passing a notable Chinese-language speech recognition capability benchmark in 2015. As of 2017, Beijing's roadmap aims to create a $150 billion AI industry by 2030. Before 2013, Chinese defense procurement was mainly restricted to a few conglomerates; however, as of 2017, China often sources sensitive emerging technology such as drones and artificial intelligence from private start-up companies. One Chinese state has pledged to invest $5 billion in AI. Beijing has committed $2 billion to an AI development park. The Japan Times reported in 2018 that annual private Chinese investment in AI is under $7 billion per year. AI startups in China received nearly half of total global investment in AI startups in 2017; the Chinese filed for nearly five times as many AI patents as did Americans.

China published a position paper in 2016 questioning the adequacy of existing international law to address the eventuality of fully autonomous weapons, becoming the first permanent member of the U.N. Security Council to broach the issue. In 2018, Xi called for greater international cooperation in basic AI research. Chinese officials have expressed concern that AI such as drones could lead to accidental war, especially in the absence of international norms. In 2019, US Defense Secretary Mark Esper lashes out at China for selling drones capable of taking life with no human oversight.

 United States 
alt=The Sea Hunter sails out to sea|The Sea Hunter, an autonomous US warship, 2016
In 2014, former Secretary of Defense Chuck Hagel posited the "Third Offset Strategy" that rapid advances in artificial intelligence will define the next generation of warfare. According to data science and analytics firm Govini, The U.S. Department of Defense increased investment in artificial intelligence, big data and cloud computing from $5.6 billion in 2011 to $7.4 billion in 2016. However, the civilian NSF budget for AI saw no increase in 2017.

The U.S. has many military AI combat programs, such as the Sea Hunter autonomous warship, which is designed to operate for extended periods at sea without a single crew member, and to even guide itself in and out of port. As of 2017, a temporary US Department of Defense directive requires a human operator to be kept in the loop when it comes to the taking of human life by autonomous weapons systems. Japan Times reported in 2018 that the United States private investment is around $70 billion per year.

 United Kingdom 
In 2015, the UK government opposed a ban on lethal autonomous weapons, stating that "international humanitarian law already provides sufficient regulation for this area", but that all weapons employed by UK armed forces would be "under human oversight and control".

 Israel 
Israel's Harpy anti-radar "fire and forget" drone is designed to be launched by ground troops, and autonomously fly over an area to find and destroy radar that fits pre-determined criteria.

 South Korea 
The South Korean Super aEgis II machine gun, unveiled in 2010, sees use both in South Korea and in the Middle East. It can identify, track, and destroy a moving target at a range of 4 km. While the technology can theoretically operate without human intervention, in practice safeguards are installed to require manual input. A South Korean manufacturer states, "Our weapons don't sleep, like humans must. They can see in the dark, like humans can't. Our technology therefore plugs the gaps in human capability", and they want to "get to a place where our software can discern whether a target is friend, foe, civilian or military".

 Trends 
According to Siemens, worldwide military spending on robotics was US$5.1 billion in 2010 and US$7.5 billion in 2015.

China became a top player in artificial intelligence research in the 2010s. According to the Financial Times, in 2016, for the first time, China published more AI papers than the entire European Union. When restricted to number of AI papers in the top 5% of cited papers, China overtook the United States in 2016 but lagged behind the European Union. 23% of the researchers presenting at the 2017 American Association for the Advancement of Artificial Intelligence (AAAI) conference were Chinese. Eric Schmidt, the former chairman of Alphabet, has predicted China will be the leading country in AI by 2025.

 AAAI presenters: Country  in 2012  in 2017 US 41%  34% China 10%  23% UK 5%  5%

 Proposals for international regulation 
As early as 2007, scholars such as AI professor Noel Sharkey have warned of "an emerging arms race among the hi-tech nations to develop autonomous submarines, fighter jets, battleships and tanks that can find their own targets and apply violent force without the involvement of meaningful human decisions". As early as 2014, AI specialists such as Steve Omohundro have been warning that "An autonomous weapons arms race is already taking place". Miles Brundage of the University of Oxford has argued an AI arms race might be somewhat mitigated through diplomacy: "We saw in the various historical arms races that collaboration and dialog can pay dividends". Over a hundred experts signed an open letter in 2017 calling on the UN to address the issue of lethal autonomous weapons; however, at a November 2017 session of the UN Convention on Certain Conventional Weapons (CCW), diplomats could not agree even on how to define such weapons. The Indian ambassador and chair of the CCW stated that agreement on rules remained a distant prospect. As of 2017, twenty-two countries have called for a full ban on lethal autonomous weapons.

Many experts believe attempts to completely ban killer robots are likely to fail. A 2017 report from Harvard's Belfer Center predicts that AI has the potential to be as transformative as nuclear weapons.Allen, Greg, and Taniel Chan. "Artificial Intelligence and National Security." Report. Harvard Kennedy School, Harvard University. Boston, MA (2017). The report further argues that "Preventing expanded military use of AI is likely impossible" and that "the more modest goal of safe and effective technology management must be pursued", such as banning the attaching of an AI dead man's switch to a nuclear arsenal. Part of the impracticality is that detecting treaty violations would be extremely difficult.Antebi, Liran. "Who Will Stop the Robots?." Military and Strategic Affairs 5.2 (2013).Shulman, C., & Armstrong, S. (2009, July). Arms control and intelligence explosions. In 7th European Conference on Computing and Philosophy (ECAP), Bellaterra, Spain, July (pp. 2-4).

 Other reactions to autonomous weapons 
A 2015 open letter calling for the ban of lethal automated weapons systems has been signed by tens of thousands of citizens, including scholars such as physicist Stephen Hawking, Tesla magnate Elon Musk, and Apple's Steve Wozniak.

Professor Noel Sharkey of the University of Sheffield has warned that autonomous weapons will inevitably fall into the hands of terrorist groups such as the Islamic State.

 Disassociation 
Many Western tech companies are leery of being associated too closely with the U.S. military, for fear of losing access to China's market. Furthermore, some researchers, such as DeepMind's Demis Hassabis, are ideologically opposed to contributing to military work.

For example, Project Maven is a Pentagon project involving using machine learning and engineering talent to distinguish people and objects in drone videos, established in a memo by the U.S. Deputy Secretary of Defense on 26 April 2017. Also known as the Algorithmic Warfare Cross Functional Team, it is, according to Lt. Gen. of the United States Air Force Jack Shanahan in November 2017, a project "designed to be that pilot project, that pathfinder, that spark that kindles the flame front of artificial intelligence across the rest of the [Defense] Department". Its chief, U.S. Marine Corps Col. Drew Cukor, said: "People and computers will work symbiotically to increase the ability of weapon systems to detect objects." At the second Defense One Tech Summit in July 2017, Cukor also said that the investment in a "deliberate workflow process" was funded by the Department [of Defense] through its "rapid acquisition authorities" for about "the next 36 months".

In June 2018, company sources at Google said that top executive Diane Greene told staff that the company would not follow-up Project Maven after the current contract expires in March 2019.