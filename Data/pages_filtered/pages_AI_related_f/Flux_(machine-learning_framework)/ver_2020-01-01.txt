 
 

Flux is an open-source machine-learning library and ecosystem written completely in Julia. Its current stable release is v0.10.0. Flux takes full advantage of Julia's just-ahead-of-time compilation and exposes an intuitive and flexible interface to users, while still providing a layer-stacking-based interface for simpler models, and can be readily integrated with other Julia packages. Flux can take full advantage of all Julia language features, and can work with almost all Julia packages. For example, GPU support is supplied transparently by CuArrays.jl, due to Julia's multiple dispatch. This is in contrast to some other machine learning frameworks which are implemented in other languages with Julia bindings,Â such as TensorFlow.jl, and thus are more limited by the functionality present in the underlying implementation, which is often in C or C++.

This advantage has been used, for example, to implement support for Neural Differential Equations, by fusing Flux and DifferentialEquations.jl into DiffEqFlux.jl.

Flux supports recurrent and convolutional networks. It is also capable of Differentiable programming through its source-to-source Automatic differentiation package, Zygote.

Julia is among the most popular machine-learning languages in Github and Flux is appointed as its most highly regarded machine-learning repository. A demonstration compiling Julia code to run in Google's Tensor processing unit received praise from Google Brain AI lead Jeff Dean.

Flux was employed to the first application of machine-learning to data encrypted with Homomorphic encryption without ever decrypting it. This kind of application is envisioned to be central for privacy to future API using machine-learning models.