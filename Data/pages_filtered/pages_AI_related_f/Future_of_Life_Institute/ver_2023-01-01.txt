The Future of Life Institute (FLI) is a nonprofit organization that works to reduce global catastrophic and existential risks facing humanity, particularly existential risk from advanced artificial intelligence (AI). The Institute's work is made up of three main strands: grantmaking for risk reduction, educational outreach, and advocacy within the United Nations, US government and European Union institutions. Its founders include MIT cosmologist Max Tegmark and Skype co-founder Jaan Tallinn, and its advisors include entrepreneur Elon Musk.

 Mission 
Max Tegmark, professor at MIT, one of the founders and current president of the Future of Life Institute
FLI's mission is reduce global catastrophic and existential risk from powerful technologies. FLI is particularly focused on the potential risks to humanity from the development of human-level or superintelligent artificial general intelligence (AGI), but also works on risks from biotechnology, nuclear weapons and climate change. The Institute's work is made up grantmaking for risk reduction, educational outreach, and advocacy within the United Nations, US government and European Union institutions.

 Key people 
The Institute was founded in March 2014 by MIT cosmologist Max Tegmark, Skype co-founder Jaan Tallinn, DeepMind research scientist Viktoriya Krakovna, Tufts University postdoctoral scholar Meia Chita-Tegmark, and UCSC physicist Anthony Aguirre. The Institute's advisors include computer scientists Stuart J. Russell and Francesca Rossi, biologist George Church, cosmologist Saul Perlmutter, astrophysicist Sandra Faber, theoretical physicist Frank Wilczek, entrepreneur Elon Musk, and actors and science communicators Alan Alda and Morgan Freeman (as well as cosmologist Stephen Hawking prior to his death in 2018).

 Conferences 
In 2014, the Future of Life Institute held its opening event at MIT: a panel discussion on "The Future of Technology: Benefits and Risks", moderated by Alan Alda. The panelists were synthetic biologist George Church, geneticist Ting Wu, economist Andrew McAfee, physicist and Nobel laureate Frank Wilczek and Skype co-founder Jaan Tallinn.

Since 2015, FLI has organised biannual conferences that bring together leading AI builders from academia and industry. To date, the following conferences have taken place:
 "The Future of AI: Opportunities and Challenges" conference in Puerto Rico (2015). The goal was to identify promising research directions that can help maximize the future benefits of AI. At the conference, the Institute circulated an open letter on AI safety which was subsequently signed by Stephen Hawking, Elon Musk, and many artificial intelligence experts.
 The Beneficial AI conference in Asilomar, California (2017), a private gathering of what The New York Times called "heavy hitters of A.I." (including Yann LeCun, Elon Musk, and Nick Bostrom). The institute released a set of principles for responsible AI development that came out of the discussion at the conference, signed by Yoshua Bengio, Yann LeCun, and many other AI researchers. These principles influenced the regulation of artificial intelligence and subsequent initiatives, such as the OECD Principles on Artificial Intelligence.
 The beneficial AGI conference in Puerto Rico (2019). This meeting focused on long-term questions on ensuring that Artificial General Intelligence is beneficial to humanity.

 Global research program 
The FLI research program started in 2015 with an initial donation of $10 million from Elon Musk. Unlike typical AI research, this program is focused on making AI safer or more beneficial to society, rather than just more powerful. In this initial round, a total of $7 million was awarded to 37 research projects. In July 2021, FLI announced that it would launch a new $25 million grant program with funding from the Russianâ€“Canadian programmer Vitalik Buterin.

 In the media 
 "The Fight to Define When AI is 'High-Risk'" in Wired.
 "Lethal Autonomous Weapons exist; They Must Be Banned" in IEEE Spectrum.
 "United States and Allies Protest U.N. Talks to Ban Nuclear Weapons" in The New York Times.
 "Is Artificial Intelligence a Threat?" in The Chronicle of Higher Education, including interviews with FLI founders Max Tegmark, Jaan Tallinn and Viktoriya Krakovna.
 "But What Would the End of Humanity Mean for Me?", an interview with Max Tegmark on the ideas behind FLI in The Atlantic.
 