Data augmentation in data analysis are techniques used to increase the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data. It acts as a regularizer and helps reduce overfitting when training a machine learning model. It is closely related to oversampling in data analysis.

 Synthetic oversampling techniques for traditional machine learning 

 Data augmentation for image classification 

 Transformations of images 
The Augmentor library introduces elastic transforms in order to generate new synthetic images from a dataset in order to alleviate issues of scarcity.
Geometric transformations, flipping, color modification, cropping, rotation, noise injection and random erasing are used to augment image in deep learning.

 Introducing new synthetic images 
If a dataset is very small, then a version augmented with rotation and mirroring etc. may still not be enough for a given problem. Another solution is the sourcing of entirely new, synthetic images through various techniques, for example the use of generative adversarial networks to create new synthetic images for data augmentation. Additionally, image recognition algorithms show improvement when transferring from images rendered in virtual environments to real-world data.

 Data augmentation for signal processing 
Residual or block bootstrap can be used for time series augmentation.

 Biological signals 
Synthetic data augmentation is of paramount importance for machine learning classification, particularly for biological data, which tend to be high dimensional and scarce. The applications of robotic control and augmentation in disabled and able-bodied subjects still rely mainly on subject-specific analyses. Data scarcity is notable in signal processing problems such as for Parkinson's Disease Electromyography signals, which are difficult to source - Zanini, et al. noted that it is possible to use a Generative adversarial network (in particular, a DCGAN) to perform style transfer in order to generate synthetic electromyographic signals that corresponded to those exhibited by sufferers of Parkinson's Disease.

The approaches are also important in electroencephalography (brainwaves). Wang, et al. explored the idea of using Deep Convolutional Neural Networks for EEG-Based Emotion Recognition, results show that emotion recognition was improved when data augmentation was used. 

A comparison of GPT-2 generated EEG signals (left) and real human brainwaves (right) across "Concentrating", "Relaxed", and "Neutral" mental state classes.
It has also been noted that OpenAI's GPT-2 model is capable of learning from, and generating synthetic biological signals such as EEG and EMG. In this study, it was noted that recognition was improved via data augmentation. It was also noted that statistical machine learning models trained on the synthetic domain could classify the human data, and vice versa. In the image, a comparison is given by some examples of EEG produced by the GPT-2 model and a human brain. 

A common approach is to generate synthetic signals by re-arranging components of real data. Lotte proposed a method of "Artificial Trial Generation Based on Analogy" where three data examples  provide examples and an artificial  is formed which is to  what  is to . A transformation is applied to  to make it more similar to , the same transformation is then applied to  which generates . This approach was shown to improve performance of a Linear Discriminant Analysis classifier on three different datasets.

Current research shows great impact can be derived from relatively simple techniques. For example, Freer observed that introducing noise into gathered data to form additional data points improved the learning ability of several models which otherwise performed relatively poorly. Tsinganos et al. studied the approaches of magnitude warping, wavelet decomposition, and synthetic surface EMG models (generative approaches) for hand gesture recognition, finding classification performance increases of up to +16% when augmented data was introduced during training. More recently, data augmentation studies have begun to focus on the field of deep learning, more specifically on the ability of generative models to create artificial data which is then introduced during the classification model training process. In 2018, Luo et al. observed that useful EEG signal data could be generated by Conditional Wasserstein Generative Adversarial Networks (GANs) which was then introduced to the training set in a classical train-test learning framework. The authors found classification performance was improved when such techniques were introduced.

 Data augmentation for speech recognition 
It has been noted that synthetic data generation of spoken MFCCs can improve the recognition of a speaker from their utterances via transfer learning from synthetic data which has been generated via a Character-level Recurrent Neural Network (RNN).