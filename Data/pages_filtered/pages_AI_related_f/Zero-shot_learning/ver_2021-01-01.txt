Zero-shot learning (ZSL) is a problem setup in machine learning, where at test time, a learner observes samples from classes that were not observed during training, and needs to predict the category they belong to.  This problem is widely studied in computer vision, natural language processing and machine perception. Unlike standard generalization in machine learning, where classifiers are expected to correctly classify new samples to classes they have already observed during training, in ZSL, no samples from the classes have been given during training the classifier. It can therefore be viewed as an extreme case of domain adaptation.

 Prerequisite information for zero-shot classes 
Naturally, some form of side information has to be given about these zero-shot classes, and this type of information can be of several types. 

 Learning with attributes: classes are accompanied by pre-defined structured description. For example, for bird descriptions, this could include "red head", "long beak" . These attributes are often organized in a structured compositional way, and taking that structure into account improves learning 
 Learning from textual description. Here classes are accompanied by free-text natural-language description. This could include for example a wikipedia description of the class  
 Class-class similarity. Here, classes are embedded in a continuous space. a zero-shot classifier can predict that a samples correspond to some position in that space, and the nearest embedded class is used as a predicted class, even if no such samples were observed during training. 

 Generalized zero-shot learning 
The above ZSL setup assumes that at test time, only zero-shot samples are given, namely, samples from new unseen classes. In generalized zero-shot learning, samples from both new and known classes, may appear at test time. This poses new challenges for classifiers at test time, because it is very challenging to estimate if a given sample is new or known. Few approaches to handle this include: 

 A gating approach. Here an additional module is first trained to decide if a given sample comes from a new class or from an old one. The gater could output a hard decision , but emitting a soft probabilistic decision further improves the accuracy of this line of approaches
 Generative approaches. Here, a generative model is trained to generate feature representation of the unseen classes. Then a standard classifier is trained given samples from all classes, seen and unseen. 

 Domains of application 
Zero shot learning has been applied to the following fields:
 image classification
 semantic segmentation
 image generation
 object detection
 natural language processing