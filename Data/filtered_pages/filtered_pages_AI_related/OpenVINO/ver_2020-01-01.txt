OpenVINO toolkit (Open Visual Inference and Neural network Optimization) is a free toolkit for inference neural network model on various Intel processors. The tookit has two versions: OpenVINO tookit, which is supported by open source community and Intel(R) Distribution of OpenVINO toolkit, which is supported by Intel.
OpenVINO was developed by Intel. The toolkit is cross-platform and free for use under Apache License Version 2.0https://docs.openvinotoolkit.org/.

The high level pipeline of OpenVINO consists of two parts: generate IR (Intermediate Representation) files via Model Optimizer using your trained model or public one and execute inference on Inference Engine on specified plugins (CPU, Intel Processor Graphics, VPU, FPGA, GNA, Multi-Device plugin, Heterogeneous plugin)https://docs.openvinotoolkit.org/latest/_docs_IE_DG_Introduction.html.

 Supported Frameworks and Formats 

 Caffe (most public branches)
 TensorFlow
 MXNet
 Kaldi
 ONNX
 and other frameworks that can be serialized to ONNX format (Pytorch, Caffe2, PaddlePaddle and others)

 Programming language 
OpenVINO is written in C++ and Python.

 OS support 
OpenVINO runs on the following desktop operation systems: Windows, Linux, MacOS.