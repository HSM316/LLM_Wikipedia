Julia is a high-level, general-purpose dynamic programming language, most commonly used for numerical analysis and computational science. Distinctive aspects of Julia's design include a type system with parametric polymorphism and the use of multiple dispatch as a core programming paradigm, efficient garbage collection, and a just-in-time (JIT) compiler (with support for ahead-of-time compilation).

Julia can be run similar to (interpreted) scripting languages (i.e. Julia has a REPL), and does by default using its runtime (when preinstalled), but Julia programs/source code can also optionally be sent to users in one ready-to-install/run file, which can be made quickly, not needing anything preinstalled. Julia programs can also be (separately) compiled to binary executables, even allowing no-source-code distribution. Such compilation is not needed for speed, since Julia is also compiled when running interactively, but it can help with hiding source code. With separate compilation all features of Julia can be used (by building in the runtime, or alternatively without the runtime, allows for tiny executables or libraries, but then with limited capabilities). Julia can be called from other languages, e.g. Python and R, and several Julia packages have been made easily available from those languages, in the form of libraries for them.

Julia's Visual Studio Code extension provides a fully-featured integrated development environment with support for debugging, linting, and profiling.

History
Work on Julia began in 2009, when Jeff Bezanson, Stefan Karpinski, Viral B. Shah, and Alan Edelman set out to create a free language that was both high-level and fast. On 14 February 2012, the team launched a website with a blog post explaining the language's mission. In an interview with InfoWorld in April 2012, Karpinski said of the name "Julia": "There's no good reason, really. It just seemed like a pretty name." Bezanson said he chose the name on the recommendation of a friend, then years later wrote:

Julia's syntax is now considered stable, since version 1.0 in 2018, and Julia has a backward compatibility guarantee for 1.x and also a stability promise for the documented (stable) API, while in the years before in the early development prior to 0.7 the syntax (and semantics) was changed in new versions. All of the (registered package) ecosystem uses the new and improved syntax, and in most cases relies on new APIs that have been added regularly, and in some cases minor additional syntax added in a forward compatible way e.g. in Julia 1.7.

In the 10 years since the 2012 launch of pre-1.0 Julia, the community has grown. The Julia package ecosystem has over 11.8 million lines of code (including docs and tests). The JuliaCon academic conference for Julia users and developers has been held annually since 2014 with JuliaCon2020 welcoming over 28,900 unique viewers, and then JuliaCon2021 breaking all previous records (with more than 300 JuliaCon2021 presentations available for free on YouTube, up from 162 the year before), and 43,000 unique viewers during the conference.

Three of the Julia co-creators are the recipients of the 2019 James H. Wilkinson Prize for Numerical Software (awarded every four years) "for the creation of Julia, an innovative environment for the creation of high-performance tools that enable the analysis and solution of computational science problems." Also, Alan Edelman, professor of applied mathematics at MIT, has been selected to receive the 2019 IEEE Computer Society Sidney Fernbach Award "for outstanding breakthroughs in high-performance computing, linear algebra, and computational science and for contributions to the Julia programming language."

Both Julia 0.7 and version 1.0 were released on 8 August 2018. Work on Julia 0.7 was a "huge undertaking" (e.g., because of an "entirely new optimizer"), and some changes were made to semantics, e.g. the iteration interface was simplified. Julia 1.1 was released in January 2019 with a new "exception stack" feature. Julia 1.2 was released in August 2019 with some built-in support for web browsers. Julia 1.3 added composable multi-threaded parallelism and a binary artifacts system for Julia packages. Julia 1.4 added syntax for generic array indexing to handle e.g. 0-based arrays. The memory model was also changed. Julia 1.5 released in August 2020 added record and replay debugging support, for Mozilla's rr tool.  The release changed the behavior in the REPL (soft scope) to the one used in Jupyter, but fully compatible with non-REPL code. Most of the thread API was marked as stable, and with this release "arbitrary immutable objects—regardless of whether they have fields that reference mutable objects or not—can now be stack allocated", reducing heap allocations, e.g. views are no longer allocating.  Julia 1.5 targeted so-called "time-to-first-plot" (TTFP, also called TTFX, for first X, the more general problem) performance, in general, the speed of compilation itself (as opposed to performance of the generated code), and added tools for developers to improve package loading.

Julia 1.6 was the largest release since 1.0, faster on many fronts, e.g. introduced parallel precompilation and faster loading of packages, in some cases "50x speedup in load times for large trees of binary artifacts".

As of version 1.7 Julia development is back to time-based releases. Julia 1.7.0 was released in November 2021 with many changes, e.g. a new faster random-number generator. Julia 1.7.3 was released on 25 May 2022, fixing some issues, including at least one security update, and 1.7.x is no longer supported. Julia 1.8 was released in 2022 (and versions up to 1.8.5 as a followup in January 2023, both fixing bugs (backporting) and "invalidations", thus compiling faster), with improvements for distributing Julia programs without source code,  and compiler speedup, in some cases by 25%,  and more controllable inlining (i.e. now also allowing applying @inline at the call site, not just on the function itself).

Julia 1.9.0 was released on 7 May 2023 (and later 1.9.4, the latest stable version). It has many improvements, such as solving the TTFX/TTFP problem; older releases have precompilation for packages, but they were not precompiled fully to native code until 1.9, leading to slower first use. Precompiled packages, since version 1.9, can be up to hundreds of times faster on first use (e.g. for CSV.jl and DataFrames.jl), and to improve precompilation of packages a new package PrecompileTools.jl has been introduced.

JuliaCon
Since 2014, the Julia Community has hosted an annual Julia Conference focused on developers and users. The first JuliaCon took place in Chicago and kickstarted the annual occurrence of the conference. Since 2014, the conference has taken place across a number of locations including MIT and the University of Maryland, Baltimore. The event audience has grown from a few dozen people to over 28,900 unique attendees during JuliaCon 2020, which took place virtually. JuliaCon 2021 also took place virtually with keynote addresses from professors William Kahan (the primary architect of the IEEE 754 floating-point standard, which his keynote is about, that virtually all CPUs use and languages, including Julia), and Jan Vitek, Xiaoye Sherry Li, and Soumith Chintala (co-creator of PyTorch). JuliaCon grew to 43,000 unique attendees and more than 300 presentations (still freely accessible, plus for older years). JuliaCon 2022 will also be virtual held between July 27 and July 29, 2022, for the first time in several languages, not just in English.

Sponsors
The Julia language became a NumFOCUS fiscally sponsored project in 2014 in an effort to ensure the project's long-term sustainability. Jeremy Kepner at MIT Lincoln Laboratory was the founding sponsor of the Julia project in its early days. In addition, funds from the Gordon and Betty Moore Foundation, the Alfred P. Sloan Foundation, Intel, and agencies such as NSF, DARPA, NIH, NASA, and FAA have been essential to the development of Julia. Mozilla, the maker of Firefox web browser, with its research grants for H1 2019, sponsored "a member of the official Julia team" for the project "Bringing Julia to the Browser", meaning to Firefox  and other web browsers. The Julia language is also supported by individual donors on GitHub.

The Julia company
JuliaHub, Inc. was founded in 2015 as Julia Computing, Inc. by Viral B. Shah, Deepak Vinchhi, Alan Edelman, Jeff Bezanson, Stefan Karpinski and Keno Fischer.

In June 2017, Julia Computing raised US$4.6million in seed funding from General Catalyst and Founder Collective, the same month was "granted $910,000 by the Alfred P. Sloan Foundation to support open-source Julia development, including $160,000 to promote diversity in the Julia community", and in December 2019 the company got $1.1million funding from the US government to "develop a neural component machine learning tool to reduce the total energy consumption of heating, ventilation, and air conditioning (HVAC) systems in buildings". In July 2021, Julia Computing announced they raised a $24 million Series A round led by Dorilton Ventures, which also owns  team Williams Racing, that partnered with Julia Computing. Williams' Commercial Director said: "Investing in companies building best-in-class cloud technology is a strategic focus for Dorilton and Julia's versatile platform, with revolutionary capabilities in simulation and modelling, is hugely relevant to our business. We look forward to embedding Julia Computing in the world's most technologically advanced sport". In June 2023, JuliaHub received (again, now under its new name) a $13 million strategic new investment led by AE Industrial Partners HorizonX ("AEI HorizonX"). AEI HorizonX is a venture capital investment platform formed in partnership with The Boeing Company, which uses Julia. Tim Holy's work (at WashU's Holy Lab) on Julia 1.9 (improving responsiveness) was funded by the Chan Zuckerberg Initiative.

Language features

Julia is a general-purpose programming language, while also originally designed for numerical/technical computing.
It is also useful for low-level systems programming, as a specification language, high-level synthesis (HLS) tool (for hardware, e.g. FPGAs), and for web programming at both server and client side.

The main features of the language are:
 Multiple dispatch: providing ability to define function behavior across combinations of argument types
 Dynamic type system: types for documentation, optimization, and dispatch
 Performance approaching that of statically-typed languages like C
 A built-in package manager
 Lisp-like macros and other metaprogramming facilities
 Designed for parallel and distributed computing
 Coroutines: lightweight green threading
 Automatic generation of code for different argument types
 Extensible conversions and promotions for numeric and other types
Multiple dispatch (also termed multimethods in Lisp) is a generalization of single dispatch the polymorphic mechanism used in common object-oriented programming (OOP) languages, such as Python, C++, Java, JavaScript, and Smalltalk that uses inheritance. In Julia, all concrete types are subtypes of abstract types, directly or indirectly subtypes of the Any type, which is the top of the type hierarchy. Concrete types can not themselves be subtyped the way they can in other languages; composition is used instead (see also inheritance vs subtyping).

By default, the Julia runtime must be pre-installed as user-provided source code is run. Alternatively, Julia (GUI) apps can be quickly bundled up into a single file with AppBundler.jl for "building Julia GUI applications in modern desktop application installer formats. It uses Snap for Linux, MSIX for Windows, and DMG for MacOS as targets. It bundles full Julia within the app". PackageCompiler.jl can build standalone executables that need no Julia source code to run.

In Julia, everything is an object, much like object-oriented languages; however, unlike most object-oriented languages, all functions use multiple dispatch to select methods, rather than single dispatch. 

Most programming paradigms can be implemented using Julia's homoiconic macros and packages. Julia's syntactic macros (used for metaprogramming), like Lisp macros, are more powerful than text-substitution macros used in the preprocessor of some other languages such as C, because they work at the level of abstract syntax trees (ASTs). Julia's macro system is hygienic, but also supports deliberate capture when desired (like for anaphoric macros) using the esc construct.

Julia draws inspiration from various dialects of Lisp, including Scheme and Common Lisp, and it shares many features with Dylan, also a multiple-dispatch-oriented dynamic language (which features an ALGOL-like free-form infix syntax rather than a Lisp-like prefix syntax, while in Julia "everything" is an expression), and with Fortress, another numerical programming language (which features multiple dispatch and a sophisticated parametric type system). While Common Lisp Object System (CLOS) adds multiple dispatch to Common Lisp, not all functions are generic functions.

In Julia, Dylan, and Fortress, extensibility is the default, and the system's built-in functions are all generic and extensible. In Dylan, multiple dispatch is as fundamental as it is in Julia: all user-defined functions and even basic built-in operations like + are generic. Dylan's type system, however, does not fully support parametric types, which are more typical of the ML lineage of languages. By default, CLOS does not allow for dispatch on Common Lisp's parametric types; such extended dispatch semantics can only be added as an extension through the CLOS Metaobject Protocol. By convergent design, Fortress also features multiple dispatch on parametric types; unlike Julia, however, Fortress is statically rather than dynamically typed, with separate compiling and executing phases. The language features are summarized in the following table:

 Language  Type system  Generic functions  Parametric types Julia  Dynamic  Default   Common Lisp  Dynamic  Opt-in   Dylan  Dynamic  Default   (no dispatch) Fortress  Static  Default  

An example of the extensibility of Julia, the Unitful.jl package adds support for physical units of measurement to the language.

Interoperability
Julia has built-in support for calling C or Fortran language libraries using the @ccall macro. Additional libraries allow users to work with Python, R, C++, Java, and SQL.

Separately-compiled executables option
Julia can be compiled to binary executables with PackageCompiler.jl. Smaller executables can also be written using a static subset of the language provided by StaticCompiler.jl that does not support runtime dispatch (nor garbage collection, since excludes the runtime that provides it).

Interaction
The Julia official distribution includes an interactive command-line read–eval–print loop (REPL), with a searchable history, tab completion, and dedicated help and shell modes, which can be used to experiment and test code quickly. The following fragment represents a sample session example where strings are concatenated automatically by println:See also:  for string interpolation and the string(greet, ", ", whom, ".\n") example for preferred ways to concatenate strings.  Julia has the println and print functions, but also a @printf macro (i.e., not in function form) to eliminate run-time overhead of formatting (unlike the same function in C).

julia> p(x) = 2x^2 + 1; f(x, y) = 1 + 2p(x)y
julia> println("Hello world!", " I'm on cloud ", f(0, 4), " as Julia supports recognizable syntax!")
Hello world! I'm on cloud 9 as Julia supports recognizable syntax!

The REPL gives user access to the system shell and to help mode, by pressing ; or ? after the prompt (preceding each command), respectively. It also keeps the history of commands, including between sessions. Code can be tested inside Julia's interactive session or saved into a file with a .jl extension and run from the command line by typing:

 $ julia <filename>

Julia uses UTF-8 and LaTeX codes, allowing it to support common math symbols for many operators, such as ∈ for the in operator, typable with \in then pressing  (i.e. uses LaTeX codes, or also possible by simply copy-pasting, e.g.  possible for sqrt and cbrt functions). Julia has support for the latest Unicode 15.1 for the languages of the world, even for source code, e.g. variable names (while it's recommened to use English recommended for code for others to read e.g. package names).

Julia is supported by Jupyter, an online interactive "notebooks" environment, and Pluto.jl, a "reactive notebook" (where notebooks are saved as pure Julia files), a possible replacement for the former kind. In addition Posit's (formerly RStudio Inc's) Quarto publishing system supports Julia, Python, R and Observable JavaScript (those languages have official support by the company, and can even be weaved together in the same notebook document, more languages are unofficially supported).

The REPL can be extended with additional modes, and has been with packages, e.g. with an SQL mode, for database access, and RCall.jl adds an , to work with the R language.

Use with other languages
Julia is in practice interoperable with other languages (e.g. majority of top 10–20 languages in popular use).  is used to call shared library functions individually (such as for written in C or Fortran), and packages are available to allow calling other languages (which do not provide C-exported functions directly) e.g. Python (with PythonCall.jl), R, MATLAB, C# (and other .NET languages with DotNET.jl, from them with JdotNET), JavaScript, Java (and other JVM languages, such as Scala with JavaCall.jl). And packages for other languages allow to call to Julia, e.g. from Python, R, Rust, Ruby, or C#. Such as with juliacall (part of PythonCall.jl, pyjulia is a different option) to call from Python and a different JuliaCall package for calling from R. Julia has also been used for hardware, i.e. to compile to VHDL, as a high-level synthesis (HLS) tool (for e.g. FPGAs).

Julia has packages supporting markup languages such as HTML (and also for HTTP), XML, JSON and BSON, and for databases (such as PostgreSQL, Mongo, Oracle, including for TimesTen, MySQL, SQLite, Microsoft SQL Server, Amazon Redshift, Vertica, ODBC) and web use in general.

Package system
Julia has a built-in package manager and includes a default registry system. Packages are most often distributed as source code hosted on GitHub, though alternatives can also be used just as well. Packages can also be installed as binaries, using artifacts. Julia's package manager is used to query and compile packages, as well as managing environments. Federated package registries are supported, allowing registries other than the official to be added locally.

Implementation
Julia's core is implemented in Julia and C, together with C++ for the LLVM dependency. The code parsing and code-lowering were implemented in FemtoLisp, a Scheme dialect, up to version 1.10. Since that version the new pure-Julia package JuliaSyntax.jl, is used for the parsing (while the old one can still be chosen) which improves speed and "greatly improves parser error messages in various cases". The LLVM compiler infrastructure project is used as the back end for generating optimized machine code for all commonly-used platforms. With some exceptions, the standard library is implemented in Julia.

Current and future platforms
Julia has tier 1 macOS support, for 64-bit Apple Silicon Macs, natively (previously Apple M1-based Macs were only supported by running in Rosetta 2 emulation), and also fully supports Intel-based Macs.  however does not fully support the Arm-based Macs (was then marked experimental), and that support got first upgraded to tier 2 with Julia 1.8, then to tier 1. Windows on ARM has no official support yet.

Julia has four support tiers. All IA-32 processors completely implementing the i686 subarchitecture are supported and all 64-bit x86-64 (aka amd64), i.e. all less than about a decade old are supported. Armv8 (AArch64) processors are supported on second tier, and ARMv7 (AArch32) on third tier. Hundreds of packages are GPU-accelerated: CUDA (i.e. Nvidia GPUs; implementing PTX) has tier 1 support, with the help of an external package (and older versions of the package support down to CUDA 9). There are also additionally packages supporting other accelerators, such as Google's TPUs, and some Intel (integrated) GPUs, through oneAPI.jl, and AMD's GPUs have support with e.g. OpenCL; and experimental support for the AMD ROCm stack.

On some platforms, Julia may need to be compiled from source code (e.g., the original Raspberry Pi), with specific build options, which has been done and unofficial pre-built binaries (and build instructions) are available. Julia has been built 
for several ARM platforms, from small Raspberry Pis to (recent) top-1 supercomputer Fugaku's ARM-based A64FX. PowerPC (64-bit) has tier 3 support, meaning it "may or may not build".

Julia is now supported in Raspbian while support is better for newer Pis, e.g., those with Armv7 or newer; the Julia support is promoted by the Raspberry Pi Foundation.

While Julia requires an operating system by default, and has no official support to run without or on embedded system platforms such as Arduino, Julia code has still been run on it, with some limitations, i.e. on a baremetal 16 MHz 8-bit (ATmega328P) AVR-microcontroller Arduino with 2 KB RAM (plus 32 KB of flash memory).

Adoption
Julia has been adopted at many universities including MIT, Stanford, UC Berkeley and the University of Cape Town. Large private firms across many sectors have adopted the language including Amazon, IBM, JP Morgan AI Research, and ASML. Julia has also been used by government agencies including NASA and the FAA, as well as every US national energy laboratory.

Scientific computing and engineering
 Amazon, for quantum computing and machine learning through Amazon SageMaker
 ASML, for hard real-time programming with their machines
 The Climate Modeling Alliance for climate change modeling
 CERN, to analyze data from the Large Hadron Collider (LHCb experiment).
 NASA and the Jet Propulsion Laboratory use Julia to model spacecraft separation dynamics, analyze TRAPPIST exoplanet datasets, and analyze cosmic microwave background data from the Big Bang
 The Brazilian INPE, for space missions and satellite simulations
 Embedded hardware to plan and execute flight of autonomous U.S. Air Force Research Laboratory VTOL drones

Pharmaceuticals and drug development
Julia is widely used for drug development in the pharmaceutical industry, having been adopted by Moderna, Pfizer, AstraZeneca, Procter & Gamble, and United Therapeutics.

Economics, finance, and political science
 The Federal Reserve Bank of New York, for macroeconomic modeling in Julia since 2015, including estimates of COVID-19 shocks in 2021 
 Also the Bank of Canada, central bank, for macroeconomic modeling
 BlackRock, the world's largest asset manager, for financial time-series analysis
 Aviva, the UK's largest general insurer, for actuarial calculations
 Mitre Corporation, for verification of published election results
 Nobel laureate Thomas J. Sargent, for macroeconometric modeling