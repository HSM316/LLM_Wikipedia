Learning curve showing training score and cross validation score

In machine learning, a learning curve (or training curve) plots the optimal value of a model's loss function for a training set against this loss function evaluated on a validation data set with same parameters as produced the optimal function. It is a tool to find out how much a machine model benefits from adding more training data and whether the estimator suffers more from a variance error or a bias error. If both the validation score and the training score converge to a value that is too low with increasing size of the training set, it will not benefit much from more training data.

The machine learning curve is useful for many purposes including comparing different algorithms,  choosing model parameters during design, adjusting optimization to improve convergence, and determining the amount of data used for training.

In the machine learning domain, there are two implications of learning curves differing in the x-axis of the curves, with experience of the model graphed either as the number of training examples used for learning or the number of iterations used in training the model.

 Formal definition 
One model of a machine learning is producing a function, , which given some information, , predicts some variable, , from training data  and . It is distinct from mathematical optimization because  should predict well for  outside of .

We often constrain the possible functions to a parameterized family of functions, , so that our function is more generalizable or so that the function has certain properties such as those that make finding a good  easier, or because we have some a priori reason to think that these properties are true.

Given that it is not possible to produce a function that perfectly fits out data, it is then necessary to produce a loss function  to measure how good our prediction is.  We then define an optimization process which finds a  which minimizes  referred to as  .

 Training curve for amount of data 
Then if our training data is  and our validation data is  a learning curve is the plot of the two curves

 
 

where 

 Training curve for number of iterations 
Many optimization processes are iterative, repeating the same step until the process converges to an optimal value. Gradient descent is one such algorithm. If you define  as the approximation of the optimal  after  steps, a learning curve is the plot of

 
 