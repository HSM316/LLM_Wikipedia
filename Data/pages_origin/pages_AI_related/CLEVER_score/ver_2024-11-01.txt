{{Orphan|date=September 2018}}
{{notability|date=September 2018}}

The CLEVER ('''C'''ross '''L'''ipschitz '''E'''xtreme '''V'''alue for n'''E'''twork '''R'''obustness) score is a way of measuring the robustness of an [[artificial neural network]] towards [[Deep learning#Cyber threat|adversarial attacks]].<ref>{{cite arXiv |last=Weng |first=Tsui-Wei |date=2018 |title=Evaluating the robustness of neural networks: An extreme value theory approach |class=stat.ML |eprint=1801.10578}}</ref>
It was developed by a team at the [[MIT-IBM Watson AI Lab]] in [[IBM Research]] and first presented at the 2018 [[International Conference on Learning Representations]].<ref>{{cite web |url=https://www.ibm.com/blogs/research/2018/05/clever-adversarial-attack/ |title=A CLEVER Way to Resist Adversarial Attack |last= |first= |date=May 2, 2018 |website= [[IBM]]|publisher= |access-date=September 12, 2018 |quote=}}</ref> It was mentioned and reviewed by [[Ian Goodfellow]]<ref>{{cite web|url=https://openreview.net/forum?id=BkUHlMZ0b |title=Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach|date=10 February 2022 }}</ref> as well. It was adopted into an educational game Fool The Bank<ref>{{ cite web|url=https://foolthebank.mybluemix.net/ |title=Fool the Bank - IBM Research}}</ref> by Narendra Nath Joshi,<ref>{{cite web|url=http://nnjoshi.co |title=Narendra Nath Joshi}}</ref> Abhishek Bhandwaldar and Casey Dugan

== References ==
{{Reflist}}

[[Category:Deep learning]]
[[Category:AI safety]]

{{Computer-science-stub}}