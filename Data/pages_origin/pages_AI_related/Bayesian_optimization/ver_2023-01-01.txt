'''Bayesian optimization''' is a [[sequential analysis|sequential design]] strategy for [[global optimization]] of [[Black box|black-box]] functions<ref name="Mockus1989"/><ref name="garnett_bayesopt_2022">{{Cite book |last=Garnett |first=Roman |url=https://bayesoptbook.com |title=Bayesian Optimization |date=2023 |publisher=Cambridge University Press |isbn=978-1-108-42578-0 }}</ref><ref name="HennigOsborneKersting2022">{{cite book | author1 = Hennig, P.
| author2 = Osborne, M. A.
| author3 = Kersting, H. P.
| date = 2022
| title = Probabilistic Numerics
| pages = 243–278
| publisher=Cambridge University Press
| isbn=978-1107163447
| url = https://www.probabilistic-numerics.org/assets/ProbabilisticNumerics.pdf
}}</ref>  that does not assume any functional forms. It is usually employed to optimize expensive-to-evaluate functions.

==History==
The term is generally attributed to {{ill|Jonas Mockus|lt}} and is coined in his work from a series of publications on global optimization in the 1970s and 1980s.<ref>{{cite journal |first=Jonas |last=Močkus |doi=10.1007/3-540-07165-2_55 |title=On Bayesian Methods for Seeking the Extremum |journal=Optimization Techniques |series=Lecture Notes in Computer Science |year=1974 |volume=27 |pages=400–404 |isbn=978-3-540-07165-5 }}</ref><ref>{{cite journal |first=Jonas |last=Močkus |title=On Bayesian Methods for Seeking the Extremum and their Application |journal=IFIP Congress |year=1977 |pages=195–200 }}</ref><ref name="Mockus1989">{{cite book |first=J. |last=Močkus |title=Bayesian Approach to Global Optimization |publisher=Kluwer Academic |location=Dordrecht |year=1989 |isbn=0-7923-0115-3 }}</ref>

==Strategy==
[[File:GpParBayesAnimationSmall.gif|thumb|440x330px|Bayesian optimization of a function (black) with Gaussian processes (purple). Three acquisition functions (blue) are shown at the bottom.<ref>{{Citation|last=Wilson|first=Samuel|title=ParBayesianOptimization R package|date=2019-11-22|url=https://github.com/AnotherSamWilson/ParBayesianOptimization|access-date=2019-12-12}}</ref>]]
Bayesian optimization is typically used on problems of the form <math display="inline">\max_{x \in A} f(x)</math>, where <math display="inline">A</math> is a set of points, <math display="inline">x</math>, which rely upon less than 20 [[dimension]]s (<math display="inline">\mathbb{R}^d, d \le 20</math>), and whose membership can easily be evaluated. Bayesian optimization is particularly advantageous for problems where <math display="inline">f(x)</math> is difficult to evaluate due to its computational cost. The objective function, <math display="inline">f</math>, is continuous and takes the form of some unknown structure, referred to as a "black box". Upon its evaluation, only <math display="inline">f(x)</math> is observed and its [[derivative]]s are not evaluated.<ref name=":0">{{cite arXiv|last=Frazier|first=Peter I.|date=2018-07-08|title=A Tutorial on Bayesian Optimization|class=stat.ML|eprint=1807.02811}}</ref>

Since the objective function is unknown, the Bayesian strategy is to treat it as a random function and place a [[Prior distribution|prior]] over it. The prior captures beliefs about the behavior of the function. After gathering the function evaluations, which are treated as data, the prior is updated to form the [[posterior distribution]] over the objective function. The posterior distribution, in turn, is used to construct an acquisition function (often also referred to as infill sampling criteria) that determines the next query point.

There are several methods used to define the prior/posterior distribution over the objective function. The most common two methods use [[Gaussian process]]es in a method called [[kriging]]. Another less expensive method uses the [[Parzen-Tree Estimator]] to construct two distributions for 'high' and 'low' points, and then finds the location that maximizes the expected improvement.<ref>J. S. Bergstra, R. Bardenet, Y. Bengio, B.  Kégl: [http://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf Algorithms for Hyper-Parameter Optimization]. Advances in Neural Information Processing Systems: 2546–2554 (2011)</ref>

Standard Bayesian optimization relies upon each <math>x \in A</math> being easy to evaluate, and problems that deviate from this assumption are known as ''exotic Bayesian optimization'' problems. Optimization problems can become exotic if it is known that there is noise, the evaluations are being done in parallel, the quality of evaluations relies upon a tradeoff between difficulty and accuracy, the presence of random environmental conditions, or if the evaluation involves derivatives.<ref name=":0" />

==Acquisition functions==
Examples of acquisition functions include 
* [[probability of improvement]]
* [[expected improvement]]
* [[Bayesian expected losses]]
* [[upper confidence bound]]s (UCB) or [[lower confidence bound]]s
* [[Thompson sampling]] 
and hybrids of these.<ref>Matthew W. Hoffman, Eric Brochu, [[Nando de Freitas]]: Portfolio Allocation for Bayesian Optimization. Uncertainty in Artificial Intelligence: 327–336 (2011)</ref> They all trade-off [[exploration and exploitation]] so as to minimize the number of function queries. As such, Bayesian optimization is well suited for functions that are expensive to evaluate.

==Solution methods==
The maximum of the acquisition function is typically found by resorting to discretization or by means of an auxiliary optimizer. Acquisition functions are typically well-behaved {{Citation needed|reason=doubtful since acquisition functions have many local maxima|date=November 2021}} and are 
maximized using a [[Mathematical_optimization#Computational_optimization_techniques|numerical optimization technique]], such as [[Newton's method in optimization|Newton's Method]] or quasi-Newton methods like the [[Broyden–Fletcher–Goldfarb–Shanno algorithm]].

==Applications==
The approach has been applied to solve a wide range of problems,<ref>Eric Brochu, Vlad M. Cora, Nando de Freitas: [https://arxiv.org/abs/1012.2599 A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning]. CoRR abs/1012.2599 (2010)</ref> including [[learning to rank]],<ref>Eric Brochu, Nando de Freitas, Abhijeet Ghosh: [http://papers.nips.cc/paper/3219-active-preference-learning-with-discrete-choice-data.pdf Active Preference Learning with Discrete Choice Data]. Advances in Neural Information Processing Systems: 409-416 (2007)</ref> [[computer graphics]] and visual design,<ref>Eric Brochu, Tyson Brochu, Nando de Freitas: [http://haikufactory.com/files/sca2010.pdf A Bayesian Interactive Optimization Approach to Procedural Animation Design]. Symposium on Computer Animation 2010: 103–112</ref><ref>Yuki Koyama, Issei Sato, Daisuke Sakamoto, Takeo Igarashi: [https://koyama.xyz/project/sequential_line_search/download/preprint.pdf Sequential Line Search for Efficient Visual Design Optimization by Crowds]. ACM Transactions on Graphics, Volume 36, Issue 4, pp.48:1–48:11 (2017). DOI: https://doi.org/10.1145/3072959.3073598</ref><ref>Yuki Koyama, Issei Sato, Masataka Goto: [https://arxiv.org/abs/2005.04107 Sequential Gallery for Interactive Visual Design Optimization]. ACM Transactions on Graphics, Volume 39, Issue 4, pp.88:1–88:12 (2020). DOI: https://doi.org/10.1145/3386569.3392444</ref> [[robotics]],<ref>Daniel J. Lizotte, Tao Wang, Michael H. Bowling, Dale Schuurmans: [https://www.aaai.org/Papers/IJCAI/2007/IJCAI07-152.pdf Automatic Gait Optimization with Gaussian Process Regression]. International Joint Conference on Artificial Intelligence: 944–949 (2007)</ref><ref>Ruben Martinez-Cantin, Nando de Freitas, Eric Brochu, Jose Castellanos and Arnaud Doucet. [https://link.springer.com/article/10.1007%2Fs10514-009-9130-2# A Bayesian exploration-exploitation approach for optimal online sensing and planning with a visually guided mobile robot]. Autonomous Robots. Volume 27, Issue 2, pp 93–103 (2009)</ref><ref>Scott Kuindersma, Roderic Grupen, and Andrew Barto. [http://ijr.sagepub.com/content/32/7/806.abstract# Variable Risk Control via Stochastic Optimization]. International Journal of Robotics Research, volume 32, number 7, pp 806–825 (2013)</ref><ref>Roberto Calandra, André Seyfarth, Jan Peters, and Marc P. Deisenroth [https://link.springer.com/article/10.1007%2Fs10472-015-9463-9 Bayesian optimization for learning gaits under uncertainty]. Ann. Math. Artif. Intell. Volume 76, Issue 1, pp 5-23 (2016) DOI:10.1007/s10472-015-9463-9</ref> [[sensor networks]],<ref>Niranjan Srinivas, Andreas Krause, Sham M. Kakade, Matthias W. Seeger: [https://infoscience.epfl.ch/record/177246/files/srinivas_ieeeit2012.pdf Information-Theoretic Regret Bounds for Gaussian Process Optimization in the Bandit Setting]. IEEE Transactions on Information Theory 58(5):3250–3265 (2012)</ref><ref>Roman Garnett, Michael A. Osborne, Stephen J. Roberts: [http://www.academia.edu/download/30681076/ipsn673-garnett.pdf Bayesian optimization for sensor set selection]{{dead link|date=July 2022|bot=medic}}{{cbignore|bot=medic}}. ACM/IEEE International Conference on Information Processing in Sensor Networks: 209–219 (2010)</ref> automatic algorithm configuration,<ref>Frank Hutter, Holger Hoos, and Kevin Leyton-Brown (2011). [http://www.cs.ubc.ca/labs/beta/Projects/SMAC/papers/11-LION5-SMAC.pdf Sequential model-based optimization for general algorithm configuration], Learning and Intelligent Optimization</ref><ref>J. Snoek, H. Larochelle, R. P. Adams [https://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf Practical Bayesian Optimization of Machine Learning Algorithms]. Advances in Neural Information Processing Systems: 2951-2959 (2012)</ref> automatic [[machine learning]] toolboxes,<ref>J. Bergstra, D. Yamins, D. D. Cox (2013).
[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.704.3494&rep=rep1&type=pdf Hyperopt: A Python Library for Optimizing the Hyperparameters of Machine Learning Algorithms].
Proc. SciPy 2013.</ref><ref>Chris Thornton, Frank Hutter, Holger H. Hoos, Kevin Leyton-Brown: [https://arxiv.org/abs/1208.3719 Auto-WEKA: combined selection and hyperparameter optimization of classification algorithms]. KDD 2013: 847–855</ref><ref>Jasper Snoek, Hugo Larochelle and Ryan Prescott Adams. [https://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf Practical Bayesian Optimization of Machine Learning Algorithms]. Advances in Neural Information Processing Systems, 2012</ref> [[reinforcement learning]], planning, visual attention, architecture configuration in [[deep learning]], static program analysis, experimental [[particle physics]],<ref>Philip Ilten, Mike Williams, Yunjie Yang. [https://arxiv.org/abs/1610.08328 Event generator tuning using Bayesian optimization]. 2017 JINST 12 P04028. DOI: 10.1088/1748-0221/12/04/P04028</ref><ref>Evaristo Cisbani et al. [https://iopscience.iop.org/article/10.1088/1748-0221/15/05/P05009 AI-optimized detector design for the future Electron-Ion Collider: the dual-radiator RICH case] 2020 JINST 15 P05009. DOI: 10.1088/1748-0221/15/05/P05009</ref> chemistry, material design, and drug development.<ref name=":0" /><ref>Gomez-Bombarelli et al. [https://pubs.acs.org/doi/10.1021/acscentsci.7b00572 Automatic Chemical Design using a Data-Driven Continuous Representation of Molecules]. ACS Central Science, Volume 4, Issue 2, 268-276 (2018)</ref><ref>Griffiths et al. [https://pubs.rsc.org/en/content/articlehtml/2020/sc/c9sc04026a Constrained Bayesian Optimization for Automatic Chemical Design using Variational Autoencoders] Chemical Science: 11, 577-586 (2020)</ref>

==See also==
* [[Multi-armed bandit]]
* [[Kriging]]
* [[Thompson sampling]]
* [[Global optimization]]
* [[Bayesian experimental design]]
* [[Probabilistic numerics]]
* [[Pareto optimum]]

==References==
{{reflist}}

==External links==
* [https://sheffieldml.github.io/GPyOpt/ GPyOpt], Python open-source library for Bayesian Optimization based on [https://github.com/SheffieldML/GPy GPy].
* [https://rmcantin.bitbucket.io/html/ Bayesopt], an efficient implementation in C/C++ with support for Python, Matlab and Octave.
* [https://github.com/HIPS/Spearmint Spearmint], a Python implementation focused on parallel and cluster computing.
* [http://www.cs.ubc.ca/labs/beta/Projects/SMAC/ SMAC], a Java implementation of random-forest-based Bayesian optimization for general algorithm configuration.
* [https://github.com/AnotherSamWilson/ParBayesianOptimization ParBayesianOptimization], A high performance, parallel implementation of Bayesian optimization with Gaussian processes in R.
* [https://github.com/mwhoffman/pybo pybo], a Python implementation of modular Bayesian optimization.
* [https://bitbucket.org/mlcircus/bayesopt.m Bayesopt.m], a Matlab implementation of Bayesian optimization with or without constraints.
* [https://github.com/yelp/MOE MOE] MOE is a Python/C++/CUDA implementation of Bayesian Global Optimization using Gaussian Processes.
* [https://sigopt.com/ SigOpt] SigOpt offers Bayesian Global Optimization as a SaaS service focused on enterprise use cases.
* [https://mindfoundry.ai/optaas Mind Foundry] OPTaaS offers Bayesian Global Optimization via web-services with flexible parameter constraints.
* [http://bayeso.org bayeso], a Python implementation of Bayesian optimization.
* [https://botorch.org BoTorch], a modular and modern PyTorch-based open-source library for Bayesian optimization research with support for [http://gpytorch.ai GPyTorch].
* [https://github.com/GPflow/GPflowOpt GPflowOpt], a TensorFlow-based open-source package for Bayesian optimization.
* [https://github.com/secondmind-labs/trieste trieste], an open-source Bayesian Optimization toolbox built on [https://www.tensorflow.org/ TensorFlow] and [https://github.com/GPflow/GPflow GPflow].
* [https://github.com/google/vizier Open Source Vizier], a Python service which allows Bayesian Optimization development built upon [https://www.tensorflow.org/probability Tensorflow Probability].

[[Category:Sequential methods]]
[[Category:Sequential experiments]]
[[Category:Stochastic optimization]]
[[Category:Machine learning]]