[[File:Partnership on AI logo.svg|thumb|Logo of the Partnership on AI]]
'''Partnership on Artificial Intelligence to Benefit People and Society,''' otherwise known as Partnership on AI, is a nonprofit coalition committed to the responsible use of [[artificial intelligence]]. Coming into inception in September of 2016, PAI (Partnership on AI) grouped together members from over 90 companies and non-profits in order to explore best practice recommendations for the tech community. <ref>{{Cite journal |last=Belfield |first=Haydn |date=2020-02-07 |title=Activism by the AI Community: Analysing Recent Achievements and Future Prospects |url=https://dl.acm.org/doi/10.1145/3375627.3375814 |journal=Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society |series=AIES '20 |location=New York, NY, USA |publisher=Association for Computing Machinery |pages=15–21 |doi=10.1145/3375627.3375814 |isbn=978-1-4503-7110-0}}</ref>Since its founding, Partnership on AI has experienced plethora of change with influential moments, comprehensive principles and missions, and generating more relevancy by every passing day.{{Short description|Nonprofit coalition}}

== History ==
The Partnership on AI was publicly announced on September 28, 2016 with founding members [[Amazon.com|Amazon]], [[Facebook]], [[Google]], [[DeepMind]], [[Microsoft]], and [[IBM]], with interim co-chairs [[Eric Horvitz]] of [[Microsoft Research]] and [[Mustafa Suleyman]] of DeepMind.<ref>{{cite news |last=Hern |first=Alex |date=2016-09-28 |title='Partnership on AI' formed by Google, DeepMind, Facebook, Amazon, IBM and Microsoft &#124; Technology |work=The Guardian |url=https://www.theguardian.com/technology/2016/sep/28/google-facebook-amazon-ibm-microsoft-partnership-on-ai-tech-firms |accessdate=2016-09-29}}</ref><ref>{{cite news |last=Waters |first=Richard |date=2016-09-29 |title=AI is 'Next Big Thing' to worry about |publisher=Financial Times |url=https://www.ft.com/content/c2c739d0-8661-11e6-8897-2359a58ac7a5 |accessdate=2016-09-29}}</ref><ref>{{cite news |last=Bindi |first=Tas |date=2016-09-29 |title=Amazon, Google, Facebook, IBM, and Microsoft form AI non-profit |publisher=ZDNet |url=http://www.zdnet.com/article/amazon-google-facebook-ibm-and-microsoft-form-ai-non-profit/ |accessdate=2016-09-29}}</ref><ref>{{cite news |last1=Rubin |first1=Ben Fox |last2=Cheng |first2=Roger |date=2016-09-29 |title=The AI Super Friends assemble! (The 3:59, Ep. 115) |publisher=CNET |url=https://www.cnet.com/news/the-ai-super-friends-assemble-the-359-ep-115/ |url-status=dead |accessdate=2016-09-29 |archive-url=https://web.archive.org/web/20160930185512/https://www.cnet.com/news/the-ai-super-friends-assemble-the-359-ep-115/ |archive-date=2016-09-30}}</ref> More than 100 partners from academia, civil society, industry, and nonprofits are member organizations in 2019.<ref>{{Cite web |date=24 September 2019 |title=New Partners To Bolster Perspective For Responsible AI |url=https://www.partnershiponai.org/new-partners-to-bolster-perspective-for-responsible-ai/}}</ref>

In January 2017, [[Apple Inc.|Apple]] head of advanced development for [[Siri]], [[Tom Gruber]], joined the Partnership on AI's board.<ref>{{Cite news |last=Tilley |first=Aaron |date=January 27, 2017 |title=Why Apple Joined Rivals Amazon, Google, Microsoft In AI Partnership |newspaper=Forbes |url=https://www.forbes.com/sites/aarontilley/2017/01/27/why-apple-joined-rivals-amazon-google-microsoft-in-ai-partnership/#257a251b3042 |access-date=2017-02-02}}</ref> In October 2017, [[Terah Lyons]] joined the Partnership on AI as the organization's founding executive director.<ref>{{Cite news |date=2017-10-17 |title=Partnership on AI Announces Executive Director Terah Lyons and Welcomes New Partners - The Partnership on AI |language=en-US |work=The Partnership on AI |url=https://www.partnershiponai.org/partnership-on-ai-announces-executive-director-terah-lyons-and-welcomes-new-partners/ |access-date=2018-09-10}}</ref> Lyons brought to the organization her expertise in technology governance, with a specific focus in machine intelligence, AI, and robotics policy, having formerly served as Policy Advisor to the United States Chief Technology Officer [[Megan Smith]]. Lyons was succeeded by Partnership on AI board member Rebecca Finlay as interim executive director. Finlay was named CEO of Partnership on AI on October 26, 2021.

In October 2017, [[Terah Lyons]] joined the Partnership on AI as the organization's founding executive director. Lyons brought to the organization her expertise in technology governance, with a specific focus in machine intelligence, AI, and robotics policy, having formerly served as Policy Advisor to the United States Chief Technology Officer [[Megan Smith]]. Lyons was succeeded by Partnership on AI board member Rebecca Finlay as interim executive director. Finlay was named CEO of Partnership on AI on October 26, 2021.

In October 2018, [[Baidu]] became the first Chinese firm to join the Partnership.<ref>{{Cite news |last=Taylor |first=Chloe |date=2018-10-17 |title=Baidu becomes the first Chinese firm to join US-led A.I. body |work=CNBC |url=https://www.cnbc.com/2018/10/17/baidu-becomes-the-first-chinese-firm-to-join-us-led-ai-body.html |url-status=live |access-date=2018-10-17 |archive-url=https://web.archive.org/web/20181103192645/https://www.cnbc.com/2018/10/17/baidu-becomes-the-first-chinese-firm-to-join-us-led-ai-body.html |archive-date=November 3, 2018}}</ref>

In November 2020 the Partnership on AI announced the [[AI Incident Database]] (AIID),<ref name="PartnershipOnAI2020">
{{cite web |last=McGregor |first=Sean |date=2020-11-18 |title=When AI Systems Fail: Introducing the AI Incident Database |url=https://www.partnershiponai.org/aiincidentdatabase/ |access-date=2020-11-21 |website=partnershiponai.org |publisher=Partnership on AI |quote=Avoiding repeated AI failures requires making past failures known. Therefore, today we introduce a systematized collection of incidents where intelligent systems have caused safety, fairness, or other real-world problems: The AI Incident Database (AIID).}}
</ref> which is a tool to identify, assess, manage, and communicate AI risk and harm.

In August 2021, the Partnership on AI submitted a response to the National Institute of Standards and Technology (NIST). The response provided examples of PAI’s work related to AI risk management, such as the Safety Critical AI report on responsible publication of AI research, the ABOUT ML project on documentation and transparency in machine learning lifecycles, and the AI Incident Database. <ref>{{Cite web |last=Hongo |first=Hudson |date=2021-10-01 |title=PAI Submits Response to NIST's Request for Information on AI Risk Management Framework |url=https://partnershiponai.org/pai-nist-framework-response/ |access-date=2023-12-05 |website=Partnership on AI |language=en-US}}</ref>The response also highlighted how the AI Incident Database involves some of the minimum attributes in NIST’s AI RMF, such as being consensus-driven, risk-based, adaptable, and consistent with other approaches to managing AI risk. <ref>{{Cite web |last=Hongo |first=Hudson |date=2021-10-01 |title=PAI Submits Response to NIST's Request for Information on AI Risk Management Framework |url=https://partnershiponai.org/pai-nist-framework-response/ |access-date=2023-12-05 |website=Partnership on AI |language=en-US}}</ref>

On October 26, 2021, Rebecca Finlay was named CEO.<ref>{{Cite web |date=2021-10-26 |title=Rebecca Finlay named as CEO: A Letter from Eric Horvitz, Chair of the Board of Directors |url=https://partnershiponai.org/rebecca-finlay-named-as-ceo-a-letter-from-eric-horvitz-chair-of-the-board-of-directors/ |access-date=2022-03-18 |website=Partnership on AI |language=en-US}}</ref>

In February 2023, the Partnership on AI (PAI) launched a novel framework aimed at guiding the ethical development and use of synthetic media. This initiative was backed by a variety of initial partners, including notable entities such as Adobe, BBC, CBC/Radio-Canada, Bumble, OpenAI, TikTok, WITNESS, and synthetic media startups Synthesia, D-ID, and Respeecher. The framework, which emphasizes transparency, creativity, and safety, was the result of a year-long collaborative process involving contributions from a wide range of stakeholders, including synthetic media startups, social media platforms, news organizations, advocacy groups, academic institutions, policy professionals, and public commenters.<ref>{{Cite web |last=Sosa |first=Penelope |date=2023-02-27 |title=Industry Leaders and Advocates Launch Framework for Responsible Use of AI-Generated Media |url=https://partnershiponai.org/industry-leaders-launch-framework-for-responsible-use-of-ai-generated-media/ |access-date=2023-12-05 |website=Partnership on AI |language=en-US}}</ref>

== Mission and Principles ==
Partnership on AI has a multiple pronged approach to achieve impact. Their initiatives are separated into five different programs: AI and media integrity; AI, work, and the economy; justice, transparency, and accountability; inclusive research and design; and security for AI. These programs aim to produce value through specific outputs, methodological tools, and articles.<ref>{{Cite web |title=OSF |url=https://osf.io/preprints/osf/sj2z5 |access-date=2023-12-06 |website=osf.io}}</ref>

Through the program on AI & Media Integrity, PAI actively endeavors to establish best practices that ensure AI's positive influence on the global information ecosystem. Recognizing the potential for AI to facilitate harmful online content and amplify existing negative narratives, PAI is committed to mitigating these risks and fostering a responsible AI presence.<ref>{{Cite web |title=AI & Media Integrity |url=https://partnershiponai.org/program/ai-media-integrity/ |access-date=2023-12-06 |website=Partnership on AI |language=en-US}}</ref>

The AI, Labor, and the Economy program serves as a collaborative platform, uniting economists, worker representative organizations, and PAI's partners to formulate a cohesive response on how AI can contribute to an inclusive economic future. The recent release of PAI's "Guidelines for AI and Shared Prosperity" on June 7th, 2023, outlines a blueprint for the judicious use of AI across various stages, guiding organizations, policymakers, and labor entities.<ref>{{Cite web |title=AI, Labor, and the Economy |url=https://partnershiponai.org/program/ai-labor-and-the-economy/ |access-date=2023-12-06 |website=Partnership on AI |language=en-US}}</ref>

The Fairness, Transparency, and Accountability program, in conjunction with the Inclusive Research & Design program, strives to reshape the AI landscape towards justice and fairness. By exploring the intersections between AI and fundamental human values, the former establishes guidelines for algorithmic equity, explainability, and responsibility. Simultaneously, the latter empowers communities by providing guidelines on co-creating AI solutions, fostering inclusivity throughout the research and design process.<ref>{{Cite web |title=Fairness, Transparency, and Accountability & ABOUT ML |url=https://partnershiponai.org/program/fairness-transparency-and-accountability-about-ml/ |access-date=2023-12-06 |website=Partnership on AI |language=en-US}}</ref><ref>{{Cite web |title=Inclusive Research & Design |url=https://partnershiponai.org/program/inclusive-research-design/ |access-date=2023-12-06 |website=Partnership on AI |language=en-US}}</ref>

The Safety Critical AI program addresses the growing deployment of AI systems in pivotal sectors like medicine, finance, transportation, and social media. With a focus on anticipating and mitigating potential risks, the program brings together partners and stakeholders to develop best practices that span the entire AI research and development lifecycle. Notable initiatives include the establishment of the AI incident Database, formulation of norms for responsible publication, and the creation of the innovative AI learning environment SafeLife.<ref>{{Cite web |title=Safety Critical AI |url=https://partnershiponai.org/program/safety-critical-ai/ |access-date=2023-12-06 |website=Partnership on AI |language=en-US}}</ref>

The association is also built of thematic foundations that drive Partnership on AI's focus. Atop the programs mentioned above, Partnership on AI looks to expand upon the social impact of AI, encouraging positive social utility. The organization has highlighted potential benefits of AI within public welfare, education, sustainability, etc. With these specific use cases, Partnership on AI is developing an ethical framework in which to analyze and AI's measure of ethical efficacy. The ethical framework places an emphasis on inclusive participatory practices that enhance equity in AI. <ref>{{Cite web |title=OSF |url=https://osf.io/sj2z5/ |access-date=2023-12-06 |website=osf.io |doi=10.31219/osf.io/sj2z5}}</ref>

== Programs and initiatives ==
The Partnership on AI has been involved in several initiatives aimed at promoting the responsible use of AI. One of their key initiatives is the development of a framework for the safe deployment of AI models. This framework guides model providers in developing and deploying AI models in a manner that ensures safety for society and can adapt to evolving capabilities and uses.<ref>{{Cite web |title=PAI’s Guidance for Safe Foundation Model Deployment |url=https://partnershiponai.org/modeldeployment/ |access-date=2023-12-03 |website=Partnership on AI |language=en-US}}</ref>

In collaboration with DeepMind, the Partnership on AI has also launched a study to investigate the high attrition rates among women and minoritized individuals in tech.<ref>{{Cite web |date=2021-01-30 |title=Investigating Challenges to Diversity in AI |url=https://partnershiponai.org/resource/investigating-challenges-to-diversity-in-ai/ |access-date=2023-12-03 |website=Partnership on AI |language=en-US}}</ref>

Recognizing the importance of explainability in AI, the Partnership on AI hosted a one-day, in-person workshop focused on the deployment of “explainable artificial intelligence” (XAI). This event brought together experts from various industries to discuss and explore the concept of XAI.<ref>{{Cite web |date=2021-01-30 |title=Convening Across Industries |url=https://partnershiponai.org/resource/convening-across-industries/ |access-date=2023-12-03 |website=Partnership on AI |language=en-US}}</ref>
[[File:AI_for_Good_Global_Summit_2018_(41408771354).jpg|thumb|409x409px|Terah Lyons, Executive Director, Partnership on AI speaking at the AI for Good Global Summit 2018 15-17 May 2018, Geneva]]
In an effort to support information integrity, the Partnership on AI collaborated with First Draft to investigate effective strategies for addressing deceptive content online.<ref>{{Cite web |date=2021-01-30 |title=Taking a Methodical Approach to Best Practices |url=https://partnershiponai.org/resource/taking-a-methodical-approach-to-best-practices/ |access-date=2023-12-03 |website=Partnership on AI |language=en-US}}</ref> This initiative reflects the organization’s methodical approach to identifying and promoting best practices in AI.

The Partnership on AI is also creating resources to facilitate effective engagement between AI practitioners and impacted communities. <ref>{{Cite web |title=Inclusive Research & Design |url=https://partnershiponai.org/program/inclusive-research-design/ |access-date=2023-12-03 |website=Partnership on AI |language=en-US}}</ref>

In November 2020, the Partnership on AI announced the AI Incident Database (AIID), a project dedicated to indexing the collective history of harms or near harms realized in the real world by the deployment of artificial intelligence systems. The AIID, which shifted to a new special-purpose independent non-profit in 2022, serves as a valuable resource for understanding and mitigating the potential risks associated with AI.<ref>{{Cite web |title=AI Incidents Database |url=https://partnershiponai.org/workstream/ai-incidents-database/ |access-date=2023-12-03 |website=Partnership on AI |language=en-US}}</ref>

Most recently, PAI conducted the PAI's 2023 Policy Forum. This event, held in London, was a gathering of diverse stakeholders to explore recent trends in AI policy globally and strategies for ensuring AI safety. During the event, the Partnership on AI (PAI) unveiled their "Guidance for Safe Foundation Model Deployment" for public feedback. This guidance, shaped by the Safety Critical AI Steering Committee and contributions from PAI's worldwide network, offers flexible principles for managing risks linked to large-scale AI implementation. Participants included policymakers, AI professionals, philanthropy and civil society members, and academic experts. <ref>{{Cite web |title=PAI's 2023 Policy Forum - YouTube |url=https://www.youtube.com/playlist?list=PLDOvLcRogwzdTa3M8KRf2ju8g80BWgL3C |access-date=2023-12-05 |website=www.youtube.com}}</ref>

== Partners and members ==
The Board of Directors of the Partnership on AI (PAI) as of 2023 includes:

* Jatin Aythora, Vice-Chair of the Board, representing [[BBC Research & Development]].<ref name=":0">{{Cite web |title=Our Team |url=https://partnershiponai.org/team/ |access-date=2023-12-05 |website=Partnership on AI |language=en-US}}</ref>
* Ben Coppin from [[Google DeepMind|DeepMind]].<ref name=":0" />
* William Covington, Board Secretary, affiliated with the [[University of Washington School of Law]].<ref name=":0" />
* Jerremy Holland, Chair of the Board, from [[Apple Inc.|Apple]].<ref name=":0" />
* Eric Horvitz, Board Chair Emeritus, representing [[Microsoft]].<ref name=":0" />
* Angela Kane, Board Treasurer, associated with the Vienna Center for Disarmament and Non-Proliferation.<ref name=":0" />
* Lama Nachman from [[Intel|Intel Labs]].<ref name=":0" />
* Joelle Pineau, Vice-Chair of the Board, representing [[Meta Platforms|Meta]].<ref name=":0" />
* Francesca Rossi, Chair of the Audit Committee, from [[IBM]].<ref name=":0" />
* Eric Sears representing the [[MacArthur Foundation|John D. and Catherine T. MacArthur Foundation]].<ref name=":0" />
* Brittany Smith from [[OpenAI]].<ref name=":0" />
* Martin Tisné from AI Collaborative.<ref name=":0" />
* Nicol Turner Lee representing the [[Brookings Institution|Brookings Institute]].<ref name=":0" />

== Criticisms ==
In October 2020, Access Now, announced its official resignation from PAI in a letter. Access Now stated that it had found that there was an increasingly smaller role for civil society to play within PAI and that PAI had not influenced or changed the attitude of member companies or encouraged them to respond to or consult with civil society on a systematic basis. Access Now also expressed its disagreement with PAI’s approach to AI ethics and risk assessment, and its advocacy for an outright ban on technologies that are fundamentally incompatible with human rights, such as facial recognition or other biometric technologies that enable mass surveillance.<ref>{{Cite web |title=Access Now resigns from the Partnership on AI |url=https://www.accessnow.org/press-release/access-now-resignation-partnership-on-ai/ |access-date=2023-12-05 |website=Access Now |language=en}}</ref>

== References ==
{{reflist}}

==External links==
* {{Official website|http://www.partnershiponai.org/}}
* The [https://incidentdatabase.ai/ AI Incident Database]

[[Category:Artificial intelligence associations]]
[[Category:Organizations established in 2016]]
[[Category:Existential risk from artificial general intelligence]]


{{International-org-stub}}