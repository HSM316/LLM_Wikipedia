{{AFC submission|d|reason|You're aiming at a very general article, and what you have written so far is just the introductory paragraph.   
I suggest you wait until you can develop it--you need good, preferably major magazine and book references on the general concept. Anf then you need a paragraph about each part. My advice is not to do it all at once, but make a somewhat better referenced article & resubmit.|u=Yuli Ban|ns=118|decliner=DGG|declinets=20191016005656|ts=20191008173046}} <!-- Do not remove this line! -->

'''Media synthesis''' (also known as '''synthetic media''', '''personalized media''', and '''AI-generated media''', and often colloquially referred to as "'''deepfakes''' of a particular area of media") is the artificial production and manipulation of media by [[automation|automated]] means, especially through the use of [[artificial intelligence]].<ref>{{Cite web | url=https://www.lesswrong.com/posts/q4vQLfqnv2C2KCoA3/on-media-synthesis-an-essay-on-the-next-15-years-of-creative |title = On Media Synthesis: An Essay on the Next 15 Years of Creative Automation - LessWrong 2.0}}</ref>. As a phrase, media synthesis is an umbrella term for an entire family of interrelated techniques, such as [[deepfakes]], [[image synthesis]], [[speech synthesis]], [[natural-language generation]], [[procedural generation]], and more, and generally refers to the use of artificial neural networks for these purposes: individual methods such as deepfakes and text synthesis are not usually referred to as "media synthesis" but instead by their respective terminology (and often generally as the "deepfakes" of a particular area, e.g. "deepfakes for text" for natural-language generation; "deepfakes for voices" for neural voice cloning, etc.). Media synthesis as a field has grown rapidly since the creation of [[generative adversarial networks]], primarily through the rise of music synthesis <ref>{{Cite web | url=https://www.theverge.com/2018/8/31/17777008/artificial-intelligence-taryn-southern-amper-music |title = How AI-generated music is changing the way hits are made|date = 2018-08-31}}</ref>, text generation <ref>{{Cite web | url=https://openai.com/blog/better-language-models/ |title = Better Language Models and Their Implications|date = 2019-02-14}}</ref>, and deepfakes <ref>{{Cite web | url=https://mashable.com/2018/02/02/what-are-deepfakes/ | title=A guide to 'deepfakes,' the internet's latest moral crisis}}</ref>. Media synthesis is an applied form of [[computational creativity]].

== Outline ==

'''Media''' are the [[communication]] outlets or tools used to [[Document|store]] and deliver [[information]] or [[data]].<ref>{{cite web |url=http://www.businessdictionary.com/definition/media.html |title=What is media? definition and meaning |work=BusinessDictionary.com}}</ref><ref>{{cite web|url=http://www.techopedia.com/definition/14462/communication-media |title=What is Communication Media? - Definition from Techopedia|author=Cory Janssen|work=Techopedia.com}}</ref> The term refers to components of the [[mass media]] communications industry, such as [[print media]], [[publishing]], the [[news media]], [[photography]], [[Movie theater|cinema]], [[broadcasting]] (radio and television), and [[advertising]].<ref>{{cite book|title=New Media: A Critical Introduction |url=http://www.philol.msu.ru/~discours/images/stories/speckurs/New_media.pdf |edition=2nd |author1=Martin Lister|author2=Jon Dovey|author3=Seth Giddings |author4=Iain Grant |author5=Kieran Kelly}}</ref> Interactive media such as [[video games]] and [[computer simulation|simulations]] also qualify under the label. 

The [[Digital Revolution|digitalization of data]] has allowed for creators and artists to develop media on a mass scale while also opening up avenues to alter media via altering the fundamental data with which it is made. Thus, media synthesis represents a form of [[automation]] of the media creation process.

== History ==

===Pre-1950s===
[[File:Maillardet's automaton at the Franklin Institute.webm|thumb|[[Maillardet's automaton]] is drawing a picture]]
Media synthesis as a process of automated art dates back to the [[Automaton|automata]] of [[Hellenistic civilization|ancient Greek civilization]], where inventors such as [[Daedalus]] and [[Hero of Alexandria]] designed machines capable of writing text, generating sounds, and playing music.<ref>{{citation |title=A programmable robot from 60 AD |author=Noel Sharkey|publisher=New Scientist|url=https://www.newscientist.com/blog/technology/2007/07/programmable-robot-from-60ad.html|date= July 4, 2007 |volume=2611}}</ref><ref>{{Citation | doi = 10.2307/2846790 | issn = 0038-7134 | volume = 29 | issue = 3 | pages = 477–487 | last = Brett | first = Gerard | title = The Automata in the Byzantine "Throne of Solomon" | journal = Speculum| date = July 1954 | postscript = . | jstor = 2846790 }}</ref> The tradition of automaton-based entertainment flourished throughout history, with mechanical beings' seemingly magical ability to mimic human creativity often drawing crowds throughout Europe<ref>{{cite web|url=https://www.youtube.com/watch?v=7YEPhe2Gp0Y|title=A Marvellous Elephant - Waddesdon Manor|last=Waddesdon Manor|date=22 July 2015|publisher=|via=YouTube}}</ref>, China<ref name=NYT>{{cite news|last=Kolesnikov-Jessop|first=Sonia|title=Chinese Swept Up in Mechanical Mania|url=https://www.nytimes.com/2011/11/26/fashion/26iht-ACAW-AUTOMATON26.html|accessdate=November 25, 2011|newspaper=The New York Times|date=November 25, 2011|quote=Mechanical curiosities were all the rage in China during the 18th and 19th centuries, as the Qing emperors developed a passion for automaton clocks and pocket watches, and the "Sing Song Merchants", as European watchmakers were called, were more than happy to encourage that interest.}}</ref>, India<ref name=Koetsier>{{cite journal |last1=Koetsier |first1=Teun  |year=2001 |title=On the prehistory of programmable machines: musical automata, looms, calculators |journal=Mechanism and Machine Theory |volume=36 |issue=5 |pages=589–603 |publisher=Elsevier |doi=10.1016/S0094-114X(01)00005-2}}</ref> , and so on.  Other automated novelties such as [[Johann Philipp Kirnberger]]'s "[[Musikalisches Würfelspiel]]" (Musical Dice Game) 1757 also amused audiences.<ref name="Algorithmic">Nierhaus, Gerhard (2009). ''Algorithmic Composition: Paradigms of Automated Music Generation'', pp. 36 & 38n7. {{ISBN|9783211755396}}.</ref>

Despite the technical capabilities of these machines, however, none were capable of generating original content and were entirely dependent upon their mechanical designs.

===Rise of artificial intelligence===
The field of AI research was born at [[Dartmouth workshop|a workshop]] at [[Dartmouth College]] in 1956,<ref name="Dartmouth conference">
[[Dartmouth Workshop|Dartmouth conference]]:
* {{Harvnb|McCorduck|2004|pp=111–136}}
* {{Harvnb|Crevier|1993|pp=47–49}}, who writes "the conference is generally recognized as the official birthdate of the new science."
* {{Harvnb|Russell|Norvig|2003|p=17}}, who call the conference "the birth of artificial intelligence."
* {{Harvnb|NRC|1999|pp=200–201}}
</ref>, begetting the rise of [[computer art | digital computing used as a medium of art]] as well as the rise of [[generative art]]. Initial experiments in AI-generated art included the '''''[[Illiac Suite]]''''', a 1957 composition for [[string quartet]] which is generally agreed to be the first score composed by an [[electronic music|electronic]] [[computer music|computer]].<ref name="Baggi">Denis L. Baggi, "[http://www.lim.dico.unimi.it/events/ctama/baggi.htm The Role of Computer Technology in Music and Musicology]", ''lim.dico.unimi.it'' (December 9, 1998).</ref> [[Lejaren Hiller]], in collaboration with [[Leonard Issacson]], programmed the [[ILLIAC I]] computer at the [[University of Illinois at Urbana–Champaign]] (where both composers were professors) to generate compositional material for his String Quartet No. 4.

In 1960, Russian researcher R.Kh.Zaripov published worldwide first paper on algorithmic music composing using the "[[Ural (computer)|Ural-1]]" computer.<ref>{{cite journal|last=Zaripov|first=R.Kh.|title=Об алгоритмическом описании процесса сочинения музыки (On algorithmic description of process of music composition)|journal=[[Proceedings of the USSR Academy of Sciences]]|year=1960|volume=132|issue=6}}</ref>

In 1965, inventor Ray Kurzweil premiered a piano piece created by a computer that was capable of pattern recognition in various compositions. The computer was then able to analyze and use these patterns to create novel melodies. The computer was debuted on Steve Allen's I've Got a Secret program, and stumped the hosts until film star Henry Morgan guessed Ray's secret.<ref>{{Cite web | url=http://www.kurzweiltech.com/raybio.html | title=About Ray Kurzweil}}</ref>

Before 1989, [[artificial neural network]]s have been used to model certain aspects of creativity. Peter Todd (1989) first trained a neural network to reproduce musical melodies from a training set of musical pieces. Then he used a change algorithm to modify the network's input parameters.  The network was able to randomly generate new music in a highly uncontrolled manner.<ref>{{cite journal | last1 = Bharucha | first1 = J.J. | last2 = Todd | first2 = P.M. | year = 1989 | title = Modeling the perception of tonal structure with neural nets | url = | journal = Computer Music Journal | volume = 13 | issue = 4| pages = 44–53 | doi=10.2307/3679552| jstor = 3679552 }}</ref><ref>Todd, P.M., and Loy, D.G. (Eds.) (1991). Music and connectionism. Cambridge, MA: MIT Press.</ref>

In 2014, [[Ian Goodfellow]] and his colleagues developed a new class of [[machine learning]] systems: '''[[generative adversarial networks]]''' ('''GAN''').<ref>{{cite conference|title=Generative Adversarial Networks|first1=Ian |last1=Goodfellow |first2=Jean |last2=Pouget-Abadie |first3=Mehdi |last3=Mirza |first4=Bing |last4=Xu |first5=David |last5=Warde-Farley |first6=Sherjil |last6=Ozair |first7=Aaron |last7=Courville |first8=Yoshua |last8=Bengio |conference= Proceedings of the International Conference on Neural Information Processing Systems (NIPS 2014) |pages= 2672–2680 |url= https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf |year=2014}}</ref> Two [[neural network]]s contest with each other in a game (in the sense of [[game theory]], often but not always in the form of a [[zero-sum game]]). Given a training set, this technique learns to generate new data with the same statistics as the training set. For example, a GAN trained on photographs can generate new photographs that look at least superficially authentic to human observers, having many realistic characteristics. Though originally proposed as a form of [[generative model]] for [[unsupervised learning]], GANs have also proven useful for [[semi-supervised learning]],<ref name="ITT_GANs">{{cite arXiv |eprint=1606.03498|title=Improved Techniques for Training GANs|last1=Salimans |first1=Tim |last2=Goodfellow |first2=Ian |last3=Zaremba |first3=Wojciech |last4=Cheung |first4=Vicki |last5=Radford |first5=Alec |last6=Chen |first6=Xi |class=cs.LG |year=2016}}</ref> fully [[supervised learning]],<ref>{{cite journal |last1=Isola |first1=Phillip |last2=Zhu |first2=Jun-Yan |last3=Zhou |first3=Tinghui |last4=Efros |first4=Alexei |title=Image-to-Image Translation with Conditional Adversarial Nets |journal=Computer Vision and Pattern Recognition |date=2017 |url=https://phillipi.github.io/pix2pix/}}</ref> and [[reinforcement learning]].<ref>{{cite journal |last1=Ho |first1=Jonathon |last2=Ermon |first2=Stefano |title=Generative Adversarial Imitation Learning |journal=Advances in Neural Information Processing Systems |pages=4565–4573 |url=http://papers.nips.cc/paper/6391-generative-adversarial-imitation-learning|year=2016 |arxiv=1606.03476 |bibcode=2016arXiv160603476H }}</ref> In a 2016 seminar, [[Yann LeCun]] described GANs as "the coolest idea in machine learning in the last twenty years".<ref>{{cite web |last1=LeCun |first1=Yann |title=RL Seminar: The Next Frontier in AI: Unsupervised Learning |url=https://www.youtube.com/watch?v=IbjF5VjniVE}}</ref>

== Branches of media synthesis ==

===Deepfakes===
{{main|Deepfake}}

'''Deepfakes''' (a [[portmanteau]] of "[[deep learning]]" and "fake"<ref name="FoxNews2018">{{Cite news |url=http://www.foxnews.com/tech/2018/02/16/terrifying-high-tech-porn-creepy-deepfake-videos-are-on-rise.html | title=Terrifying high-tech porn: Creepy 'deepfake' videos are on the rise | last=Brandon | first=John | date=2018-02-16 | work=Fox News | access-date=2018-02-20 | language=en-US}}</ref>) are media that take a person in an existing image or video and replace them with someone else's likeness using [[Artificial neural network|artificial neural networks]].<ref name=":3">{{cite web|url=https://www.vice.com/en_us/article/bjye8a/reddit-fake-porn-app-daisy-ridley|title=We Are Truly Fucked: Everyone Is Making AI-Generated Fake Porn Now|last=Cole|first=Samantha|date=24 January 2018|website=Vice|language=|archive-url=|archive-date=|url-status=|access-date=4 May 2019}}</ref> They often combine and superimpose existing media onto source media using [[machine learning]] techniques known as [[Autoencoder|autoencoders]] and [[generative adversarial network]]<nowiki/>s (GANs).<ref name="Schwartz">{{cite news | last1=Schwartz |first1=Oscar | title=You thought fake news was bad? Deep fakes are where truth goes to die |url=https://www.theguardian.com/technology/2018/nov/12/deep-fakes-fake-news-truth | accessdate=14 November 2018 | work=The Guardian | date=12 November 2018 |language=en}}</ref><ref name=":14">{{Cite web|url=https://towardsdatascience.com/family-fun-with-deepfakes-or-how-i-got-my-wife-onto-the-tonight-show-a4454775c011|title=Family fun with deepfakes. Or how I got my wife onto the Tonight Show|last=PhD|first=Sven Charleer|date=2019-05-17|website=Medium|language=en|access-date=2019-11-08}}</ref> Deepfakes have garnered widespread attention for their uses in [[Celebrity sex tape|celebrity pornographic videos]], [[revenge porn]], [[fake news]], [[Hoax|hoaxes]], and [[Accounting scandals|financial fraud]].<ref name="HighSnobiety2018">{{Cite news |url=https://www.highsnobiety.com/p/what-are-deepfakes-ai-porn/ | title=What Are Deepfakes & Why the Future of Porn is Terrifying | date=2018-02-20 | work=Highsnobiety | access-date=2018-02-20 | language=en-US}}</ref><ref>{{cite web|url=https://theoutline.com/post/3179/deepfake-videos-are-freaking-experts-out|title=Experts fear face swapping tech could start an international showdown|website=The Outline|language=en|access-date=2018-02-28}}</ref><ref>{{Cite news|url=https://www.nytimes.com/2018/03/04/technology/fake-videos-deepfakes.html|title=Here Come the Fake Videos, Too|last=Roose|first=Kevin|date=2018-03-04|work=The New York Times|access-date=2018-03-24|language=en-US|issn=0362-4331}}</ref><ref>{{cite document|title=Adversarial Learning of Deepfakes in Accounting|language=en|arxiv = 1910.03810|last1 = Schreyer|first1 = Marco|last2 = Sattarov|first2 = Timur|last3 = Reimer|first3 = Bernd|last4 = Borth|first4 = Damian|year = 2019|bibcode = 2019arXiv191003810S}}</ref> This has elicited responses from both industry and government to detect and limit their use.<ref name=":21">{{Cite web|url=https://deepfakedetectionchallenge.ai/|title=Join the Deepfake Detection Challenge (DFDC)|website=deepfakedetectionchallenge.ai|access-date=2019-11-08}}</ref><ref name=":5">{{Cite web|url=https://www.congress.gov/bill/116th-congress/house-bill/3230|title=H.R.3230 - 116th Congress (2019-2020): Defending Each and Every Person from False Appearances by Keeping Exploitation Subject to Accountability Act of 2019|last=Clarke|first=Yvette D.|date=2019-06-28|website=www.congress.gov|access-date=2019-10-16}}</ref>

The term deepfakes originated around the end of 2017 from a [[Reddit]] user named "deepfakes".<ref name=":3">{{cite web|url=https://www.vice.com/en_us/article/bjye8a/reddit-fake-porn-app-daisy-ridley|title=We Are Truly Fucked: Everyone Is Making AI-Generated Fake Porn Now|last=Cole|first=Samantha|date=24 January 2018|website=Vice|language=|archive-url=|archive-date=|url-status=|access-date=4 May 2019}}</ref> He, as well as others in the Reddit community r/deepfakes, shared deepfakes they created; many videos involved celebrities’ faces swapped onto the bodies of actresses in pornographic videos,<ref name=":3" /> while non-pornographic content included many videos with actor [[Nicolas Cage]]’s face swapped into various movies.<ref>{{cite web|url=https://mashable.com/2018/01/31/nicolas-cage-face-swapping-deepfakes/|title=People Are Using Face-Swapping Tech to Add Nicolas Cage to Random Movies and What Is 2018|last=Haysom|first=Sam|date=31 January 2018|website=Mashable|archive-url=|archive-date=|url-status=|access-date=4 April 2019}}</ref> In December 2017, Samantha Cole published an article about r/deepfakes in ''[[Vice Media|Vice]]'' that drew the first mainstream attention to deepfakes being shared in online communities.<ref name=":25">{{cite web|url=https://www.vice.com/en_us/article/gydydm/gal-gadot-fake-ai-porn|title=AI-Assisted Fake Porn Is Here and We're All Fucked|last=Cole|first=Samantha|date=11 December 2017|website=Vice|language=|archive-url=|archive-date=|url-status=|access-date=19 December 2018}}</ref> Six weeks later, Cole wrote in a follow-up article about the large increase in AI-assisted fake pornography.<ref name=":3" /> In February 2018, r/deepfakes was banned by Reddit for sharing involuntary pornography.<ref name="CNBC2018">{{Cite news|url=https://www.cnbc.com/2018/02/08/reddit-pornhub-ban-deepfake-porn-videos.html|title=Reddit, Pornhub ban videos that use A.I. to superimpose a person's face over an X-rated actor|last=Kharpal|first=Arjun|date=2018-02-08|work=CNBC|access-date=2018-02-20}}</ref> Other websites have also banned the use of deepfakes for involuntary pornography, including the social media platform [[Twitter]] and the pornography site [[Pornhub]].<ref name=":1">{{Cite web|url=https://www.vice.com/en_us/article/ywqgab/twitter-bans-deepfakes|title=Twitter Is the Latest Platform to Ban AI-Generated Porn|last=Cole|first=Samantha|date=2018-02-06|website=Vice|language=en|access-date=2019-11-08}}</ref> However, some websites have not yet banned Deepfake content, including 4chan and 8chan. <ref name=":4">{{cite web|url=https://www.dailydot.com/unclick/deepfake-sites-reddit-ban/|title=Here's where 'deepfakes,' the new fake celebrity porn, went after the Reddit ban|last=Hathaway|first=Jay|date=8 February 2018|website=The Daily Dot|language=|archive-url=|archive-date=|url-status=|access-date=22 December 2018}}</ref>
Other online communities remain, including Reddit communities that do not share pornography, such as r/SFWdeepfakes (short for "safe for work deepfakes"), in which community members share deepfakes depicting celebrities, politicians, and others in non-pornographic scenarios.<ref>{{cite web|url=https://www.reddit.com/r/SFWdeepfakes/|title=r/SFWdeepfakes|last=|first=|date=|website=Reddit|language=|archive-url=|archive-date=|url-status=|access-date=12 December 2018}}</ref> Other online communities continue to share pornography on platforms that have not banned deepfake pornography.<ref name=":4" />

===Image synthesis===

In terms of [[generative art]], image synthesis is the artificial production of visual media, especially through algorithmic means. One subfield of this includes [[human image synthesis]], which is the use of neural networks to make believable and even [[photorealism|photorealistic]] renditions<ref>[https://ieeexplore.ieee.org/document/568819 Physics-based muscle model for mouth shape control] on ''[[IEEE]] Explore'' (requires membership)</ref><ref>[https://ieeexplore.ieee.org/document/531968 Realistic 3D facial animation in virtual space teleconferencing] on ''[[IEEE]] Explore'' (requires membership)</ref> of human-likenesses, moving or still. It has effectively existed since the early [[2000s (decade)|2000s]]. Many films using [[computer generated imagery]] have featured synthetic images of human-like characters [[digital compositing|digitally composited]] onto the real or other simulated film material. Towards the end of the [[2010s (decade)|2010s]] [[deep learning]] [[artificial intelligence]] has been applied to synthesize images and video that look like humans, without need for human assistance, once the training phase has been completed, whereas the old school 7D-route required massive amounts of human work.The website This Person Does Not Exist showcases fully automated [[human image synthesis]] by endlessly generating images that look like facial portraits of human faces.<ref name="Style-based GANs – Generating and Tuning Realistic Artificial Faces">

{{Cite web 
|url=https://www.lyrn.ai/2018/12/26/a-style-based-generator-architecture-for-generative-adversarial-networks/ 
|title=Style-based GANs – Generating and Tuning Realistic Artificial Faces 
|last=Horev 
|first=Rani 
|date=2018-12-26 
|website=Lyrn.AI 
|access-date=2019-02-16
}}

</ref> The website was published in February 2019 by Phillip Wang. The technology has drawn comparison with [[deep fakes]]<ref name="This Person Does Not Exist Is the Best One-Off Website of 2019">

{{Cite web 
|last=Paez 
|first=Danny 
|date=2019-02-13
|title=This Person Does Not Exist Is the Best One-Off Website of 2019 
|url=https://www.inverse.com/article/53280-this-person-does-not-exist-gans-website
|website=[[Inverse (website)]] 
|access-date=2019-02-16
}}
</ref> and the [[Tell (poker)|tell]]s of [[Poker|poker]], and its potential usage for sinister purposes has been bruited.<ref name="'This Person Does Not Exist' Website Uses AI To Create Realistic Yet Horrifying Faces">
{{Cite web 
|url=https://tech.slashdot.org/story/19/02/14/199200/this-person-does-not-exist-website-uses-ai-to-create-realistic-yet-horrifying-faces 
|title='This Person Does Not Exist' Website Uses AI To Create Realistic Yet Horrifying Faces  
|last=msmash 
|first=n/a 
|date=2019-02-14 
|website=[[Slashdot]] 
|access-date=2019-02-16
}}
</ref>

===Photo manipulation===
{{Main|Photo manipulation|Image editing}}
'''Photo manipulation''' involves [[image editing|transforming or altering]] a [[photograph]] using various methods and techniques to achieve desired results.  Some photo manipulations are considered skillful artwork while others are frowned upon as unethical practices, especially when used to deceive the public.  Other examples include being used for political [[propaganda]], or to make a product or person look better, or simply for entertainment purposes or harmless pranks. 
Artificial neural networks used for image synthesizing projects can engage in digital [[inpainting]], where damaged, deteriorating, or missing parts of an artwork are reconstructed, can also be used for the opposite purpose: intelligently removing certain objects and subjects from an image without evidence of tampering.<ref>{{Cite web | url=https://www.digitaltrends.com/photography/nvidia-inpainting-ai-healing-brush-tool/ |title = Using A.I.-Based Brush, Removing Objects from Photos is No Biggie|date = 2018-04-24}}</ref> 

===Music generation===
{{main|Computer music|Music and artificial intelligence|Pop music automation}}

The capacity to generate music through autonomous, non-programmable means has long been sought after since the days of Antiquity, and with developments in artificial intelligence, two particular domains have arisen:
# The robotic creation of music, whether through machines playing instruments or sorting of virtual instrument notes (such as through [[MIDI]] files)
# Directly generating [[waveform | waveforms]] that perfectly recreate instrumentation and human voice without the need for instruments, MIDI, or organizing premade notes.

In 2016, [[Google DeepMind]] unveiled WaveNet, a deep generative model of raw audio waveforms that could learn to understand which waveforms best resembled human speech as well as musical instrumentation.<ref>{{Cite web | url=https://deepmind.com/blog/article/wavenet-generative-model-raw-audio |title = WaveNet: A Generative Model for Raw Audio}}</ref> Other networks capable of generating music through waveform manipulation include TacoTron (by Google) and DeepVoice (by Baidu).

===Speech synthesis===
{{main|Speech synthesis}}

Speech synthesis is the artificial production of human [[speech]]. A computer system used for this purpose is called a '''speech computer''' or '''speech synthesizer''', and can be implemented in [[software]] or [[Computer hardware|hardware]] products. A '''text-to-speech''' ('''TTS''') system converts normal language text into speech; other systems render [[symbolic linguistic representation]]s like [[phonetic transcription]]s into speech.<ref>{{Cite book |first1=Jonathan |last1=Allen |first2=M. Sharon |last2=Hunnicutt |first3=Dennis |last3=Klatt |title=From Text to Speech: The MITalk system |publisher=Cambridge University Press |year=1987 |isbn=978-0-521-30641-6 |url-access=registration |url=https://archive.org/details/fromtexttospeech00alle }}</ref>

Synthesized speech can be created by concatenating pieces of recorded speech that are stored in a [[database]]. Systems differ in the size of the stored speech units; a system that stores [[phone (phonetics)|phones]] or [[diphone]]s provides the largest output range, but may lack clarity. For specific usage domains, the storage of entire words or sentences allows for high-quality output. Alternatively, a synthesizer can incorporate a model of the [[vocal tract]] and other human voice characteristics to create a completely "synthetic" voice output.<ref>{{Cite journal | doi = 10.1121/1.386780 | last1 = Rubin | first1 = P. | last2 = Baer | first2 = T. | last3 = Mermelstein | first3 = P. | year = 1981 | title = An articulatory synthesizer for perceptual research | url = | journal = Journal of the Acoustical Society of America | volume = 70 | issue = 2| pages = 321–328 | bibcode = 1981ASAJ...70..321R }}</ref>

WaveNet, DeepMind's a deep generative model of raw audio waveforms, specialized on human speech.<ref>{{Cite web | url=https://deepmind.com/blog/article/wavenet-generative-model-raw-audio |title = WaveNet: A Generative Model for Raw Audio}}</ref> TacoTron is another network capable of generating believably-human speech.

===Audio synthesis===

Beyond music and human speech, generative networks are also capable of generating any conceivable sound that can be achieved through audio waveform manipulation, which might conceivably be used to generate stock audio of sound effects or simulate audio of currently imaginary things.

===Natural-language generation===
{{Main|Computational creativity#Story generation|Computational creativity#Poetry}}

[[Natural-language generation]] ('''NLG''', sometimes synonymous with '''text synthesis''') is a software process that transforms structured data into natural language.  It can be used to produce long form content for organizations to automate custom reports, as well as produce custom content for a web or mobile application. It can also be used to generate short blurbs of text in interactive conversations (a [[chatbot]]) which might even be read out  by a [[text-to-speech]] system. Interest in natural-language generation increased in 2019 after [[OpenAI]] unveiled GPT2, an AI system that generates text matching its input in subject and tone. GPT2 is a [[Transformer_(machine_learning_model)|transformer]], a [[Deep learning|deep]] [[machine learning]] model introduced in 2017 used primarily in the field of [[natural language processing]] (NLP).<ref>{{cite arxiv|last=Polosukhin|first=Illia|last2=Kaiser|first2=Lukasz|last3=Gomez|first3=Aidan N.|last4=Jones|first4=Llion|last5=Uszkoreit|first5=Jakob|last6=Parmar|first6=Niki|last7=Shazeer|first7=Noam|last8=Vaswani|first8=Ashish|date=2017-06-12|title=Attention Is All You Need|eprint=1706.03762|class=cs.CL}}</ref>

Natural-language generation alone theoretically can accomplish many other methods of media synthesis by way of generating binary code to create text, audio, and image files as a sort of applied undertaking of the [[Infinite monkey theorem]].

===Procedural graphics generation===

[[Procedural generation]] is a method of creating data [[algorithm]]ically as opposed to manually, typically through a combination of human-generated assets and algorithms coupled with computer-generated randomness and processing power. In [[computer graphics]], it is commonly used to create [[texture mapping|textures]] and [[3D models]]. In video games, it is used to automatically create large amounts of content in a game. Advantages of procedural generation include smaller file sizes, larger amounts of content, and randomness for less predictable gameplay.

== Practical applications ==

The first auction sale of artificial intelligence art was at [[Christie's|Christies Auction House]] in [[New York City|New York]]. The AI artwork sold for $432,500 which was almost 45 times higher than its estimate of $7,000-$10,000. The artwork was created by "Obvious", a [[Paris]]-based collective consisting of Hugo Caselles-Dupré, Pierre Fautrel and Gauthier Vernier.<ref name=christies/><ref name=bbc/><ref name=nytimes/><ref name=nytimes2/>

The company [[Narrative Science]] makes computer generated news and reports commercially available, including summarizing team sporting events based on statistical data from the game.  It also creates financial reports and real estate analyses.<ref>{{cite web|url=http://www.narrativescience.com/solutions.html |title=Archived copy |accessdate=2011-05-01 |url-status=dead |archiveurl=https://web.archive.org/web/20111103192105/http://www.narrativescience.com/solutions.html |archivedate=2011-11-03 }}</ref>

In 2018, GANs reached the [[mod (video gaming)|video game modding]] community, as a method of [[image scaling|up-scaling]] low-resolution 2D textures in old video games by recreating them in [[4K resolution|4k]] or higher resolutions via image training, and then down-sampling them to fit the game's native resolution (with results resembling the [[supersampling]] method of [[spatial anti-aliasing|anti-aliasing]]).<ref>{{cite news|last=Tang|first=Xiaoou|last2=Qiao|first2=Yu|last3=Loy|first3=Chen Change|last4=Dong|first4=Chao|last5=Liu|first5=Yihao|last6=Gu|first6=Jinjin|last7=Wu|first7=Shixiang|last8=Yu|first8=Ke|last9=Wang|first9=Xintao|date=2018-09-01|title=ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks|language=en|arxiv=1809.00219|bibcode=2018arXiv180900219W}}</ref> With proper training, GANs provide a clearer and sharper 2D texture image magnitudes higher in quality than the original, while fully retaining the original's level of details, colors, etc. Known examples of extensive GAN usage include [[Final Fantasy VIII]], [[Final Fantasy IX]], [[Resident Evil (2002 video game)|Resident Evil]] REmake HD Remaster, and [[Max Payne]].

On 30 April, 2019, the world’s first collection of images produced using AI was published through Amazon. The collection was produced by a UK based team "AIArtMedia". <ref name=aiartmedia/><ref name=amazon/>

== Concerns and Controversies ==

Deepfakes have been used to misrepresent well-known politicians in videos. In separate videos, the face of the Argentine President [[Mauricio Macri]] has been replaced by the face of [[Adolf Hitler]], and [[Angela Merkel]]'s face has been replaced with [[Donald Trump]]'s.<ref name=":0">{{cite web |title=Wenn Merkel plötzlich Trumps Gesicht trägt: die gefährliche Manipulation von Bildern und Videos |publisher=az Aargauer Zeitung |date=2018-02-03 |url=https://www.aargauerzeitung.ch/leben/digital/wenn-merkel-ploetzlich-trumps-gesicht-traegt-die-gefaehrliche-manipulation-von-bildern-und-videos-132155720}}</ref><ref>{{cite web |author=Patrick Gensing|url=http://faktenfinder.tagesschau.de/hintergrund/deep-fakes-101.html |title=Deepfakes: Auf dem Weg in eine alternative Realität? }}</ref>

{{Anchor|DeepNude}}In June 2019, a downloadable [[Windows]] and [[Linux]] application called DeepNude was released which used neural networks, specifically [[generative adversarial networks]], to remove clothing from images of women. The app had both a paid and unpaid version, the paid version costing $50.<ref>{{cite web |last1=Cole |first1=Samantha |last2=Maiberg |first2=Emanuel |last3=Koebler |first3=Jason |title=This Horrifying App Undresses a Photo of Any Woman with a Single Click |url=https://www.vice.com/en_us/article/kzm59x/deepnude-app-creates-fake-nudes-of-any-woman |website=Vice |accessdate=2 July 2019 |date=26 June 2019}}</ref><ref>{{cite news |url=https://www.vice.com/en_us/article/8xzjpk/github-removed-open-source-versions-of-deepnude-app-deepfakes |publisher=[[Vice Media]] |title=GitHub Removed Open Source Versions of DeepNude |first=Joseph |last=Cox |date=July 9, 2019}}</ref> On June 27 the creators removed the application and refunded consumers.<ref>{{Cite web|url=https://twitter.com/deepnudeapp/status/1144307316231200768|title=pic.twitter.com/8uJKBQTZ0o|date=27 June 2019}}</ref>

In 2019, voice deepfake technology was used to successfully impersonate a chief executive’s voice and demand a fraudulent transfer of €220,000.<ref>{{Cite web | url=https://www.wsj.com/articles/fraudsters-use-ai-to-mimic-ceos-voice-in-unusual-cybercrime-case-11567157402 | title=Fraudsters Used AI to Mimic CEO's Voice in Unusual Cybercrime Case}}</ref> The case raised concerns about the lack of encryption methods over telephones as well as the unconditional trust often given to voice and to media in general.<ref>{{Cite news | url=https://www.wsj.com/articles/ai-could-make-cyberattacks-more-dangerous-harder-to-detect-1542128667?mod=article_inline | title=AI Could Make Cyberattacks More Dangerous, Harder to Detect| newspaper=Wall Street Journal| date=2018-11-13| last1=Janofsky| first1=Adam}}</ref>

== Potential uses and impacts ==

Media synthesis techniques involve generating, manipulating, and altering [[data]] to emulate creative processes on a much faster and more accurate scale. As a result, the potential uses are as wide as human creativity itself, ranging from revolutionizing the [[Outline_of_entertainment#Mass_media_entertainment_industry|entertainment industry]] to accelerating the research and production of academia. Potential future hazards include the use of a combination of different subfields to generate [[fake news]]<ref>https://www.cnbc.com/2019/10/15/deepfakes-could-be-problem-for-the-2020-election.html</ref>, natural-language bot swarms generating trends and [[memes]], false evidence being generated, and potentially addiction to personalized content and a retreat into AI-generated fantasy worlds.

In 2019, Elon Musk warned of the potential use of advanced text-generating [[internet bot|bots]] to manipulate humans on social media platforms. <ref>{{Cite news|url=https://www.businessinsider.com/elon-musk-warns-of-advanced-ai-manipulating-social-media-2019-9|title=Elon Musk has warned that 'advanced AI' could poison social media|last=Hamilton|first=Isobel|date=2019-09-26}}</ref> In the future, even more advanced bots may be employed for means of [[astroturf|astroturfing]] apps, websites, and political movements, as well as supercharging [[internet meme|memes]] and cultural trends— including those generated for the sole purpose of being promoted by bots until humans perpetuate them without further assistance.

[[Deep reinforcement learning]]-based natural-language generators have the potential to be the first AI systems to pass the [[Turing Test]] and potentially be used as advanced chatbots<ref>https://dwjbosman.github.io/chatbot-using-open-ai-gpt-2-transformer-model</ref>, which may then be used to forge artificial relationships in a manner similar to the 2013 film ''[[Her_(film)|Her]]'' and [[spamming|spam]] believable comments on news articles.

One use case for natural-language generation is to generate or assist with writing novels and short stories<ref>https://www.theatlantic.com/technology/archive/2018/10/automated-on-the-road/571345/</ref>, while other potential developments are that of stylistic editors to emulate professional writers<ref>{{cite news|url=https://www.theatlantic.com/technology/archive/2018/10/automated-on-the-road/571345/ |first=Brian|last=Merchant |title=When an AI Goes Full Jack Kerouac |newspaper=[[The Atlantic]] |date=1 October 2018 |url-status=live}}</ref>. The same technique could then be used for songwriting, poetry, and technical writing, as well as rewriting old books in other authors' styles and generating conclusions to incomplete series.<ref>https://towardsdatascience.com/openai-gpt-2-writes-alternate-endings-for-game-of-thrones-c9be75cd2425</ref>
Furthermore, the ability to generate personalized content with no intent of being shared or with an extreme and usually unmarketable [[niche]] at any quality for virtually no price has the potential to lead to a breakdown in certain literary conventions, such as [[censorship]], [[dramatic structure]], conservation of detail (e.g. cutting out any detail in a story that does not immediately move a plot forward)<ref>https://thestorycoach.net/2017/07/21/the-law-of-conservation-of-detail-and-exceptions/</ref>, and [[demographic targeting|writing to a particular demographic]] or [[Commission_(art)|for a specific patron]] in projects that, without media synthesis methods, would require very large budgets to create (which would otherwise greatly increase the risks of defying such conventions). Conceivably, this will also work for visual and audio media as well.

Image synthesis tools may be able to streamline or even completely automate the creation of certain aspects of visual illustrations, such as [[animated cartoons]], [[comic books]], and [[political cartoons]].<ref>https://venturebeat.com/2017/06/02/pixar-veteran-creates-a-i-tool-for-automating-2d-animations/</ref> Because the automation process takes away the need for teams of designers, artists, and others involved in the making of entertainment, costs could plunge to virtually nothing and allow for the creation of "bedroom multimedia franchises" where singular people can generate results indistinguishable from the highest budget productions for little more than the cost of running their computer. Character and scene creation tools will no longer be based on premade assets, thematic limitations, or personal skill but instead based on tweaking certain parameters and giving enough input.

An increase in cyberattacks has also been feared due to methods of [[phishing]], [[catfishing]], and [[social hacking]] being automated by new technological methods.<ref>{{Cite news | url=https://www.wsj.com/articles/ai-could-make-cyberattacks-more-dangerous-harder-to-detect-1542128667?mod=article_inline | title=AI Could Make Cyberattacks More Dangerous, Harder to Detect| newspaper=Wall Street Journal| date=2018-11-13| last1=Janofsky| first1=Adam}}</ref>

Natural-language generation bots mixed with image synthesis networks may theoretically be used to clog search results, filling [[search engines]] with trillions of otherwise useless but legitimate-seeming blogs, websites, and marketing spam.<ref>https://www.theverge.com/2019/7/2/19063562/ai-text-generation-spam-marketing-seo-fractl-grover-google</ref>

There has been speculation about deepfakes being used for creating digital actors for future films. Digitally constructed/altered humans have already been used in [[Film|films]] before, and deepfakes could contribute new developments in the near future.<ref>{{Cite news|url=https://www.theguardian.com/film/2019/jul/03/in-the-age-of-deepfakes-could-virtual-actors-put-humans-out-of-business|title=In the age of deepfakes, could virtual actors put humans out of business?|last=Kemp|first=Luke|date=2019-07-08|work=The Guardian|access-date=2019-10-20|language=en-GB|issn=0261-3077}}</ref> Amateur deepfake technology has already been used to insert faces into existing films, such as the insertion of [[Harrison Ford]]'s young face onto Han Solo's face in [[Solo: A Star Wars Story|''Solo: A Star Wars Story'']],<ref>{{Cite web|url=https://www.polygon.com/2018/10/17/17989214/harrison-ford-solo-movie-deepfake-technology|title=Harrison Ford is the star of Solo: A Star Wars Story thanks to deepfake technology|last=Radulovic|first=Petrana|date=2018-10-17|website=Polygon|language=en|access-date=2019-10-20}}</ref> and techniques similar to those used by deepfakes were used for the acting of Princess Leia in ''[[Rogue One]].''<ref>{{Cite web|url=https://www.technologyreview.com/s/612241/how-acting-as-carrie-fishers-puppet-made-a-career-for-rogue-ones-princess-leia/|title=How acting as Carrie Fisher's puppet made a career for Rogue One's Princess Leia|last=Winick|first=Erin|website=MIT Technology Review|language=en-US|access-date=2019-10-20}}</ref>

In the future, video games may utilize media synthesis to perfect [[procedural generation|random asset creation and dialogue generation]], allowing for 100% freedom in gameplay and design or even for automatic video game generation. [[Image scaling|Upscaling]] and asset synthesis may be used to mod older games, adding features and mechanics that did not previously exist or bringing them up to modern standards. For example, a 2D game may be redone in 3D or vice versa without the need for lengthy asset design.

GANs can be used to create photos of imaginary fashion models, with no need to hire a model, photographer, makeup artist, or pay for a studio and transportation.<ref>{{cite web |last1=Wong |first1=Ceecee |title=The Rise of AI Supermodels |url=https://www.cdotrends.com/story/14300/rise-ai-supermodels |website=CDO Trends}}</ref> GANs can be used to create fashion advertising campaigns including more diverse groups of models, which may increase intent to buy among people resembling the models.<ref>{{cite web |last1=Dietmar |first1=Julia |title=GANs and Deepfakes Could Revolutionize The Fashion Industry |url=https://www.forbes.com/sites/forbestechcouncil/2019/05/21/gans-and-deepfakes-could-revolutionize-the-fashion-industry/#515624593d17 |work=Forbes}}</ref> GANs can also be used to create [https://www.artbreeder.com/ portraits, landscapes and album covers]. The ability for GANs to generate photorealistic human bodies presents a challenge to industries such as [[Model_(person)|fashion modeling]], which may be at heightened risk of being automated.<ref>https://research.zalando.com/welcome/mission/research-projects/generative-fashion-design/</ref><ref>https://syncedreview.com/2019/08/29/ai-creates-fashion-models-with-custom-outfits-and-poses/</ref>

A combination of natural-language generation and image synthesis may allow future users to turn any literary passage into a full-motion movie or comic, as well as vice versa.

Algorithmic direction can democratize the skill set needed to master the use of programs like [[Adobe Photoshop]] and [[Audacity_(audio_editor)|Audacity]], allowing for vastly easier and more streamlined image and audio manipulation at a much higher quality.

Musical artists and their respective brands may also conceivably be generated from scratch, including AI-generated music, videos, interviews, and promotional material. Conversely, existing music can be completely altered at will, such as changing lyrics, singers, instrumentation, and composition.<ref>https://www.theverge.com/2019/4/26/18517803/openai-musenet-artificial-intelligence-ai-music-generation-lady-gaga-harry-potter-mozart</ref>

Neural network-powered [[photo manipulation]] has the potential to reduce the ease by which [[totalitarian]] and [[absolutist]] regimes can engage in [[damnatio memoriae]]. A sufficiently paranoid totalitarian government or community may engage in a total wipe-out of history using all manner of media synthesis technologies, fabricating history and personalities as well as any evidence of their existence at all times. Even in otherwise rational and [[democracy|democratic]] societies, certain social and political groups may utilize media synthesis to craft cultural, political, and scientific cocoons that greatly reduce or even altogether destroy the ability of the public to agree on basic objective facts. Conversely, the existence of media synthesis will be used to discredit factual news sources and scientific facts as "potentially fabricated."

Theoretically, even [[Wikipedia]] may suffer from excesses of false evidence and facts being generated in an effort to write, rewrite, and [[censorship|censor]] articles.

==See also==

* [[Algorithmic art]]
* [[Artificial imagination]]
* [[Computational creativity]]
* [[Computer music]]
* [[Deepfakes]]
* [[Generative art]]
* [[Generative adversarial network]]
* [[Human image synthesis]]
* [[WaveNet]]

== References ==
<!-- Inline citations added to your article will automatically display here. See en.wikipedia.org/wiki/WP:REFB for instructions on how to add citations. -->
{{reflist|refs=
<ref name=christies>{{cite web
| url         = https://www.christies.com/features/A-collaboration-between-two-artists-one-human-one-a-machine-9332-1.aspx
| title       = Is artificial intelligence set to become art's next medium?
| date        = 2018-12-12
| website     = [[Christie's]]
| accessdate  = 2019-05-21}}</ref>
<ref name=bbc>{{cite web
| url         = https://www.bbc.co.uk/news/technology-45980863
| title       = Portrait by AI program sells for $432,000
| date        = 2018-10-25
| website     = [[BBC News]]
| accessdate  = 2019-05-21}}</ref>
<ref name=nytimes>{{cite web
| url         = https://www.nytimes.com/2018/10/25/arts/design/ai-art-sold-christies.html
| title       = AI Art at Christie's Sells for $432,500
| first       = Gabe
| last        = Cohn
| date        = 2018-10-25
| website     = [[New York Times]]
| accessdate  = 2019-05-21}}</ref>
<ref name=nytimes2>{{cite web
| url         = https://www.nytimes.com/2018/10/22/arts/design/christies-art-artificial-intelligence-obvious.html?module=inline
| title       = Up for Bid, AI Art Signed 'Algorithm'
| first       = Gabe
| last        = Cohn
| date        = 2018-10-22
| website     = [[New York Times]]
| accessdate  = 2019-05-21}}</ref>
<ref name=aiartmedia>{{cite web
| url         = https://aiartmedia.com/news/
| title       = Publication of First AI Art Collection Book
| date        = 2019-04-30
| website     = AIARTMEDIA
| accessdate  = 2019-05-21}}</ref>
<ref name=amazon>{{cite book
| title       = AI Art - Collection 1 - 800+ images created using Artificial Intelligence
| date        = 2019-04-30
|isbn = 978-1096289128|last1 = Breadon|first1 = Mark}}</ref>

}}

{{AFC submission|||ts=20191125193656|u=Yuli Ban|ns=118}}