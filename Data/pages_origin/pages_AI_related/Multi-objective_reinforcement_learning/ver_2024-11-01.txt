{{orphan|date=December 2019}}

'''Multi-objective reinforcement learning''' (MORL) is a form of [[reinforcement learning]] concerned with conflicting alternatives. It is distinct from [[multi-objective optimization]] in that it is concerned with agents acting in environments.<ref>{{cite journal |vauthors=Hayes C, Radulescu R, Bargiacchi E, et al |date= 2022 |title=A practical guide to multi-objective reinforcement learning and planning|journal= Autonomous Agents and Multi-Agent Systems |volume= 36|doi= 10.1007/s10458-022-09552-y|s2cid= 254235920 |doi-access= free|arxiv= 2103.09568}},</ref><ref>{{cite book |title=Multiple Attribute Decision Making: Methods and Applications |edition=1st |first1=Gwo-Hshiung |last1=Tzeng |first2=Jih-Jeng |last2=Huang |date=2011 |isbn=9781439861578}}</ref>

==References==
{{reflist}}

{{Compu-AI-stub}}

[[Category:Reinforcement learning]]