{{Short description|Parallel computing platform: GPGPU libraries and application programming interface}}
{{Use American English|date=December 2022}}
{{Use mdy dates|date=December 2022}}
{{Infobox software
| name = ROCm
| screenshot = 
| developer = [[AMD]]
| genre = [[GPGPU]] libraries and APIs
| released = {{Start date and age|2016|11|14}}
| latest_release_version = 5.3.0
| latest_release_date = {{Start date and age|2022|10|4}}<ref>{{cite web|url=https://github.com/RadeonOpenCompute/ROCm/releases/tag/rocm-5.3.0|title=ROCm 5.3 release|website=[[GitHub]] |date=October 4, 2022|access-date=October 10, 2022}}</ref>
| repo = [[#Official|Meta-repository]]<br />{{URL|https://github.com/radeonopencompute/rocm}}
| operating_system = [[Linux]], [[Windows]]
| platform = [[#Hardware support|Supported GPUs]]
| programming language = [[C (programming language)|C]], [[C++]], [[Python (programming language)|Python]], [[Fortran]], [[Julia (programming language)|Julia]]
| middleware = [[#HIP_-_Heterogeneous_Interface_for_Portability|HIP]]
| engine = [[#ROCk_-_Kernel_driver|AMDgpu]] [[kernel driver]], [[#HIPCC|HIPCC]], a [[LLVM]]-based [[compiler]]
| size = <2 [[Byte#Multiple-byte units|GiB]]
| replaces = [[Close to metal]], [[AMD Stream Processor#Software Development Kit|Stream]], [[Heterogeneous System Architecture|HSA]]
| license = [[Free and open-source software|Libre]]
| website = {{URL|https://www.amd.com/en/graphics/servers-solutions-rocm}}
}}

'''ROCm'''<ref>{{Cite web|url=https://github.com/RadeonOpenCompute/ROCm/issues/1628|title=Question: What does ROCm stand for? · Issue #1628 · RadeonOpenCompute/ROCm|website=Github.com|access-date=January 18, 2022}}</ref> is an [[Advanced Micro Devices]] (AMD) software stack for [[graphics processing unit]] (GPU) programming. ROCm spans several domains: [[general-purpose computing on graphics processing units]] (GPGPU), [[high performance computing]] (HPC), [[heterogeneous computing]]. It offers several programming models: [[#HIP_-_Heterogeneous_Interface_for_Portability|HIP]] ([[compute kernel|GPU-kernel-based programming]]), [[OpenMP]]/[[Message Passing Interface]] (MPI) ([[directive (programming)|directive-based programming]]), [[OpenCL]].

ROCm is free, libre and [[open-source software]] (except the GPU [[binary blob|firmware blobs]]<ref>{{Cite web|url=https://packages.debian.org/buster/firmware-amd-graphics|title=Debian -- Details of package firmware-amd-graphics in buster|website=Packages.debian.org|access-date=January 18, 2022}}</ref>), it is distributed under various licenses.

{{TOC limit|5}}

== Background ==
The first GPGPU software stack from [[ATI Technologies|ATI]]/AMD was [[Close to Metal]], which became [[AMD Stream Processor#Software Development Kit|Stream]].

ROCm was launched around 2016<ref>{{Cite web|url=https://www.anandtech.com/show/10831/amd-sc16-rocm-13-released-boltzmann-realized|title=AMD @ SC16: Radeon Open Compute Platform (ROCm) 1.3 Released, Boltzmann Comes to Fruition|website=anandtech.com|access-date=January 19, 2022}}</ref> with the [[GPUOpen#Radeon Open Compute (ROCm)|Boltzmann Initiative]].<ref>{{Cite web|url=https://www.anandtech.com/show/9792/amd-sc15-boltzmann-initiative-announced-c-and-cuda-compilers-for-amd-gpus|title=AMD @ SC15: Boltzmann Initiative Announced - C++ and CUDA Compilers for AMD GPUs|website=anandtech.com|access-date=January 19, 2022}}</ref> ROCm stack builds upon previous AMD GPU stacks, some tools trace back to [[GPUOpen]], others to the [[Heterogeneous System Architecture]] (HSA).

===Heterogeneous System Architecture===
HSA was aimed at producing a middle-level, hardware-agnostic intermediate representation, that could be JIT-compiled to the eventual hardware (GPU, FPGA...) using the appropriate finalizer. This approach was dropped for ROCm: now it builds only GPU code, using [[LLVM]], and its [[LLVM#Backend|AMDGPU backend]] that was upstreamed,<ref>{{Cite web|url=https://llvm.org/docs/AMDGPUUsage.html|title=User Guide for AMDGPU Backend — LLVM 13 documentation|website=Llvm.org|access-date=January 18, 2022}}</ref> although there is still research on such enhanced modularity with LLVM MLIR.<ref name="The LLVM Compiler Infrastructure">{{Cite web|url=https://github.com/ROCmSoftwarePlatform/llvm-project-mlir|title=The LLVM Compiler Infrastructure|website=[[GitHub]]|date=January 19, 2022}}</ref>

===Microsoft AMP C++ 1.2===

== Programming abilities ==
{{Expand section|date=January 2022|small=no}}
ROCm as a stack ranges from the kernel driver to the end-user applications.
AMD has introductory videos about AMD GCN hardware,<ref>{{Cite web|url=https://www.youtube.com/watch?v=uu-3aEyesWQ|title=Introduction to AMD GPU Hardware|via=www.youtube.com}}</ref> and ROCm programming<ref>{{Cite web|url=https://developer.amd.com/resources/rocm-learning-center/fundamentals-of-hip-programming/|title=Fundamentals of HIP Programming|website=AMD}}</ref> via its learning portal.<ref>{{Cite web|url=https://developer.amd.com/resources/rocm-learning-center/|title=ROCm™ Learning Center|website=AMD}}</ref>

One of the best technical introductions about the stack and ROCm/HIP programming, remains, to date, to be found on Reddit.<ref>{{Cite web|url=http://www.reddit.com/r/Amd/comments/a9tjge/amd_rocm_hcc_programming_introduction/|title=AMD ROCm / HCC programming: Introduction|date=December 26, 2018}}</ref>

===High-level programming===

===HIP programming===
====HIP(HCC) kernel language====
====Memory allocation====
=====NUMA=====
=====Heterogeneous Memory Model and Shared Virtual Memory=====

====ROCm code objects====
====Compute/Graphics interop====

===Low-level programming===

== Hardware support ==
ROCm is primarily targeted at discrete professional GPUs, but [https://docs.amd.com/bundle/ROCm-Getting-Started-Guide-v5.2.3/page/Introduction_to_AMD_ROCm_Getting_Started_Guide_for_Linux.html], but unofficial support includes Vega-family and RDNA2 consumer GPUs.

[[AMD Accelerated Processing Unit|Accelerated Processor Units]] (APU) are "enabled", but not officially supported. Having ROCm functional there is involved.<ref>{{Cite web|url=https://www.reddit.com/r/Amd/comments/rd7mmi/heres_something_you_dont_see_every_day_pytorch/|title = Here's something you don't see every day: PyTorch running on top of ROCm on a 6800M (6700XT) laptop! Took a ton of minor config tweaks and a few patches but it actually functionally works. HUGE!|date = December 10, 2021}}</ref>

{{See also|List of AMD graphics processing units}}

=== Professional-grade GPUs ===
[[AMD Instinct accelerators]] are the first-class ROCm citizens, alongside the [https://en.wiktionary.org/wiki/prosumer#Etymology_2 prosumer] [[Radeon Pro |Radeon Pro GPU series]]: they mostly see full support.

The only consumer-grade GPU that has relatively equal support is, as of January 2022, the Radeon VII (GCN 5 - Vega).

=== Consumer-grade GPUs ===
{| class="wikitable" style="font-size: 85%; text-align: center"
! Name of [[Graphics processing unit|GPU]] series
! [[Radeon HD 7000 Series|Southern<br />Islands]]
! [[AMD Radeon Rx 200 series|Sea<br />Islands]]
! [[AMD Radeon Rx 300 series|Volcanic<br />Islands]]
! [[AMD Radeon 400 series|Arctic<br />Islands/Polaris]]
! [[AMD RX Vega series|Vega]]
! [[AMD Radeon RX 5000 series|Navi 1X]]
! [[AMD Radeon RX 6000 series|Navi 2X]]
|- style="border-top:2px solid grey"
! {{rh}} | Released
| Jan 2012
| Sep 2013
| Jun 2015
| Jun 2016
| Jun 2017
| Jul 2019
| Nov 2020
|-
! {{rh}} | Marketing Name
| Radeon HD 7000
| Radeon Rx 200
| Radeon Rx 300
| Radeon RX 400/500
| Radeon RX Vega/Radeon VII(7&nbsp;nm)
| Radeon RX 5000
| Radeon RX 6000
|- 
! {{rh}} | AMD support
| colspan="3" {{na}} || colspan=4 {{ya|Current}}
|-
! {{rh}} | [[Instruction set]]
| colspan=5 | [[Graphics Core Next#Instruction set|GCN instruction set]]
| colspan=2 | [[RDNA (microarchitecture)#Instruction set|RDNA instruction set]]
|-
! {{rh}} | [[Microarchitecture]]
| [[Graphics Core Next#first|GCN 1st gen]]
| [[Graphics Core Next#second|GCN 2nd gen]] 
| [[Graphics Core Next#third|GCN 3rd gen]] 
| [[Graphics Core Next#fourth|GCN 4th gen]]
| [[Graphics Core Next#fifth|GCN 5th gen]]
| [[RDNA (microarchitecture)#Architecture|RDNA]]
| [[RDNA (microarchitecture)#RDNA 2|RDNA 2]]
|-
! {{rh}} | Type
| colspan="7" |[[Unified shader model]]

|- style="border-top:2px solid grey"
! {{rh}} | ROCm <ref>{{cite web |title=ROCm Getting Started Guide v5.2.3 | url=https://docs.amd.com/bundle/ROCm-Getting-Started-Guide-v5.2.3}}</ref>
| colspan=4 {{na}}
| colspan=1 {{ya}}
| colspan=1 {{na}}
| colspan=2 {{ya}}
|- 
! {{rh}} | [[OpenCL]]
|1.2 (on [[Linux]]: 1.1 (no Image support) with Mesa 3D)
| colspan=4 | 2.0 (Adrenalin driver on [[Windows 7|Win7+]])<br />(on [[Linux]]: 1.1 (no Image support) with Mesa 3D, 2.0 with AMD drivers or AMD ROCm)
| 2.0
| 2.1 <ref>{{cite web |title=AMD Radeon RX 6800 XT Specs |url=https://www.techpowerup.com/gpu-specs/radeon-rx-6800-xt.c3694 |website=TechPowerUp |access-date=January 1, 2021}}</ref>
|- 
! {{rh}} | [[Vulkan (API)|Vulkan]]
| 1.0<br />([[Windows 7|Win 7+]] or [[Mesa (computer graphics)|Mesa 17+]])
| colspan=6 | 1.2 (Adrenalin 20.1, Linux Mesa 3D 20.0)

|-
! {{rh}} | [[High-Level Shading Language#Shader model comparison|Shader model]]
| 5.1
| colspan=3 | 5.1<br />6.3
| colspan=2 | 6.4
| 6.5
|- 
! {{rh}} | [[OpenGL]]
| colspan=7 | 4.6 (on Linux: 4.6 (Mesa 3D 20.0))

|-
! {{rh}} | [[Direct3D]]
| 11 ([[Feature levels in Direct3D#Direct3D 11|11_1]])<br />12 ([[Feature levels in Direct3D#Direct3D 12|11_1]])
| colspan=3 | 11 ([[Feature levels in Direct3D#Direct3D 11|12_0]])<br />12 ([[Feature levels in Direct3D#Direct3D 12|12_0]])
| colspan=2 | 11 ([[Feature levels in Direct3D#Direct3D 11|12_1]])<br />12 ([[Feature levels in Direct3D#Direct3D 12|12_1]])
| 11 ([[Feature levels in Direct3D#Direct3D 11|12_1]])<br />12 ([[Feature levels in Direct3D#Direct3D 12|12_2]])

|- 
! {{rh}} class="table-rh" | <code>/drm/amdgpu</code>{{efn|name="drm"}}
| colspan=2 {{not yet|Experimental}}<ref>{{cite web |url=http://phoronix.com/scan.php?page=news_item&px=Linux-4.9-Kernel-Highlights |title=The Best Features of the Linux 4.9 Kernel |last=Larabel |first=Michael |date=December 7, 2016 |publisher=[[Phoronix]] |access-date=December 7, 2016}}</ref>
| colspan=5 {{ya}}
|}

{{notelist|refs=
{{efn|name="drm"|DRM ([[Direct Rendering Manager]]) is a component of the [[Linux kernel]].}}
}}

== Software ecosystem ==
=== Learning resources ===
{{Expand section|date=January 2022|small=no}}
AMD ROCm product manager gave a tour of the stack.<ref>{{cite web|url=https://www.hpcwire.com/2020/07/06/rocm-open-software-ecosystem-for-accelerated-compute/|title=ROCm presentation|website=HPCwire.com|date=July 6, 2020|access-date=January 18, 2022}}</ref>

=== Third-party integration ===
The main consumers of the stack are machine learning and high-performance computing/GPGPU applications.

==== Machine learning ====
Various Deep Learning frameworks have a ROCm backend:<ref name=infoq-mi200>{{Cite web|url=https://www.infoq.com/news/2021/12/amd-deep-learning-accelerator/|title=AMD Introduces Its Deep-Learning Accelerator Instinct MI200 Series GPUs|website=Infoq.com|access-date=January 18, 2022}}</ref>
* [[PyTorch]]
* [[TensorFlow]]
* [[Onnx|ONNX]]
* [[Apache MXNet|MXNet]]
* [[CuPy]]<ref>{{Cite web|url=https://docs.cupy.dev/en/latest/install.html#using-cupy-on-amd-gpu-experimental|title=Installation}}</ref>
* [https://github.com/rocmsoftwareplatform/miopen MIOpen]
* [[Caffe (software)|Caffe]]
* [https://github.com/google/iree Iree] (which uses LLVM Multi-Level Intermediate Representation (MLIR))

==== Supercomputing ====
ROCm is gaining significant traction in the [[TOP500|top 500]].<ref>{{Cite web|url=https://www.crn.com/news/components-peripherals/amd-chips-away-at-intel-in-world-s-top-500-supercomputers-as-gpu-war-looms|title = AMD Chips Away at Intel in World's Top 500 Supercomputers as GPU War Looms|date = November 16, 2020}}</ref>
ROCm is used with the Exascale supercomputers [[ElCapitan (supercomputer)|ElCapitan]]<ref>{{Cite web|url=https://www.anandtech.com/show/15581/el-capitan-supercomputer-detailed-amd-cpus-gpus-2-exaflops|title = El Capitan Supercomputer Detailed: AMD CPUs & GPUs to Drive 2 Exaflops of Compute}}</ref><ref>{{Cite web|url=https://www.hpcwire.com/2021/02/18/livermores-el-capitan-supercomputer-hpe-rabbit-storage-nodes/|title=Livermore's el Capitan Supercomputer to Debut HPE 'Rabbit' Near Node Local Storage|date=February 18, 2021}}</ref> and [[Frontier (supercomputer)|Frontier]].

Some related software is to be found at [https://www.amd.com/fr/technologies/infinity-hub AMD Infinity hub].

==== Other acceleration & graphics interoperation ====
As of version 3.0, [[Blender (software)|Blender]] can now use HIP compute kernels for its [[Rendering (computer graphics)|renderer]] Cycles.<ref>{{Cite web|url=https://gpuopen.com/blender-cycles-amd-gpu/|title=Blender 3.0 takes support for AMD GPUs to the next level. Beta support available now!|date=November 15, 2021|website=Gpuopen.com|access-date=January 18, 2022}}</ref>

==== Other Languages ====

===== Julia =====

[[Julia (programming language)|Julia]] has the AMDGPU.jl package,<ref>{{Cite web|url=https://juliagpu.org/rocm/|title=AMD ROCm ⋅ JuliaGPU|website=juliagpu.org}}</ref> which integrates with LLVM and selects components of the ROCm stack. Instead of compiling code through HIP, AMDGPU.jl uses Julia's compiler to generate LLVM IR directly, which is later consumed by LLVM to generate native device code. AMDGPU.jl uses ROCr's HSA implementation to upload native code onto the device and execute it, similar to how HIP loads its own generated device code.

AMDGPU.jl also supports integration with ROCm's rocBLAS (for BLAS), rocRAND (for random number generation), and rocFFT (for FFTs). Future integration with rocALUTION, rocSOLVER, MIOpen, and certain other ROCm libraries is planned.

=== Software distribution ===
==== Official ====
ROCm software is currently spread across dozens of public [[GitHub]] repositories. Within the main public [https://github.com/radeonopencompute/rocm meta-repository], there is an [https://github.com/RadeonOpenCompute/ROCm/blob/95493f625cadb3457cedb454e4ebd0df7b991443/default.xml xml manifest] for each official release: using [https://gerrit.googlesource.com/git-repo/ git-repo], a [[version control]] tool built on top of [[git]], is the recommended way to synchronize with the stack locally.<ref>{{Cite web|url=https://rocmdocs.amd.com/en/latest/Installation_Guide/Installation-Guide.html#getting-the-rocm-source-code|title=ROCm Installation v4.3 — ROCm 4.5.0 documentation|website=Rocmdocs.amd.com|access-date=January 18, 2022}}</ref>

The release of ROCm 5.1 is imminent, probably mid-February given a minor release each month.<ref name=infoq-mi200 />

{| class="wikitable"
|+
!Stack area
!Public GitHub organisation
|-
|Low-level (mostly)
|https://github.com/radeonopencompute
|-
|Mid-level (mostly)
|https://github.com/rocm-developer-tools
|-
|High-level (mostly)
|https://github.com/rocmsoftwareplatform/
|}
AMD starts distributing containerized applications for ROCm, notably scientific research applications gathered under [https://www.amd.com/en/technologies/infinity-hub AMD Infinity Hub].<ref>{{Cite web|url=https://www.hpcwire.com/2021/10/18/running-scientific-applications-on-amd-instinct-accelerators-just-got-easier|title=Running Scientific Applications on AMD Instinct Accelerators Just Got Easier|date=October 18, 2021|access-date=January 25, 2022|website=HPCwire.com}}</ref>

AMD [https://repo.radeon.com/rocm distributes itself] packages tailored to various Linux distributions.

{{See|AMD Radeon Software}}

==== Third-party ====
There is a growing [https://repology.org/projects/r/?search=rocm third-party ecosystem packaging ROCm].

Linux distributions are packaging officially (natively) ROCm, with various degrees of advancement: Arch,<ref>{{Cite web|url=https://github.com/rocm-arch/rocm-arch|title=ROCm for Arch Linux|date=January 17, 2022|access-date=January 18, 2022|website=Github.com}}</ref> Gentoo,<ref>{{Cite web|url=https://www.phoronix.com/scan.php?page=news_item&px=Gentoo-2021-Recap|title=Gentoo Linux Packages Up AMD ROCm, Makes Progress On RISC-V, LTO+PGO Python|website=Phoronix.com|access-date=January 18, 2022}}</ref> Debian and Fedora,<ref>{{Cite web|url=https://www.phoronix.com/scan.php?page=news_item&px=Fedora-Debian-ROCm-Work|title=Fedora & Debian Developers Look At Packaging ROCm For Easier Radeon GPU Computing Experience|website=Phoronix.com|access-date=January 18, 2022}}</ref> GNU Guix, NixOS.

There are spack packages.<ref>{{Cite web|url=https://github.com/spack/spack|title=The Spack Package Manager: Bringing Order to HPC Software Chaos|first1=Todd|last1=Gamblin|first2=Matthew|last2=LeGendre|first3=Michael R.|last3=Collette|first4=Gregory L.|last4=Lee|first5=Adam|last5=Moody|first6=Bronis R.|last6=de Supinski|first7=Scott|last7=Futral|date=November 15, 2015|via=GitHub}}</ref>

== Components ==
{{Expand section|date=January 2022|small=no}}
There is one kernel-space component, ROCk, and the rest - there is roughly a hundred components in the stack - is made of [[User space|user-space]] modules.

The unofficial typographic policy is to use: uppercase ROC lowercase following for low-level libraries, i.e. ROCt, and the contrary for user-facing libraries, i.e. rocBLAS.<ref>{{Cite mailing list|url=https://lists.debian.org/debian-ai/2021/12/msg00028.html|title=20211221 Packaging session notes and small update|mailing-list=debian-ai@lists.debian.org|last=Bloor|first=Cordell|language=english|access-date=January 18, 2022}}</ref>

AMD is active developing with the LLVM community, but upstreaming is not instantaneous, and as of January 2022, still lagging.<ref>{{Cite web|url=https://github.com/ROCm-Developer-Tools/HIP/issues/2449|title = &#91;Debian official packaging&#93; How is ROCm LLVM fork still needed? · Issue #2449 · ROCm-Developer-Tools/HIP|website = [[GitHub]]}}</ref> AMD still packages officially various LLVM forks<ref>{{Cite web|url=https://github.com/ROCm-Developer-Tools/aomp|title = Aomp - V 14.0-1|website = [[GitHub]]|date = January 22, 2022}}</ref><ref>{{Cite web|url=https://github.com/RadeonOpenCompute/llvm-project|title = The LLVM Compiler Infrastructure|website = [[GitHub]]|date = January 10, 2022}}</ref><ref name="The LLVM Compiler Infrastructure"/> for parts that are not yet upstreamed - compiler optimizations destined to remain proprietary, debug support, OpenMP offloading...

=== Low-level ===
==== ROCk - Kernel driver ====
{{Main|AMDgpu (Linux kernel module)}}

==== ROCm - Device libraries ====
[https://github.com/RadeonOpenCompute/ROCm-Device-Libs Support libraries] implemented as LLVM bitcode. These provide various utilities and functions for math operations, atomics, queries for launch parameters, on-device kernel launch, etc.

==== ROCt - Thunk ====
The [https://github.com/radeonopencompute/roct-thunk-interface thunk] is responsible for all the thinking and queuing that goes into the stack.

==== ROCr - Runtime ====
The [https://github.com/radeonopencompute/rocr-runtime ROC runtime] is different from the ROC Common Language Runtime in that it is not the same thing.

==== ROCm - CompilerSupport ====
[https://github.com/radeonopencompute/rocm-compilersupport ROCm code object manager] is in charge of interacting with LLVM [[intermediate representation]].

=== Mid-level ===
==== ROCclr Common Language Runtime ====
The [https://github.com/rocm-developer-tools/rocclr common language runtime] is an indirection layer adapting calls to ROCr on linux and PAL on windows.
It used to be able to route between different compilers like the HSAIL-compiler. It is now being absorbed by the upper indirection layers (HIP, OpenCL).

====OpenCL====
{{See|OpenCL}}
ROCm ships its Installable Client Driver ICD loader and an OpenCL<ref>{{Cite web|url=https://www.khronos.org/registry/OpenCL/|title=Khronos OpenCL Registry - The Khronos Group Inc|website=www.khronos.org}}</ref> [https://github.com/radeonopencompute/rocm-opencl-runtime implementation bundled together].
As of January 2022, ROCm 4.5.2 ships OpenCL 2.2, and is lagging behind competition.<ref>{{Cite web|url=https://www.khronos.org/conformance/adopters/conformant-products/opencl|title=List of OpenCL Conformant Products - The Khronos Group Inc|website=www.khronos.org|date=February 3, 2022}}</ref>

==== HIP - [https://github.com/rocm-developer-tools/hip Heterogeneous Interface for Portability] ====
The AMD implementation for its GPUs is called [https://github.com/ROCm-Developer-Tools HIPAMD]. There is also a [https://github.com/ROCm-Developer-Tools/HIP-CPU CPU implementation] mostly for demonstration purposes.

==== HIPCC ====
HIP builds a `HIPCC` compiler that either wraps [[Clang]] and compiles with LLVM open AMDGPU backend, or redirects to the [[Nvidia CUDA Compiler|NVIDIA compiler]].<ref>{{Cite web|url=https://www.researchgate.net/figure/HIPCC-compilation-process-illustration-The-clang-compiler-skips-the-step-to-generate-the_fig3_346904487|title = Figure 3. HIPCC compilation process illustration. The clang compiler}}</ref>

==== HIPIFY ====
[https://github.com/ROCm-Developer-Tools/HIPIFY HIPIFY] is a source-to-source compiling tool, it translates CUDA to HIP and reverse, either using a clang-based tool, or a sed-like Perl script.

==== GPUFORT ====
Like HIPIFY, [https://github.com/rocmsoftwareplatform/gpufort GPUFORT] is a tool compiling source code into other third-generation-language sources, allowing users to migrate from CUDA Fortran to HIP Fortran. It is also in the repertoire of research projects, even more so.<ref>{{Cite web|url=https://www.phoronix.com/scan.php?page=news_item&px=AMD-Radeon-GPUFORT|title = AMD Publishes Open-Source "GPUFORT" as Newest Effort to Help Transition Away from CUDA}}</ref>

=== High-level ===
ROCm high-level libraries are usually consumed directly by application software, such as [[machine learning]] frameworks. Most of the following libraries are in the [[General Matrix Multiply]] (GEMM) category, which GPU architecture excels at.

The majority of these user-facing libraries comes in dual-form: ''hip'' for the indirection layer that can route to Nvidia hardware, and ''roc'' for AMD implementation.<ref>
{{Cite conference
|url=https://www.olcf.ornl.gov/wp-content/uploads/2021/04/SPOCK_Libraries_profiling_JMaia.pdf
|title=ROCm Library Support & Profiling Tools
| last1 = Maia
| first1 = Julio 
| last2 = Chalmers
| first2 = Noel
| last3 = T. Bauman
| first3 = Paul
| last4 = Curtis
| first4 = Nicholas
| last5 = Malaya
| first5 = Nicholas
| last6 = McDougall
| first6 = Damon
| last7 = van Oostrum
| first7 = Rene
| last8 = Wolfe
| first8 = Noah
| date= May 2021
| publisher=AMD
}}</ref>

==== rocBLAS / hipBLAS ====
[https://github.com/rocmsoftwareplatform/rocblas rocBLAS] and [https://github.com/rocmsoftwareplatform/hipblas hipBLAS] are central in high-level libraries, it is the AMD implementation for [[Basic Linear Algebra Subprograms]].
It uses the library [https://github.com/ROCmSoftwarePlatform/Tensile Tensile] privately.

==== rocSOLVER / hipSOLVER ====
This pair of libraries constitutes the [[LAPACK]] implementation for ROCm and is strongly coupled to rocBLAS.

=== Utilities ===
* [https://github.com/orgs/ROCm-Developer-Tools ROCm developer tools]: Debug, tracer, profiler, System Management Interface, Validation suite, Cluster management.
* [https://github.com/GPUOpen-Tools GPUOpen tools]: GPU analyzer, memory visualizer...
* External tools: radeontop ([[Text-based user interface|TUI]] overview)

== Comparison with competitors ==
ROCm is a competitor to similar stacks aimed at GPU computing: Nvidia [[CUDA]] and [[OneAPI (compute acceleration)|Intel OneAPI]].

=== NVidia CUDA ===
{{Main|CUDA}}
Nvidia is close-source until cuBLAS and such high-level libraries.<br />
Nvidia vendors the Clang frontend and its [[Parallel Thread Execution]] (PTX) LLVM GPU backend as the [[Nvidia CUDA Compiler]] (NVCC).<br />
There is an open-source layer above it, for example [https://github.com/rapidsai RAPIDS].

=== Intel OneAPI ===
{{Main|OneAPI (compute acceleration)}}
{{Empty section|date=January 2022|small=no}}

==See also==
*[[AMD#Software|AMD Software]] – a general overview of AMD's drivers, APIs, and development endeavors. 
*[[GPUOpen]] – AMD's complementary graphics stack
*[[AMD Radeon Software]] – AMD's software distribution channel

==References==
{{Reflist}}

==External links==
* {{cite web|url=https://docs.amd.com|publisher=[[AMD]]|title=ROCm official documentation|date=February 10, 2022}}
* {{cite web|url=https://developer.amd.com/resources/rocm-learning-center/|publisher=[[AMD]]|title=ROCm Learning Center|date=January 25, 2022}}
* {{cite web|url=https://github.com/radeonopencompute/rocm|publisher=[[AMD]]|title=ROCm official documentation on the github super-project|date=January 25, 2022}}
* {{cite web|url=https://rocmdocs.amd.com/en/latest/index.html|publisher=[[AMD]]|title=ROCm official documentation - pre 5.0 |date=January 19, 2022}}
* {{cite web|url=https://www.amd.com/system/files/documents/gpu-accelerated-applications-catalog.pdf|publisher=[[AMD]]|title=GPU-Accelerated Applications with AMD Instinct Accelerators & AMD ROCm Software|date=January 25, 2022}}
* {{cite web|url=https://www.amd.com/fr/technologies/infinity-hub|publisher=[[AMD]]|title=AMD Infinity Hub|date=January 25, 2022}} — [[Docker (software)|Docker containers]] for scientific applications.

{{AMD}}
{{AMD technology}}
{{AMD graphics}}
{{Graphics Processing Unit}}
{{Parallel computing}}
{{Processor technologies}}
{{Numerical linear algebra}}
{{Portal bar|Computer programming|Free and open-source software|Linux|Engineering|Electronics|Technology|Mathematics}}
{{Authority control}}

[[Category:AMD software]]
[[Category:GPGPU]]
[[Category:GPGPU libraries]]
[[Category:Parallel computing]]
[[Category:Heterogeneous computing]]
[[Category:Concurrent computing]]
[[Category:Supercomputers]]
[[Category:Graphics hardware]]
[[Category:Graphics cards]]
[[Category:Application programming interfaces]]
[[Category:Machine learning]]