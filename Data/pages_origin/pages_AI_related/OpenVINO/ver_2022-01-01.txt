{{Short description|Toolkit for deploying inference neural network model on Intel hardware}}
{{Use dmy dates|date=March 2020}}
{{Infobox software
| title = 
| name = OpenVINO
| logo = <!-- Image name is enough -->
| logo size = 
| logo alt = 
| logo caption = 
| screenshot = <!-- Image name is enough -->
| screenshot size = 
| screenshot alt = 
| caption = 
| collapsible = 
| author = [[Intel Corporation]],
| developer = [[Intel Corporation]]
| released = {{Start date and age|2018|05|16}}
| discontinued = 
| latest release version = 2021.4.2
| latest release date = November 2021.<ref>{{Cite web | url=https://software.intel.com/content/www/us/en/develop/articles/openvino-relnotes.html |title = Release Notes for Intel Distribution of OpenVINO toolkit 2021|date = November 2021}}</ref>
| latest preview version = 
| latest preview date = 
| programming language = [[C++]], [[Python (programming language)|Python]]
| operating system = [[Cross-platform]]
| platform = 
| size =  <!-- 2.4.13 for Linux, unpacked -->
| language count = <!-- Number only -->
| language footnote = 
| genre = 
| license = [[Apache License]] 2.0
| alexa = 
| website = {{URL|https://docs.openvino.ai/}}
| repo = {{URL|https://github.com/openvinotoolkit/openvino}}
| standard = 
| AsOf = 
}}
'''OpenVINO toolkit''' (Open Visual Inference and Neural network Optimization) is a free toolkit facilitating the optimization of a [[deep learning]] model from a framework and deployment using an inference engine onto [[Intel]] hardware.{{Sfnp|Nanjappa|2019|p=91}} The toolkit has two versions: OpenVINO toolkit, which is supported by open source community and Intel Distribution of OpenVINO toolkit, which is supported by Intel. OpenVINO was developed by [[Intel]]. The toolkit is cross-platform and free for use under [[Apache License]] version 2.0.<ref>{{Cite web | url=https://docs.openvinotoolkit.org/ | title=OpenVINO Toolkit: Welcome to OpenVINO}}</ref> The toolkit enables a write-once, deploy-anywhere approach to deep learning deployments on Intel platforms, including [[CPU]], integrated [[GPU]], Intel [[Movidius]] [[Vision processing unit|VPU]], and [[FPGA]]s.  

==Overview==
The high level pipeline of OpenVINO consists of two parts: generate IR (Intermediate Representation) files via Model Optimizer using your trained model or public one and execute inference on [[Inference engine|Inference Engine]] on specified plugins ([[Central processing unit|CPU]], Intel Processor Graphics, VPU, [[Field-programmable gate array|FPGA]], GNA, Multi-Device plugin, [[Heterogeneous computing|Heterogeneous]] plugin)<ref>{{Cite web | url=https://docs.openvino.ai/latest/openvino_docs_IE_DG_Deep_Learning_Inference_Engine_DevGuide.html | title=Introduction to Intel Deep Learning Deployment Toolkit – OpenVINO Toolkit}}</ref>

The toolkit’s [https://docs.openvino.ai/latest/openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html Model Optimizer] is a cross-platform tool that transforms a trained model from the original framework to OpenVINO format (IR) and optimizes it for future inference on supported devices. As a result, Model Optimizer produces two files: *[[Binary file|.bin]] and *[[XML|.xml]], which contain weights and model structures respectively. 

The toolkit’s [https://docs.openvino.ai/latest/openvino_docs_IE_DG_Samples_Overview.html Inference Engine] is a [[C++]] library for inferring input on devices and getting results. To better understand OpenVINO API there are a lot of samples, that demonstrate how to work with OpenVINO

OpenVINO has different sample types: classification, object detection, style transfer, speech recognition, etc. It is possible to try inference on [https://github.com/openvinotoolkit/open_model_zoo public models] There are a variety of models for tasks, such as: 
* classification  
* segmentation   
* object detection   
* face recognition   
* human pose estimation   
* monocular depth estimation  
* image inpainting  
* style transfer  
* action recognition  
* colorization 

All these models are available for learning purpose or for development deep learning software. Open Model Zoo is licensed under [[Apache License]] version 2.0. 

Along with the primary components of model optimization and runtime within Intel® Distribution of OpenVINO toolkit, the toolkit also includes a user-friendly web browser interface called the [https://docs.openvinotoolkit.org/latest/workbench_docs_Workbench_DG_Introduction.html Deep Learning Workbench] to aid in model analysis and experimentation; a tool called the [https://docs.openvinotoolkit.org/latest/pot_README.html Post-Training Optimization Tool] to accelerate inference by converting models into low-precision and that do not require re-training (e.g., post-training quantization); and, additional add-ons, such as the [https://github.com/openvinotoolkit/dlstreamer_gst Deep Learning Streamer] to aid in streaming analytics pipeline interoperability, the [https://github.com/openvinotoolkit/model_server OpenVINO Model Server] to enable scalability via a serving microservice, [https://github.com/openvinotoolkit/training_extensions Training Extensions] like the [https://github.com/openvinotoolkit/nncf_pytorch Neural Network Compression Framework], and the [https://github.com/openvinotoolkit/cvat Computer Vision Annotation Tool], an online interactive video and image annotation tool. 

OpenVINO has two webpages: one for [https://docs.openvinotoolkit.org/ documentation] another for [https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/choose-download.html downloads].

== Supported frameworks and formats ==

* [[Caffe (software)|Caffe]] (most public branches)
* [[TensorFlow]]
* [[Apache MXNet|MXNet]]
* [[Kaldi (software)|Kaldi]]
* [[Open Neural Network Exchange|ONNX]]
* and other frameworks that can be serialized to [[Open Neural Network Exchange|ONNX]] format ([[PyTorch]], Caffe2, PaddlePaddle and others)

== Programming language ==
OpenVINO is written in [[C++]] and [[Python (programming language)|Python]].

== OS support ==
OpenVINO runs on the following desktop operation systems: [[Microsoft Windows|Windows]], [[Linux]] and [[MacOS]]

==See also==
* [[Comparison of deep learning software]]

== References ==
{{Reflist|refs=}}
{{Refbegin}}
* {{cite thesis |last1=Agrawal|first1=Vasu|year=2019
     |type=MSc |title=Ground Up Design of a Multi-modal Object Detection System |publisher=Carnegie Mellon University Pittsburgh, PA
     |url=https://www.ri.cmu.edu/wp-content/uploads/2019/12/thesis_ebook.pdf|url-status=live
     |archive-url=https://web.archive.org/web/20200126174037/https://www.ri.cmu.edu/wp-content/uploads/2019/12/thesis_ebook.pdf|archive-date=26 January 2020}}
* {{cite journal|last1=Driaba|first1=Alexander|last2=Gordeev|first2=Aleksei|last3=Klyachin|first3=Vladimir|year=2019|title=Recognition of Various Objects from a Certain Categorical Set in Real Time Using Deep Convolutional Neural Networks|url=http://ceur-ws.org/Vol-2500/paper_5.pdf|access-date=26 January 2020|url-status=live|archive-url=https://archive.today/20200126171356/http://ceur-ws.org/Vol-2500/paper_5.pdf|archive-date=26 January 2020|publisher=Institute of Mathematics and Informational Technologies Volgograd State University}}
* {{Cite book|last=Nanjappa|first=Ashwin|date=31 May 2019|title=Caffe2 Quick Start Guide: Modular and scalable deep learning made easy
     |publisher=Packt|isbn=978-1789137750|pages=91–98}}
{{Refend}}

{{Intel software}}
{{Deep Learning Software}}
[[Category:Free statistical software]]
[[Category:Applied machine learning]]