{{refimprove|date=May 2015}}

'''Backpropagation Through Structure''' (BPTS) is a [[gradient]]-based technique for training [[Recursive neural network|recursive neural nets]] (a superset of [[Recurrent neural network|recurrent neural nets]]) and is extensively described in a 1996 paper written by Christoph Goller and Andreas KÃ¼chler.<ref>{{cite paper|last1=Kuchler|first1=Andreas|title=Learning Task-Dependent Distributed Representations by Backpropagation Through Structure|citeseerx = 10.1.1.49.1968|website=psu.edu|url=https://pdfs.semanticscholar.org/794e/6ed81d21f1bf32a0fd3be05c44c1fa362688.pdf}}</ref>

==References==
{{Reflist}}

{{compu-ai-stub}}

[[Category:Artificial neural networks]]