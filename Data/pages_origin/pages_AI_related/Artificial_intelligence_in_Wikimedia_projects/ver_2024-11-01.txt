{{Short description|none}}
[[Artificial intelligence]] is used in [[Wikipedia]] and other [[Wikimedia projects]] for the purpose of developing those projects.<ref>{{cite web |last1=Marr |first1=Bernard |title=The Amazing Ways How Wikipedia Uses Artificial Intelligence |url=https://www.forbes.com/sites/bernardmarr/2018/08/17/the-amazing-ways-how-wikipedia-uses-artificial-intelligence/#7cbdda802b9d |website=Forbes |language=en |date=17 August 2018}}</ref><ref name="NYT-20230718">{{cite news |last=Gertner |first=Jon |title=Wikipedia's Moment of Truth - Can the online encyclopedia help teach A.I. chatbots to get their facts right — without destroying itself in the process? + comment |url=https://www.nytimes.com/2023/07/18/magazine/wikipedia-ai-chatgpt.html |date=18 July 2023 |work=[[The New York Times]] |url-status=bot: unknown |archiveurl=https://web.archive.org/web/20230718233916/https://www.nytimes.com/2023/07/18/magazine/wikipedia-ai-chatgpt.html#permid=126389255 |archivedate=18 July 2023 |accessdate=19 July 2023 }}</ref> Human and [[Internet bot|bot]] interaction in Wikimedia projects is routine and iterative.<ref>{{cite arXiv |last1=Piscopo |first1=Alessandro |title=Wikidata: A New Paradigm of Human-Bot Collaboration? |date=1 October 2018 |eprint=1810.00931|class=cs.HC }}</ref>

==Using artificial intelligence for Wikimedia projects==
Various projects seek to improve Wikipedia and Wikimedia projects by using artificial intelligence tools.

===ORES===
The Objective Revision Evaluation Service (ORES) project is an artificial intelligence service for grading the quality of Wikipedia edits.<ref>{{cite web |last1=Simonite |first1=Tom |title=Software That Can Spot Rookie Mistakes Could Make Wikipedia More Welcoming |url=https://www.technologyreview.com/s/544036/artificial-intelligence-aims-to-make-wikipedia-friendlier-and-better/ |website=MIT Technology Review |language=en |date=1 December 2015}}</ref><ref>{{Cite magazine |last1=Metz |first1=Cade |title=Wikipedia Deploys AI to Expand Its Ranks of Human Editors |url=https://www.wired.com/2015/12/wikipedia-is-using-ai-to-expand-the-ranks-of-human-editors/ |magazine=Wired |date=1 December 2015|archive-url=https://web.archive.org/web/20240402000516/https://www.wired.com/2015/12/wikipedia-is-using-ai-to-expand-the-ranks-of-human-editors/|archive-date=2 Apr 2024}}</ref> The Wikimedia Foundation presented the ORES project in November 2015.<ref>{{cite web |last1=Halfaker |first1=Aaron |last2=Taraborelli |first2=Dario |title=Artificial intelligence service "ORES" gives Wikipedians X-ray specs to see through bad edits |url=https://wikimediafoundation.org/2015/11/30/artificial-intelligence-x-ray-specs/ |website=Wikimedia Foundation |date=30 November 2015}}</ref>

===Detox===
Detox was a project by Google, in collaboration with the Wikimedia Foundation, to research methods that could be used to address users posting unkind comments in Wikimedia community discussions.<ref>{{Cite book |title=Research:Detox - Meta |url=https://meta.wikimedia.org/wiki/Research:Detox |language=en}}</ref> Among other parts of the Detox project, the Wikimedia Foundation and [[Jigsaw (company)|Jigsaw]] collaborated to use artificial intelligence for basic research and to develop technical solutions{{examples needed|date=April 2023}} to address the problem. In October 2016 those organizations published "Ex Machina: Personal Attacks Seen at Scale" describing their findings.<ref>{{Cite book |pages=1391–1399 |doi=10.1145/3038912.3052591 |arxiv=1610.08914|year=2017 |last1=Wulczyn |first1=Ellery |last2=Thain |first2=Nithum |last3=Dixon |first3=Lucas |title=Proceedings of the 26th International Conference on World Wide Web |chapter=Ex Machina: Personal Attacks Seen at Scale |isbn=9781450349130 |s2cid=6060248 }}</ref><ref>{{cite web |author1=Jigsaw |title=Algorithms And Insults: Scaling Up Our Understanding Of Harassment On Wikipedia |url=https://medium.com/jigsaw/algorithms-and-insults-scaling-up-our-understanding-of-harassment-on-wikipedia-6cc417b9f7ff |website=Medium |date=7 February 2017}}</ref> Various popular media outlets reported on the publication of this paper and described the social context of the research.<ref>{{cite news |last1=Wakabayashi |first1=Daisuke |title=Google Cousin Develops Technology to Flag Toxic Online Comments |url=https://www.nytimes.com/2017/02/23/technology/google-jigsaw-monitor-toxic-online-comments.html |journal=The New York Times |language=en |date=23 February 2017}}</ref><ref>{{cite web |last1=Smellie |first1=Sarah |title=Inside Wikipedia's Attempt to Use Artificial Intelligence to Combat Harassment |url=https://motherboard.vice.com/en_us/article/aeyvxz/wikipedia-jigsaw-google-artificial-intelligence |website=Motherboard |publisher=[[Vice Media]] |language=en-us |date=17 February 2017}}</ref><ref>{{cite web |last1=Gershgorn |first1=Dave |title=Alphabet's hate-fighting AI doesn't understand hate yet |url=https://qz.com/918640/alphabets-hate-fighting-ai-doesnt-understand-hate-yet/ |website=Quartz |date=27 February 2017}}</ref>

===Bias reduction===
In August 2018, a company called Primer reported attempting to use artificial intelligence to create Wikipedia articles about women as a way to address [[gender bias on Wikipedia]].<ref>{{Cite magazine |last1=Simonite |first1=Tom |title=Using Artificial Intelligence to Fix Wikipedia's Gender Problem |url=https://www.wired.com/story/using-artificial-intelligence-to-fix-wikipedias-gender-problem/ |magazine=Wired |date=3 August 2018}}</ref><ref>{{cite web |last1=Verger |first1=Rob |title=Artificial intelligence can now help write Wikipedia pages for overlooked scientists |url=https://www.popsci.com/artificial-intelligence-scientists-wikipedia |website=Popular Science |language=en |date=7 August 2018}}</ref>

===Generative language models===

In 2022, the public release of [[ChatGPT]] inspired more experimentation with AI and writing Wikipedia articles. A debate was sparked about whether and to what extent such [[large language model]]s are suitable for such purposes in light of their tendency to [[Hallucination (artificial intelligence)|generate plausible-sounding misinformation]], including fake references; to generate prose that is not encyclopedic in tone; and to [[Algorithmic bias|reproduce biases]].<ref>{{Cite web |last=Harrison |first=Stephen |date=2023-01-12 |title=Should ChatGPT Be Used to Write Wikipedia Articles? |url=https://slate.com/technology/2023/01/chatgpt-wikipedia-articles.html |access-date=2023-01-13 |website=Slate Magazine |language=en}}</ref><ref name ="vice"/> {{As of|2023|05}}, a draft Wikipedia policy on ChatGPT and similar [[large language model]]s (LLMs) recommended that users who are unfamiliar with LLMs should avoid using them due to the aforementioned risks, as well as the potential for [[libel]] or [[copyright infringement]].<ref name ="vice">{{cite news |last1=Woodcock |first1=Claire |title=AI Is Tearing Wikipedia Apart |url=https://www.vice.com/en/article/v7bdba/ai-is-tearing-wikipedia-apart |work=Vice |date=2 May 2023 |language=en}}</ref>

A [[WikiProject]] exists for finding and removing AI-generated text and images, called WikiProject AI Cleanup.<ref>{{Cite news |last=Maiberg |first=Emanuel |date=October 9, 2024 |title=The Editors Protecting Wikipedia from AI Hoaxes |url=https://www.404media.co/the-editors-protecting-wikipedia-from-ai-hoaxes/ |access-date=October 9, 2024 |work=[[404 Media]]}}</ref>

==Using Wikimedia projects for artificial intelligence==
Content in Wikimedia projects is useful as a dataset in advancing artificial intelligence research and applications. For instance, in the development of the Google's [[Perspective API]] that identifies toxic comments in online forums, a dataset containing hundreds of thousands of Wikipedia talk page comments with human-labelled toxicity levels was used.<ref>{{Cite news|url=https://www.engadget.com/2017/09/01/google-perspective-comment-ranking-system/|title=Google's comment-ranking system will be a hit with the alt-right|work=Engadget|date=2017-09-01}}</ref>

A 2012 paper reported that more than 1000 academic articles, including those using artificial intelligence, examine Wikipedia, reuse information from Wikipedia, use technical extensions linked to Wikipedia, or research communication about Wikipedia.<ref>{{cite journal |last1=Nielsen |first1=Finn Årup |title=Wikipedia Research and Tools: Review and Comments |journal=SSRN Working Paper Series |date=2012 |doi=10.2139/ssrn.2129874 |language=en |issn=1556-5068}}</ref> A 2017 paper described Wikipedia as the [[mother lode]] for human-generated text available for machine learning.<ref>{{cite journal |last1=Mehdi |first1=Mohamad |last2=Okoli |first2=Chitu |last3=Mesgari |first3=Mostafa |last4=Nielsen |first4=Finn Årup |last5=Lanamäki |first5=Arto |title=Excavating the mother lode of human-generated text: A systematic review of research that uses the wikipedia corpus |journal=Information Processing & Management |volume=53 |issue=2 |pages=505–529 |doi=10.1016/j.ipm.2016.07.003 |date=March 2017|s2cid=217265814 |url=http://urn.fi/urn:nbn:fi-fe202003057304 }}</ref>

A 2016 research project called "One Hundred Year Study on Artificial Intelligence" named Wikipedia as a key early project for understanding the interplay between artificial intelligence applications and human engagement.<ref>{{cite web |title=AI Research Trends - One Hundred Year Study on Artificial Intelligence (AI100) |url=https://ai100.stanford.edu/2016-report/section-i-what-artificial-intelligence/ai-research-trends |website=ai100.stanford.edu |language=en}}</ref>

==References==
{{reflist}}

==See also==
*[https://www.mediawiki.org/wiki/ORES ORES Mediawiki page]
* [[Wikipedia:Artificial intelligence]]

{{Wikimedia Foundation|state=collapsed}}

[[Category:AI software]]
[[Category:Wikimedia projects]]
[[Category:Commercial use of Wikimedia projects]]