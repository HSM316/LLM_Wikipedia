{{short description|Overview of field as applied to Wikimedia}}
[[Artificial intelligence]] is used in [[Wikipedia]] and other [[Wikimedia projects]] for the purpose of developing those projects.<ref>{{cite web |last1=Marr |first1=Bernard |title=The Amazing Ways How Wikipedia Uses Artificial Intelligence |url=https://www.forbes.com/sites/bernardmarr/2018/08/17/the-amazing-ways-how-wikipedia-uses-artificial-intelligence/#7cbdda802b9d |website=Forbes |language=en |date=17 August 2018}}</ref> Human and [[Internet bot|bot]] interaction in Wikimedia projects is routine and iterative.<ref>{{cite arxiv |last1=Piscopo |first1=Alessandro |title=Wikidata: A New Paradigm of Human-Bot Collaboration? |date=1 October 2018 |eprint=1810.00931|class=cs.HC }}</ref>

==Using artificial intelligence for Wikimedia projects==
Various projects seek to improve Wikipedia and Wikimedia projects by using artificial intelligence tools.

===ORES===
The Objective Revision Evaluation Service (ORES) project is an artificial intelligence service for grading the quality of Wikipedia edits.<ref>{{cite web |last1=Simonite |first1=Tom |title=Software That Can Spot Rookie Mistakes Could Make Wikipedia More Welcoming |url=https://www.technologyreview.com/s/544036/artificial-intelligence-aims-to-make-wikipedia-friendlier-and-better/ |website=MIT Technology Review |language=en |date=1 December 2015}}</ref><ref>{{Cite journal |last1=Metz |first1=Cade |title=Wikipedia Deploys AI to Expand Its Ranks of Human Editors |url=https://www.wired.com/2015/12/wikipedia-is-using-ai-to-expand-the-ranks-of-human-editors/ |journal=Wired |date=1 December 2015}}</ref> The Wikimedia Foundation presented the ORES project in November 2015.<ref>{{cite web |last1=Halfaker |first1=Aaron |last2=Taraborelli |first2=Dario |title=Artificial intelligence service "ORES" gives Wikipedians X-ray specs to see through bad edits |url=https://wikimediafoundation.org/2015/11/30/artificial-intelligence-x-ray-specs/ |website=Wikimedia Foundation |date=30 November 2015}}</ref>

===Detox===
Detox is a project to prevent users from posting unkind comments in Wikimedia community discussions.<ref>{{Cite book |title=Research:Detox - Meta |url=https://meta.wikimedia.org/wiki/Research:Detox |website=meta.wikimedia.org |language=en}}</ref> Among other parts of the Detox project, the Wikimedia Foundation and [[Jigsaw (company)|Jigsaw]] collaborated to use artificial intelligence for basic research and to develop technical solutions to address the problem. In October 2016 those organizations published "Ex Machina: Personal Attacks Seen at Scale" describing their findings.<ref>{{Cite book |title=Ex Machina: Personal Attacks Seen at Scale |pages=1391–1399 |doi=10.1145/3038912.3052591 |arxiv=1610.08914|chapter=Ex Machina |year=2017 |last1=Wulczyn |first1=Ellery |last2=Thain |first2=Nithum |last3=Dixon |first3=Lucas |isbn=9781450349130 |s2cid=6060248 }}</ref><ref>{{cite web |author1=Jigsaw |title=Algorithms And Insults: Scaling Up Our Understanding Of Harassment On Wikipedia |url=https://medium.com/jigsaw/algorithms-and-insults-scaling-up-our-understanding-of-harassment-on-wikipedia-6cc417b9f7ff |website=Medium |date=7 February 2017}}</ref> Various popular media outlets reported on the publication of this paper and described the social context of the research.<ref>{{Cite newspaper |last1=Wakabayashi |first1=Daisuke |title=Google Cousin Develops Technology to Flag Toxic Online Comments |url=https://www.nytimes.com/2017/02/23/technology/google-jigsaw-monitor-toxic-online-comments.html |journal=The New York Times |language=en |date=23 February 2017}}</ref><ref>{{cite web |last1=Smellie |first1=Sarah |title=Inside Wikipedia's Attempt to Use Artificial Intelligence to Combat Harassment |url=https://motherboard.vice.com/en_us/article/aeyvxz/wikipedia-jigsaw-google-artificial-intelligence |website=Motherboard |publisher=[[Vice Media]] |language=en-us |date=17 February 2017}}</ref><ref>{{cite web |last1=Gershgorn |first1=Dave |title=Alphabet's hate-fighting AI doesn't understand hate yet |url=https://qz.com/918640/alphabets-hate-fighting-ai-doesnt-understand-hate-yet/ |website=Quartz |date=27 February 2017}}</ref>

===Other===
In August 2018, a company called Primer reported attempting to use artificial intelligence to create Wikipedia articles about women as a way to address [[gender bias on Wikipedia]].<ref>{{Cite journal |last1=Simonite |first1=Tom |title=Using Artificial Intelligence to Fix Wikipedia's Gender Problem |url=https://www.wired.com/story/using-artificial-intelligence-to-fix-wikipedias-gender-problem/ |journal=Wired |date=3 August 2018}}</ref><ref>{{cite web |last1=Verger |first1=Rob |title=Artificial intelligence can now help write Wikipedia pages for overlooked scientists |url=https://www.popsci.com/artificial-intelligence-scientists-wikipedia |website=Popular Science |language=en |date=7 August 2018}}</ref>

==Using Wikimedia projects for artificial intelligence==
Content in Wikimedia projects is useful as a dataset in advancing artificial intelligence research and applications. For instance, in the development of the Google's [[Perspective API]] that identifies toxic comments in online forums, a dataset containing hundreds of thousands of Wikipedia talk page comments with human-labelled toxicity levels was used.<ref>{{Cite news|url=https://www.engadget.com/2017/09/01/google-perspective-comment-ranking-system/|title=Google's comment-ranking system will be a hit with the alt-right|work=Engadget|date=2017-09-01}}</ref>

A 2012 paper reported that more than 1000 academic articles, including those using artificial intelligence, examine Wikipedia, reuse information from Wikipedia, use technical extensions linked to Wikipedia, or research communication about Wikipedia.<ref>{{cite journal |last1=Nielsen |first1=Finn Årup |title=Wikipedia Research and Tools: Review and Comments |journal=SSRN Working Paper Series |date=2012 |doi=10.2139/ssrn.2129874 |language=en |issn=1556-5068}}</ref> A 2017 paper described Wikipedia as the [[mother lode]] for human-generated text available for machine learning.<ref>{{cite journal |last1=Mehdi |first1=Mohamad |last2=Okoli |first2=Chitu |last3=Mesgari |first3=Mostafa |last4=Nielsen |first4=Finn Årup |last5=Lanamäki |first5=Arto |title=Excavating the mother lode of human-generated text: A systematic review of research that uses the wikipedia corpus |journal=Information Processing & Management |volume=53 |issue=2 |pages=505–529 |doi=10.1016/j.ipm.2016.07.003 |date=March 2017|url=http://urn.fi/urn:nbn:fi-fe202003057304 }}</ref>

A 2016 research project called "One Hundred Year Study on Artificial Intelligence" named Wikipedia as a key early project for understanding the interplay between artificial intelligence applications and human engagement.<ref>{{cite web |title=AI Research Trends - One Hundred Year Study on Artificial Intelligence (AI100) |url=https://ai100.stanford.edu/2016-report/section-i-what-artificial-intelligence/ai-research-trends |website=ai100.stanford.edu |language=en}}</ref>

==References==
{{reflist}}

==See also==
*[https://www.mediawiki.org/wiki/ORES ORES Mediawiki page]

[[Category:Artificial intelligence]]
[[Category:Wikimedia projects]]