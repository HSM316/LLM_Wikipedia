{{Short description|Architectural motif in neural networks for computing translation-invariant features}}

{{Machine learning}}In [[artificial neural networks]], a '''convolutional layer''' is a type of [[Layer (deep learning)|network layer]] that applies a [[convolution]] operation to the input. Convolutional layers are some of the primary building blocks of [[convolutional neural networks]] (CNNs), a class of neural network most commonly applied to images, video, audio, and other data that have the property of uniform [[translational symmetry]].<ref name="Goodfellow">{{Cite book |last1=Goodfellow |first1=Ian |title=Deep Learning |last2=Bengio |first2=Yoshua |last3=Courville |first3=Aaron |date=2016 |publisher=MIT Press |isbn=978-0262035613 |location=Cambridge, MA |pages=326–366}}</ref>

The convolution operation in a convolutional layer involves sliding a small window (called a [[Kernel (image processing)|kernel]] or filter) across the input data and computing the [[dot product]] between the values in the kernel and the input at each position. This process creates a feature map that represents detected [[Feature (computer vision)|features]] in the input.<ref name="Zhang">{{Cite book |last1=Zhang |first1=Aston |title=Dive into deep learning |last2=Lipton |first2=Zachary |last3=Li |first3=Mu |last4=Smola |first4=Alexander J. |date=2024 |publisher=Cambridge University Press |isbn=978-1-009-38943-3 |location=Cambridge New York Port Melbourne New Delhi Singapore |chapter=7.2. Convolutions for Images |chapter-url=https://d2l.ai/chapter_convolutional-neural-networks/conv-layer.html}}</ref>

== Concepts ==

=== Kernel ===

'''Kernels''', also known as '''filters''', are small matrices of weights that are learned during the training process. Each kernel is responsible for detecting a specific feature in the input data. The size of the kernel is a hyperparameter that affects the network's behavior.

=== Convolution ===

For a 2D input <math>x</math> and a 2D kernel <math>w</math>, the 2D convolution operation can be expressed as:<math display="block">
y[i,j] = \sum_{m=0}^{k_h-1} \sum_{n=0}^{k_w-1} x[i+m,j+n] \cdot w[m,n]
</math>where <math>k_h</math> and <math>k_w</math> are the height and width of the kernel, respectively.

This generalizes immediately to nD convolutions. Commonly used convolutions are 1D (for audio and text), 2D (for images), and 3D (for spatial objects, and videos).

=== Stride ===

Stride determines how the kernel moves across the input data. A stride of 1 means the kernel shifts by one pixel at a time, while a larger stride (e.g., 2 or 3) results in less overlap between convolutions and produces smaller output feature maps.

=== Padding ===

Padding involves adding extra pixels around the edges of the input data. It serves two main purposes:

* Preserving spatial dimensions: Without padding, each convolution reduces the size of the feature map.
* Handling border pixels: Padding ensures that border pixels are given equal importance in the convolution process.

Common padding strategies include:

* No padding/valid padding. This strategy typically causes the output to shrink.
* Same padding: Any method that ensures the output size same as input size is a same padding strategy.
* Full padding: Any method that ensures each input entry is convolved over for the same number of times is a full padding strategy.
Common padding algorithms include:

* Zero padding: Add zero entries to the borders of input.
* Mirror/reflect/symmetric padding: Reflect the input array on the border.
* Circular padding: Cycle the input array back to the opposite border, like a torus.

The exact numbers used in convolutions is complicated, for which we refer to (Dumoulin and Visin, 2018)<ref>{{Cite journal |last1=Dumoulin |first1=Vincent |last2=Visin |first2=Francesco |date=2016 |title=A guide to convolution arithmetic for deep learning |journal=arXiv preprint arXiv:1603.07285|arxiv=1603.07285 }}</ref> for details.

== Variants ==

=== Standard ===

The basic form of convolution as described above, where each kernel is applied to the entire input volume.

=== Depthwise separable ===

{{Anchor|Depthwise separable}}'''Depthwise separable convolution''' separates the standard convolution into two steps: '''depthwise convolution''' and '''pointwise convolution'''. The depthwise separable convolution decomposes a single standard convolution into two convolutions: a depthwise convolution that filters each input channel independently and a pointwise convolution (<math>1 \times 1</math> convolution) that combines the outputs of the depthwise convolution. This factorization significantly reduces computational cost.<ref name=":1">{{Cite book |last1=Chollet |first1=François |chapter=Xception: Deep Learning with Depthwise Separable Convolutions |date=2017 |title=2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) |chapter-url=https://openaccess.thecvf.com/content_cvpr_2017/html/Chollet_Xception_Deep_Learning_CVPR_2017_paper.html |pages=1800–1807 |doi=10.1109/CVPR.2017.195|arxiv=1610.02357 |isbn=978-1-5386-0457-1 }}</ref>

It was first developed by Laurent Sifre during an internship at [[Google Brain]] in 2013 as an architectural variation on [[AlexNet]] to improve convergence speed and model size.<ref name=":1" />
=== Dilated ===

'''Dilated convolution''', or '''atrous convolution''', introduces gaps between kernel elements, allowing the network to capture a larger receptive field without increasing the kernel size.<ref>{{Cite journal |last1=Yu |first1=Fisher |last2=Koltun |first2=Vladlen |date=2016 |title=Multi-Scale Context Aggregation by Dilated Convolutions |journal=Iclr 2016|arxiv=1511.07122 }}</ref><ref>{{Cite journal |last1=Chen |first1=Liang-Chieh |last2=Papandreou |first2=George |last3=Kokkinos |first3=Iasonas |last4=Murphy |first4=Kevin |last5=Yuille |first5=Alan L. |date=2018-04-01 |title=DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs |url=https://ieeexplore.ieee.org/document/7913730 |journal=IEEE Transactions on Pattern Analysis and Machine Intelligence |volume=40 |issue=4 |pages=834–848 |doi=10.1109/TPAMI.2017.2699184 |pmid=28463186 |arxiv=1606.00915 |issn=0162-8828}}</ref>

=== Transposed ===

'''Transposed convolution''', also known as '''deconvolution''' or '''fractionally strided convolution''', is a convolution where the output tensor is larger than its input tensor. It's often used in encoder-decoder architectures for upsampling.

== History ==

The concept of convolution in neural networks was inspired by the visual cortex in biological brains. Early work by Hubel and Wiesel in the 1960s on the cat's visual system laid the groundwork for artificial convolution networks.<ref>{{Cite journal |last1=Hubel |first1=D. H. |last2=Wiesel |first2=T. N. |date=1968 |title=Receptive fields and functional architecture of monkey striate cortex |journal=The Journal of Physiology |volume=195 |issue=1 |pages=215–243 |doi=10.1113/jphysiol.1968.sp008455 |pmid=4966457 |pmc=1557912}}</ref>

An early convolution neural network was developed by [[Kunihiko Fukushima]] in 1969. It had mostly hand-designed kernels inspired by convolutions in mammalian vision.<ref>{{Cite journal |last=Fukushima |first=Kunihiko |date=1969 |title=Visual Feature Extraction by a Multilayered Network of Analog Threshold Elements |url=https://ieeexplore.ieee.org/document/4082265 |journal=IEEE Transactions on Systems Science and Cybernetics |volume=5 |issue=4 |pages=322–333 |doi=10.1109/TSSC.1969.300225 |issn=0536-1567}}</ref> In 1979 he improved it to the [[Neocognitron]], which ''learns'' all convolutional kernels by [[unsupervised learning]] (in his terminology, "[[Self-organization|self-organized]] by 'learning without a teacher'").<ref>{{cite journal |last=Fukushima |first=Kunihiko |date=October 1979 |title=位置ずれに影響されないパターン認識機構の神経回路のモデル --- ネオコグニトロン --- |trans-title=Neural network model for a mechanism of pattern recognition unaffected by shift in position — Neocognitron — |url=https://search.ieice.org/bin/summary.php?id=j62-a_10_658 |journal=Trans. IECE |language=ja |volume=J62-A |issue=10 |pages=658–665}}</ref><ref>{{Cite journal |last=Fukushima |first=Kunihiko |date=1980 |title=Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position |journal=Biological Cybernetics |volume=36 |issue=4 |pages=193–202 |doi=10.1007/BF00344251 |pmid=7370364}}</ref>

In 1998, [[Yann LeCun]] et al. introduced [[LeNet|LeNet-5]], an early influential CNN architecture for handwritten digit recognition, trained on the [[MNIST database|MNIST dataset]].<ref>{{Cite journal |last1=LeCun |first1=Yann |last2=Bottou |first2=Léon |last3=Bengio |first3=Yoshua |last4=Haffner |first4=Patrick |date=1998 |title=Gradient-based learning applied to document recognition |journal=Proceedings of the IEEE |volume=86 |issue=11 |pages=2278–2324 |doi=10.1109/5.726791}}</ref>

(Olshausen & Field, 1996)<ref>{{Cite journal |last1=Olshausen |first1=Bruno A. |last2=Field |first2=David J. |date=June 1996 |title=Emergence of simple-cell receptive field properties by learning a sparse code for natural images |url=https://www.nature.com/articles/381607a0 |journal=Nature |language=en |volume=381 |issue=6583 |pages=607–609 |doi=10.1038/381607a0 |pmid=8637596 |bibcode=1996Natur.381..607O |issn=1476-4687}}</ref> discovered that [[Simple cell|simple cells]] in the mammalian [[primary visual cortex]] implement localized, oriented, bandpass receptive fields, which could be recreated by fitting sparse linear codes for natural scenes. This was later found to also occur in the lowest-level kernels of trained CNNs.<ref name=":0" />{{Pg|location=Fig 3}}

The field saw a resurgence in the 2010s with the development of deeper architectures and the availability of large datasets and powerful GPUs. [[AlexNet]], developed by [[Alex Krizhevsky]] et al. in 2012, was a catalytic event in modern [[deep learning]].<ref name=":0">{{Cite journal |last1=Krizhevsky |first1=Alex |last2=Sutskever |first2=Ilya |last3=Hinton |first3=Geoffrey E |date=2012 |title=ImageNet Classification with Deep Convolutional Neural Networks |url=https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html |journal=Advances in Neural Information Processing Systems |publisher=Curran Associates, Inc. |volume=25}}</ref>

== See also ==
* [[Convolutional neural network]]
* [[Pooling layer]]
* [[Feature learning]]
* [[Deep learning]]
* [[Computer vision]]

== References ==
<references />{{Differentiable computing}}
[[Category:Artificial neural networks]]
[[Category:Computer vision]]
[[Category:Deep learning]]