{{refimprove|date=March 2010}}
'''ViBe''' is a [[background subtraction]] [[algorithm]] which has been presented at the IEEE [[ICASSP]] 2009 conference and was refined in later publications.<ref name="BarnichVan Droogenbroeck2009">{{cite book|last1=Barnich|first1=Olivier|title=2009 IEEE International Conference on Acoustics, Speech and Signal Processing|last2=Van Droogenbroeck|first2=Marc|chapter=ViBe: A powerful random technique to estimate the background in video sequences|year=2009|pages=945–948|doi=10.1109/ICASSP.2009.4959741|hdl=2268/12087|isbn=978-1-4244-2353-8|s2cid=10129753|chapter-url=http://orbi.ulg.ac.be/handle/2268/12087}}</ref><ref name="BarnichVan Droogenbroeck2011">{{cite journal|last1=Barnich|first1=O|last2=Van Droogenbroeck|first2=M|title=ViBe: A Universal Background Subtraction Algorithm for Video Sequences|journal=IEEE Transactions on Image Processing|volume=20|issue=6|year=2011|pages=1709–1724|issn=1057-7149|doi=10.1109/TIP.2010.2101613|pmid=21189241|bibcode=2011ITIP...20.1709B|hdl=2268/145853|s2cid=783186|url=http://orbi.ulg.ac.be/handle/2268/145853|hdl-access=free}}</ref><ref name="Van DroogenbroeckPaquot2012">{{cite book|last1=Van Droogenbroeck|first1=M.|title=2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops|last2=Paquot|first2=O.|chapter=Background subtraction: Experiments and improvements for ViBe|year=2012|pages=32–37|doi=10.1109/CVPRW.2012.6238924|hdl=2268/117561|isbn=978-1-4673-1612-5|s2cid=10545941|chapter-url=http://orbi.ulg.ac.be/handle/2268/117561}}</ref><ref name="Van DroogenbroeckBarnich2014">{{cite book|last1=Van Droogenbroeck|first1=Marc|title=Background Modeling and Foreground Detection for Video Surveillance|last2=Barnich|first2=Olivier|chapter=ViBe: A Disruptive Method for Background Subtraction|year=2014|pages=7.1–7.23|doi=10.1201/b17223-10|isbn=978-1-4822-0537-4|chapter-url=http://www2.ulg.ac.be/telecom/research/vibe}}</ref> More precisely, it is a software module for extracting background information from moving images. It has been developed by Oliver Barnich and Marc Van Droogenbroeck of the  [[Montefiore Institute]], [[University of Liège]], Belgium.<ref>{{Cite web|url=http://www.telecom.ulg.ac.be/research/vibe/|title = ViBe - a powerful technique for background detection and subtraction in video sequences}}</ref>

ViBe is patented:<ref>World Intellectual Property Organization. [http://patentscope.wipo.int/search/en/detail.jsf?docId=WO2009007198&tab=PCT+Biblio ViBe patents]</ref> the patent covers various aspects such as stochastic replacement, spatial diffusion, and non-chronological handling.

ViBe is written in the [[C (programming language)|programming language C]], and has been implemented on [[CPU]], [[GPU]] and [[FPGA]].<ref>Kryjak, Tomasz; Gorgon, Marek. [https://ieeexplore.ieee.org/document/6644061/ "Real-time Implementation of the ViBe Foreground Object Segmentation Algorithm"]. In Proceedings of the 2013 Federated Conference on Computer Science and Information Systems (FedCSIS) pp. 591–596</ref>

== Technical description<ref name="BarnichVan Droogenbroeck2011" /> ==

=== Pixel model and classification process ===
Many advanced techniques are used to provide an estimate of the temporal [[probability density function]] (pdf) of a pixel x. ViBe's approach is different, as it imposes the influence of a value in the polychromatic space to be limited to the local neighborhood. In practice, ViBe does not estimate the pdf, but uses a set of previously observed sample values as a pixel model. To classify a value pt(x), it is compared to its closest values among the set of samples.

=== Model update: Sample values lifespan policy ===
ViBe ensures a smooth exponentially decaying lifespan for the sample values that constitute the pixel models. This makes ViBe able to successfully deal with concomitant events with a single model of a reasonable size for each pixel. This is achieved by choosing, randomly, which sample to replace when updating a pixel model. Once the sample to be discarded has been chosen, the new value replaces the discarded sample. The pixel model that would result from the update of a given pixel model with a given pixel sample cannot be predicted since the value to be discarded is chosen at random.

=== Model update: Spatial Consistency ===
To ensure the spatial consistency of the whole image model and handle practical situations such as small camera movements or slowly evolving background objects, ViBe uses a technique similar to that developed for the updating process in which it chooses at random and update a pixel model in the neighborhood of the current pixel. By denoting NG(x) and p(x) respectively the spatial neighborhood of a pixel x and its value, and assuming that it was decided to update the set of samples of x by inserting p(x), then ViBe also use this value p(x) to update the set of samples of one of the pixels in the neighborhood NG(x), chosen at random. As a result, ViBe is able to produce spatially coherent results directly without the use of any post-processing method.

=== Model initialization ===
Although the model could easily recover from any type of initialization, for example by choosing a set of random values, it is convenient to get an accurate background estimate as soon as possible. Ideally a segmentation algorithm would like to be able to segment the video sequences starting from the second frame, the first frame being used to initialize the model. Since no temporal information is available prior to the second frame, ViBe populates the pixel models with values found in the spatial neighborhood of each pixel; more precisely, it initializes the background model with values taken randomly in each pixel neighborhood of the first frame. The background
estimate is therefore valid starting from the second frame of a video sequence.

== References ==
{{reflist|2}}

{{Computer vision footer}}

[[Category:Computer vision]]