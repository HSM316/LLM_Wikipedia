{{Short description|Parameter controlling the machine learning process}}
{{distinguish|Hyperparameter (Bayesian)}}

In [[machine learning]], a '''hyperparameter''' is a [[Parameter (computer programming)|parameter]] that can be set in order to define any configurable part of a [[machine learning model|model]]'s learning process. Hyperparameters can be classified as either model hyperparameters (such as the topology and size of a [[neural network (machine learning)|neural network]]) or algorithm hyperparameters (such as the [[learning rate]] and the batch size of an [[Optimization algorithm|optimizer]]). These are named ''hyper''parameters in contrast to [[parameter]]s, which are characteristics that the model learns from the data.

Hyperparameters are not required by every model or algorithm. Some simple algorithms such as [[ordinary least squares]] regression require none. However, the [[LASSO]] algorithm, for example, adds a [[Regularization (mathematics)|regularization]] hyperparameter to ordinary least squares which must be set before training.<ref>{{Cite journal |last1=Yang |first1=Li |last2=Shami |first2=Abdallah |date=2020-11-20 |title=On hyperparameter optimization of machine learning algorithms: Theory and practice |url=https://www.sciencedirect.com/science/article/pii/S0925231220311693 |journal=Neurocomputing |language=en |volume=415 |pages=295–316 |doi=10.1016/j.neucom.2020.07.061 |arxiv=2007.15745 |s2cid=220919678 |issn=0925-2312}}</ref> Even models and algorithms without a strict requirement to define hyperparameters may not produce meaningful results if these are not carefully chosen. However, optimal values for hyperparameters are not always easy to predict. Some hyperparameters may have no meaningful effect, or one important variable may be conditional upon the value of another. Often a separate process of [[hyperparameter tuning]] is needed to find a suitable combination for the data and task. 

As well was improving model performance, hyperparameters can be used to by researchers introduce [[robustness (computer science)|robustness]] and [[reproducibility]] into their work, especially if it uses models that incorporate [[random number generation]].

== Considerations ==
The time required to train and test a model can depend upon the choice of its hyperparameters.<ref name=abs1502.02127>{{cite news |arxiv=1502.02127 |title=Claesen, Marc, and Bart De Moor. "Hyperparameter Search in Machine Learning." arXiv preprint arXiv:1502.02127 (2015).|bibcode=2015arXiv150202127C}}</ref> A hyperparameter is usually of continuous or integer type, leading to mixed-type optimization problems.<ref name=abs1502.02127/> The existence of some hyperparameters is conditional upon the value of others, e.g. the size of each hidden layer in a neural network can be conditional upon the number of layers.<ref name=abs1502.02127/>

=== Difficulty-learnable parameters ===
The [[objective function]] is typically [[Differentiable function|non-differentiable]] with respect to hyperparameters.{{Clarify|date=September 2024}} As a result, in most instances, hyperparameters cannot be learned using [[Gradient method|gradient-based optimization methods]] (such as gradient descent), which are commonly employed to learn model parameters. These hyperparameters are those parameters describing a model representation that cannot be learned by common optimization methods, but nonetheless affect the loss function. An example would be the tolerance hyperparameter for errors in [[support vector machines]].

=== Untrainable parameters ===
Sometimes, hyperparameters cannot be learned from the training data because they aggressively increase the capacity of a model and can push the loss function to an undesired minimum ([[overfitting]] to the data), as opposed to correctly mapping the richness of the structure in the data. For example, if we treat the degree of a polynomial equation fitting a regression model as a [[trainable parameter]], the degree would increase until the model perfectly fit the data, yielding low training error, but poor generalization performance.

=== Tunability ===
Most performance variation can be attributed to just a few hyperparameters.<ref name=hutter14>{{Cite journal|url=http://proceedings.mlr.press/v32/hutter14.html|title=An Efficient Approach for Assessing Hyperparameter Importance|first1=Kevin|last1=Leyton-Brown|first2=Holger|last2=Hoos|first3=Frank|last3=Hutter|date=January 27, 2014|pages=754–762|via=proceedings.mlr.press}}</ref><ref name=abs1502.02127/><ref name=abs1710.04725>{{cite news |arxiv=1710.04725 |title=van Rijn, Jan N., and Frank Hutter. "Hyperparameter Importance Across Datasets." arXiv preprint arXiv:1710.04725 (2017).|bibcode=2017arXiv171004725V}}</ref> The tunability of an algorithm, hyperparameter, or interacting hyperparameters is a measure of how much performance can be gained by tuning it.<ref name=arXiv:1802.09596>{{cite news |arxiv=1802.09596 |title=Probst, Philipp, Bernd Bischl, and Anne-Laure Boulesteix. "Tunability: Importance of Hyperparameters of Machine Learning Algorithms." arXiv preprint arXiv:1802.09596 (2018).|bibcode=2018arXiv180209596P}}</ref> For an [[Long short-term memory|LSTM]], while the [[learning rate]] followed by the network size are its most crucial hyperparameters,<ref name=pmid27411231>{{Cite journal|title=LSTM: A Search Space Odyssey|first1=K.|last1=Greff|first2=R. K.|last2=Srivastava|first3=J.|last3=Koutník|first4=B. R.|last4=Steunebrink|first5=J.|last5=Schmidhuber|date=October 23, 2017|journal=IEEE Transactions on Neural Networks and Learning Systems|volume=28|issue=10|pages=2222–2232|doi=10.1109/TNNLS.2016.2582924|pmid=27411231|arxiv=1503.04069|s2cid=3356463}}</ref> batching and momentum have no significant effect on its performance.<ref name=abs1508.02774>{{cite news |arxiv=1508.02774 |title=Breuel, Thomas M. "Benchmarking of LSTM networks." arXiv preprint arXiv:1508.02774 (2015).|bibcode=2015arXiv150802774B}}</ref>

Although some research has advocated the use of mini-batch sizes in the thousands, other work has found the best performance with mini-batch sizes between 2 and 32.<ref name=arXiv:1804.07612>{{cite news |arxiv=1804.07612 |title=Revisiting Small Batch Training for Deep Neural Networks (2018).|bibcode=2018arXiv180407612M}}</ref>

=== Robustness ===
An inherent stochasticity in learning directly implies that the empirical hyperparameter performance is not necessarily its true performance.<ref name=abs1502.02127/> Methods that are not [[Robustness (computer science)|robust]] to simple changes in hyperparameters, [[random seed]]s, or even different implementations of the same algorithm cannot be integrated into mission critical control systems without significant simplification and robustification.<ref name=arXiv:1803.07055>{{cite news |arxiv=1803.07055 |title=Mania, Horia, Aurelia Guy, and Benjamin Recht. "Simple random search provides a competitive approach to reinforcement learning." arXiv preprint arXiv:1803.07055 (2018).|bibcode=2018arXiv180307055M}}</ref>

[[Reinforcement learning]] algorithms, in particular, require measuring their performance over a large number of random seeds, and also measuring their sensitivity to choices of hyperparameters.<ref name=arXiv:1803.07055/> Their evaluation with a small number of random seeds does not capture performance adequately due to high variance.<ref name=arXiv:1803.07055/> Some reinforcement learning methods, e.g. DDPG (Deep Deterministic Policy Gradient), are more sensitive to hyperparameter choices than others.<ref name=arXiv:1803.07055/>

== Optimization ==
{{main|Hyperparameter optimization}}

Hyperparameter optimization finds a tuple of hyperparameters that yields an optimal model which minimizes a predefined [[loss function]] on given test data.<ref name=abs1502.02127/>  The objective function takes a tuple of hyperparameters and returns the associated loss.<ref name=abs1502.02127/> Typically these methods are not gradient based, and instead apply concepts from [[derivative-free optimization]] or black box optimization.

== Reproducibility ==
Apart from tuning hyperparameters, machine learning involves storing and organizing the parameters and results, and making sure they are reproducible.<ref name=sacred2015>{{cite news |url=https://indico.lal.in2p3.fr/event/2914/contributions/6476/subcontributions/169/attachments/6034/7159/Sacred_3.pdf |title=Greff, Klaus, and Jürgen Schmidhuber. "Introducing Sacred: A Tool to Facilitate Reproducible Research." |year=2015}}</ref> In the absence of a robust infrastructure for this purpose, research code often evolves quickly and compromises essential aspects like bookkeeping and [[reproducibility]].<ref name=sacred2017>{{cite news |url=http://conference.scipy.org/proceedings/scipy2017/pdfs/klaus_greff.pdf |title=Greff, Klaus, et al. "The Sacred Infrastructure for Computational Research." |year=2017 |access-date=2018-04-06 |archive-date=2020-09-29 |archive-url=https://web.archive.org/web/20200929163559/http://conference.scipy.org/proceedings/scipy2017/pdfs/klaus_greff.pdf |url-status=dead }}</ref> Online collaboration platforms for machine learning go further by allowing scientists to automatically share, organize and discuss experiments, data, and algorithms.<ref name=arXiv:1407.7722>{{cite news |arxiv=1407.7722 |title=Vanschoren, Joaquin, et al. "OpenML: networked science in machine learning." arXiv preprint arXiv:1407.7722 (2014).|bibcode=2014arXiv1407.7722V}}</ref> Reproducibility can be particularly difficult for [[deep learning]] models.<ref>{{cite web |url=https://determined.ai/blog/reproducibility-in-ml/ |title=Reproducibility in ML: why it matters and how to achieve it |last1=Villa |first1=Jennifer |last2= Zimmerman |first2=Yoav |date=25 May 2018 |website=Determined AI Blog |access-date=31 August 2020}}</ref> For example, research has shown that deep learning models depend very heavily even on the [[random seed]] selection of the [[Random number generation|random number generator]].<ref>Bethard, S. (2022). We need to talk about random seeds. ArXiv, abs/2210.13393.</ref>

== See also ==
* [[Hyper-heuristic]]
* [[Replication crisis]]

== References ==
{{Reflist}}

{{Differentiable computing}}

[[Category:Machine learning]]
[[Category:Model selection]]