{{Short description|Data analysis technique}}
{{one source|date=September 2020}}
{{Machine learning}}

'''Data augmentation''' is a technique in [[machine learning]] used to reduce [[overfitting]] when training a machine learning model,<ref name="Big Data 2019 6:60">{{cite journal | last1=Shorten | first1=Connor | last2=Khoshgoftaar | first2=Taghi M. | title=A survey on Image Data Augmentation for Deep Learning | journal=Mathematics and Computers in Simulation | publisher=springer | volume=6 | year=2019 | doi=10.1186/s40537-019-0197-0 | pages=60 | doi-access=free }}</ref> by training models on several slightly-modified copies of existing data.

== Synthetic oversampling techniques for traditional [[machine learning]] ==
{{main|Oversampling and undersampling in data analysis#Oversampling techniques for classification problems}}

== Data augmentation for image classification ==
When [[convolutional neural networks]] grew larger in mid-1990s, there often was not enough available data to train them, especially considering that some part of the overall dataset should be spared for later testing. It was proposed to perturb existing data with affine transformations to create new examples with the same labels,<ref>{{cite book|author=Yann Lecun |display-authors=et. al. |title=Learning algorithms for classification: A comparison on handwritten digit recognition |url=https://nyuscholars.nyu.edu/en/publications/learning-algorithms-for-classification-a-comparison-on-handwritte |website=nyuscholars.nyu.edu |access-date=14 May 2023 |format=Conference paper |year=1995|pages=261–276 |publisher=World Scientific }}</ref> which were complemented by so-called elastic distortions in 2003,<ref>{{cite book | s2cid=4659176 | doi=10.1109/ICDAR.2003.1227801 | chapter=Best practices for convolutional neural networks applied to visual document analysis | title=Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings. | year=2003 | last1=Simard | first1=P.Y. | last2=Steinkraus | first2=D. | last3=Platt | first3=J.C. | volume=1 | pages=958–963 | isbn=0-7695-1960-1 }}</ref> and the technique was widely used as of 2010s.<ref>{{cite arXiv |title=Improving neural networks by preventing co-adaptation of feature detectors |eprint=1207.0580 |last1=Hinton |first1=Geoffrey E. |last2=Srivastava |first2=Nitish |last3=Krizhevsky |first3=Alex |last4=Sutskever |first4=Ilya |last5=Salakhutdinov |first5=Ruslan R. |class=cs.NE |year=2012}}</ref>
{{section stub|date=April 2023}}

== Data augmentation for signal processing ==
[[Bootstrapping (statistics)|Residual or block bootstrap]] can be used for time series augmentation.

=== Biological signals ===
Synthetic data augmentation is of paramount importance for machine learning classification, particularly for biological data, which tend to be high dimensional and scarce. The applications of robotic control and augmentation in disabled and able-bodied subjects still rely mainly on subject-specific analyses. Data scarcity is notable in signal processing problems such as for Parkinson's Disease [[Electromyography]] signals, which are difficult to source - Zanini, et al. noted that it is possible to use a [[generative adversarial network]] (in particular, a DCGAN) to perform style transfer in order to generate synthetic electromyographic signals that corresponded to those exhibited by sufferers of Parkinson's Disease.<ref name="Anicet ZaniniLuna Colombini2020">{{cite journal|last1=Anicet Zanini|first1=Rafael|last2=Luna Colombini|first2=Esther|title=Parkinson's Disease EMG Data Augmentation and Simulation with DCGANs and Style Transfer|journal=Sensors|volume=20|issue=9|year=2020|pages=2605|issn=1424-8220|doi=10.3390/s20092605|pmid=32375217|pmc=7248755|bibcode=2020Senso..20.2605A |doi-access=free}}</ref>

The approaches are also important in [[electroencephalography]] (brainwaves). Wang, et al. explored the idea of using deep [[Convolutional neural network|convolutional neural networks]] for EEG-Based Emotion Recognition, results show that emotion recognition was improved when data augmentation was used.<ref name="WangZhong2018">{{cite book|last1=Wang|first1=Fang|last2=Zhong|first2=Sheng-hua|last3=Peng|first3=Jianfeng|last4=Jiang|first4=Jianmin|last5=Liu|first5=Yan|title=MultiMedia Modeling |chapter=Data Augmentation for EEG-Based Emotion Recognition with Deep Convolutional Neural Networks|series=Lecture Notes in Computer Science|volume=10705|year=2018|pages=82–93|issn=0302-9743|doi=10.1007/978-3-319-73600-6_8|isbn=978-3-319-73599-3}}</ref> 

A common approach is to generate synthetic signals by re-arranging components of real data. Lotte<ref name="Lotte2015">{{cite journal|last1=Lotte|first1=Fabien|title=Signal Processing Approaches to Minimize or Suppress Calibration Time in Oscillatory Activity-Based Brain–Computer Interfaces|journal=Proceedings of the IEEE|volume=103|issue=6|year=2015|pages=871–890|issn=0018-9219|doi=10.1109/JPROC.2015.2404941|s2cid=22472204|url=https://hal.inria.fr/hal-01159171/file/lotte_sigProcCalibReduction-final.pdf }}</ref> proposed a method of ''"Artificial Trial Generation Based on Analogy"'' where three data examples <math>x_{1}, x_{2}, x_{3}</math> provide examples and an artificial <math>x_{synthetic}</math> is formed which is to <math>x_{3}</math> what <math>x_{2}</math> is to <math>x_{1}</math>. A transformation is applied to <math>x_{1}</math> to make it more similar to <math>x_{2}</math>, the same transformation is then applied to <math>x_{3}</math> which generates <math>x_{synthetic}</math>. This approach was shown to improve performance of a Linear Discriminant Analysis classifier on three different datasets.

Current research shows great impact can be derived from relatively simple techniques. For example, Freer<ref name="FreerYang2020">{{cite journal|last1=Freer|first1=Daniel|last2=Yang|first2=Guang-Zhong|title=Data augmentation for self-paced motor imagery classification with C-LSTM|journal=Journal of Neural Engineering|volume=17|issue=1|year=2020|pages=016041|issn=1741-2552|doi=10.1088/1741-2552/ab57c0|pmid=31726440|bibcode=2020JNEng..17a6041F|hdl=10044/1/75376|s2cid=208034533 |hdl-access=free}}</ref> observed that introducing noise into gathered data to form additional data points improved the learning ability of several models which otherwise performed relatively poorly. Tsinganos et al.<ref name="TsinganosCornelis2020">{{cite journal|last1=Tsinganos|first1=Panagiotis|last2=Cornelis|first2=Bruno|last3=Cornelis|first3=Jan|last4=Jansen|first4=Bart|last5=Skodras|first5=Athanassios|title=Data Augmentation of Surface Electromyography for Hand Gesture Recognition|journal=Sensors|volume=20|issue=17|year=2020|pages=4892|issn=1424-8220|doi=10.3390/s20174892|pmid=32872508|pmc=7506981|bibcode=2020Senso..20.4892T |doi-access=free}}</ref> studied the approaches of magnitude warping, wavelet decomposition, and synthetic surface EMG models (generative approaches) for hand gesture recognition, finding classification performance increases of up to +16% when augmented data was introduced during training. More recently, data augmentation studies have begun to focus on the field of deep learning, more specifically on the ability of generative models to create artificial data which is then introduced during the classification model training process. In 2018, Luo et al.<ref name="LuoLu2018">{{cite book|last1=Luo|first1=Yun|last2=Lu|first2=Bao-Liang|title=2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)|chapter=EEG Data Augmentation for Emotion Recognition Using a Conditional Wasserstein GAN|year=2018|volume=2018|pages=2535–2538|doi=10.1109/EMBC.2018.8512865|pmid=30440924|isbn=978-1-5386-3646-6|s2cid=53105445}}</ref> observed that useful EEG signal data could be generated by Conditional Wasserstein Generative Adversarial Networks (GANs) which was then introduced to the training set in a classical train-test learning framework. The authors found classification performance was improved when such techniques were introduced.

=== Mechanical  signals ===
The prediction of mechanical signals based on data augmentation brings a new generation of technological innovations, such as new energy dispatch, 5G communication field, and robotics control engineering.<ref name="YangYang2022">{{cite journal|last1=Yang|first1=Yang|title=Wind speed forecasting with correlation network pruning and augmentation: A two-phase deep learning method|journal=Renewable Energy|volume=198|issue=1|year=2022|pages=267–282|issn=0960-1481|doi=10.1016/j.renene.2022.07.125|arxiv=2306.01986 |s2cid=251511199 }}</ref> In 2022, Yang et al.<ref name="YangYang2022"/> integrate constraints, optimization and control into a deep network framework based on data augmentation and data pruning with spatio-temporal data correlation, and improve the interpretability, safety and controllability of deep learning in real industrial projects through explicit mathematical programming equations and analytical solutions.

== See also ==
* [[Oversampling and undersampling in data analysis]]
* [[Generative adversarial network]]
* [[Variational autoencoder]]
* [[Data pre-processing]]
* [[Convolutional neural network]]
* [[Regularization (mathematics)]]
* [[Data preparation]]
* [[Data fusion]]

==References==
{{reflist}}

{{Differentiable computing}}
{{data}}

[[Category:Machine learning]]