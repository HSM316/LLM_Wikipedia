{{Short description|Cloud-based computer vision platform}}
{{Infobox software
| name = Amazon Rekognition
| developer = [[Amazon (company)|Amazon]], [[Amazon Web Services]]
| released = {{Start date and age|2016|11|30|df=yes}}<ref name=":0">{{cite web|url=http://social.techcrunch.com/2016/11/30/amazon-launches-amazon-ai-to-bring-its-machine-learning-smarts-to-developers/|last=Lardinois|first=Frederic|date=2016-11-30|title=Amazon launches Amazon AI to bring its machine learning smarts to developers|work=TechCrunch|access-date=2019-07-21}}</ref>
| genre = [[Software as a service]]
| website = {{URL|https://aws.amazon.com/rekognition}}
}}

'''Amazon Rekognition''' is a [[Cloud computing|cloud]]-based [[software as a service]] (SaaS) [[computer vision]] platform that was launched in 2016. It has been sold to, and used by a number of United States government agencies, including [[U.S. Immigration and Customs Enforcement|U.S. Immigration and Customs Enforcement (ICE)]] and [[Orlando Police Department|Orlando, Florida police]], as well as private entities.

== Capabilities ==
Rekognition provides a number of computer vision capabilities, which can be divided into two categories: Algorithms that are pre-trained on data collected by Amazon or its partners, and algorithms that a user can train on a custom dataset.

As of July 2019, Rekognition provides the following computer vision capabilities.<ref name=":0" /><ref>{{Cite web|url=https://docs.aws.amazon.com/rekognition/latest/dg/what-is.html|title=What Is Amazon Rekognition?|website=Amazon Rekognition Developer Guide|access-date=2019-07-21}}</ref>

=== Pre-trained algorithms ===

* ''Celebrity recognition'' in images<ref>{{Cite web|url=https://aws.amazon.com/rekognition/the-facts-on-facial-recognition-with-artificial-intelligence/|title=What is the Celebrity Recognition API? Is that the same or different than doing a face search?|website=AWS|access-date=2019-07-21}}</ref><ref>{{Cite news|url=https://techcrunch.com/2017/06/08/amazon-rekognition-can-now-recognize-celebrities/|title=Amazon Rekognition can now recognize celebrities|last=Lardinois|first=Frederic|date=2016-06-08|work=TechCrunch|access-date=2019-07-21}}</ref>
* ''Facial attribute'' ''detection'' in images, including gender, age range, emotions (e.g. happy, calm, disgusted), whether the face has a beard or mustache, whether the face has eyeglasses or sunglasses, whether the eyes are open, whether the mouth is open, whether the person is smiling, and the location of several markers such as the pupils and jaw line.<ref>{{Cite web|url=https://docs.aws.amazon.com/rekognition/latest/dg/faces-detect-images.html|title=Detecting Faces in an Image|website=Amazon Rekognition Developer Guide|access-date=2019-07-21}}</ref><ref>{{Cite news|url=http://www.planetbiometrics.com/article-details/i/10064/desc/amazon-rekognition-launches-enhanced-face-analysis/|title=Amazon Rekognition launches enhanced face analysis|date=2019-03-19|work=Planet Biometrics|access-date=2019-07-21}}</ref>
* ''People Pathing'' enables tracking of people through a video. An advertised use-case of this capability is to track sports players for post-game analysis.<ref name=":0" /><ref>{{Cite web|url=https://docs.aws.amazon.com/rekognition/latest/dg/persons.html|title=People Pathing|website=Amazon Rekognition Developer Guide|access-date=2019-07-21}}</ref>
* ''Text detection and classification'' in images<ref>{{Cite web|url=https://docs.aws.amazon.com/rekognition/latest/dg/text-detection.html|title=Detecting Text|website=Amazon Rekognition Developer Guide|access-date=2019-07-21}}</ref><ref name=":1" />
* ''Unsafe visual content detection''<ref>{{Cite web|url=https://docs.aws.amazon.com/rekognition/latest/dg/moderation.html|title=Detecting Unsafe Content|website=Amazon Rekognition Developer Guide|access-date=2019-07-21}}</ref>

=== Algorithms that a user can train on a custom dataset ===

* ''SearchFaces'' enables users to import a [[database]] of images with [[List of manual image annotation tools|pre-labeled]] faces, to train a machine learning model on this database, and to expose the model as a cloud service with an [[Application programming interface|API]]. Then, the user can post new images to the API and receive information about the faces in the image. The API can be used to expose a number of capabilities, including identifying faces of known people, comparing faces, and finding similar faces in a database.<ref>{{Cite web|url=https://docs.aws.amazon.com/rekognition/latest/dg/collections.html|title=Searching Faces in a Collection|website=Amazon Rekognition Developer Guide|access-date=2019-07-21}}</ref><ref name=":2" />
* ''Face-based user verification''<ref name=":0" />

== History and use ==

===2017===
In late 2017, the [[Washington County, Oregon]] Sheriff's Office began using Rekognition to identify [[suspect]]s' faces. Rekognition was marketed as a general-purpose computer vision tool, and an engineer working for Washington County decided to use the tool for facial analysis of suspects.<ref name=":2">{{Cite news|url=https://www.oregonlive.com/washingtoncounty/2019/05/amazons-facial-recognition-technology-is-supercharging-washington-county-police.html|title=Amazon's facial-recognition technology is supercharging Washington County police|work=Oregon Live|access-date=2019-07-21}}</ref><ref>{{Cite web|url=https://aws.amazon.com/rekognition/customers/|title=Amazon Rekognition Customers|website=AWS|access-date=2019-07-21}}</ref> Rekognition was offered to the department for free,<ref name="EC"/> and Washington County became the first US law enforcement agency known to use Rekognition. In 2018, the agency logged over 1,000 facial searches. The county, according to the ''Washington Post,'' by 2019 was paying about $7 a month for all of its searches.<ref name="EG">{{cite news|last=Harwell |first=Drew |date=April 30, 2019 |title=Oregon became a testing ground for Amazon's facial-recognition policing. But what if Rekognition gets it wrong? |url=https://www.washingtonpost.com/technology/2019/04/30/amazons-facial-recognition-technology-is-supercharging-local-police/ |work=[[The Washington Post]] |access-date= August 27, 2019}}</ref> The relationship was unknown to the public until May 2018.<ref name="EC">{{cite news|last=Glaser |first=April |date=July 19, 2019 |title=How to Not Build a Panopticon |url=https://slate.com/technology/2019/07/amazon-rekognition-surveillance-panopticon.html |work=[[Slate (magazine)|Slate]] |access-date= August 27, 2019}}</ref> In 2018, Rekognition was also used to help identify celebrities during a royal wedding telecast.<ref name="HK"/>

===2018===
In April 2018, it was reported that [[FamilySearch]] was using Rekognition to enable their users to "see which of their ancestors they most resemble based on family photographs".<ref>{{Cite news|url=https://aws.amazon.com/about-aws/whats-new/2018/04/amazon-rekognition-improves-accuracy-of-real-time-face-recognition-and-verification/|title=Amazon Rekognition Improves Accuracy of Real-Time Face Recognition and Verification|date=2018-04-02|work=AWS|access-date=2019-07-21}}</ref> In early 2018, the [[Federal Bureau of Investigation|FBI]] also began using it as a pilot program for analyzing video surveillance.<ref name="HK"/>

In May 2018, it was reported by the [[ACLU]] that [[Orlando, Florida]] was running a pilot using Rekognition for facial analysis in law enforcement,<ref>{{Cite news|url=https://www.theverge.com/2018/5/22/17379968/amazon-rekognition-facial-recognition-surveillance-aclu|title=Amazon is selling police departments a real-time facial recognition system|last=Brandom|first=Russell|date=2018-05-22|work=The Verge|access-date=2019-07-21}}</ref> with that pilot ending in July 2019.<ref>{{Cite news|url=https://www.theverge.com/2019/7/18/20700072/amazon-rekognition-pilot-program-orlando-florida-law-enforcement-ended|title=Orlando police once again ditch Amazon's facial recognition software|last=Statt|first=Nick|date=2019-07-18|work=The Verge|access-date=2019-07-21}}</ref> After the report,<ref name="AB"/><ref name="AD"/> on June 22, 2018, [[Gizmodo]] reported that Amazon workers had written a letter to CEO [[Jeff Bezos]] requesting he cease selling Rekognition to US law enforcement, particularly ICE and [[Homeland Security]].<ref name="AD">{{cite news|last=Keane |first=Sean |date=June 22, 2018 |title=Amazon employees protest sale of face recognition software to police |url=https://www.cnet.com/news/amazon-employees-want-jeff-bezos-to-stop-selling-facial-recognition-software-to-law-enforcement/ |work=[[CNET]] |access-date= August 27, 2019}}</ref> A letter was also sent to Bezos by the ACLU.<ref name="AB"/> On June 26, 2018, it was reported that the Orlando police force had ceased using Rekognition after their trial contract expired, reserving the right to use it in the future.<ref name="AB">{{cite news|last=Zhou |first=Marrian |date=June 26, 2018 |title=Orlando stops using Amazon's controversial facial recognition tech |url=https://www.cnet.com/news/orlando-stops-using-amazons-controversial-facial-recognition-tech/ |work=[[CNET]] |access-date= August 27, 2019}}</ref> The Orlando Police Department said that they had "never gotten to the point to test images" due to old infrastructure and low bandwidth.<ref name="EC"/>

In July 2018, the ACLU released a test showing that Rekognition had falsely matched 28 members of Congress with mugshot photos, particularly Congresspeople of color. 25 House members afterwards sent a letter to Bezos, expressing concern about Rekognition.<ref name="EA"/> Amazon responded saying the Rekognition test had generated 80 percent confidence, while it recommended law enforcement only use matches rated at 99 percent confidence.<ref name="HA"/> ''The Washington Post'' states that Oregon instead has officers pick a "best of five" result, instead of adhering to the recommendation.<ref name="EG"/>

In September 2018, it was reported that [[Mapillary]] was using Rekognition to read the text on parking signs (e.g. no stopping, no parking, or specific parking hours) in cities.<ref name=":1">{{Cite news|url=https://venturebeat.com/2018/09/13/mapillary-strikes-computer-vision-partnership-with-amazon-rekognition-to-ease-urban-parking-crunch/|title=Mapillary will use Amazon Rekognition in effort to ease urban parking crunch|last=O'Brien|first=Chris|date=2018-09-13|work=Venture Beat|access-date=2019-07-21}}</ref>

In October 2018, it was reported that Amazon had earlier that year pitched Rekognition to [[U.S. Immigration and Customs Enforcement]] agency.<ref name="EA">{{cite news|last=Singh Guliani |first=Neema |date=October 24, 2018 |title=Amazon Met With ICE Officials to Market Its Facial Recognition Product |url=https://www.aclu.org/blog/privacy-technology/surveillance-technologies/amazon-met-ice-officials-market-its-facial |work=[[ACLU]] |access-date= August 27, 2019}}</ref><ref name="DU">{{cite news|last=Day |first=Matt |date=October 23, 2018 |title=Amazon Officials Pitched Their Facial Recognition Software to ICE |url=https://www.seattletimes.com/business/amazon/amazon-officials-pitched-their-facial-recognition-software-to-ice/ |work=[[The Seattle Times]] |access-date= August 27, 2019}}</ref> Amazon defended government use of Rekognition.<ref name="HA">{{cite news|last=Statt |first=Nick |date=November 8, 2018 |title=Amazon told employees it would continue to sell facial recognition software to law enforcement |url=https://www.theverge.com/2018/11/8/18077292/amazon-rekognition-jeff-bezos-andrew-jassy-facial-recognition-ice-rights-violations |work=[[The Verge]] |access-date= August 27, 2019}}</ref>
 
On December 1, 2018, it was reported that 8 Democratic lawmakers had said in a letter that Amazon had "failed to provide sufficient answers" about Rekognition, writing that they had "serious concerns that this type of product has significant accuracy issues, places disproportionate burdens on communities of color, and could stifle Americans' willingness to exercise their First Amendment rights in public."<ref name="DK">{{cite news|last=Boyce |first=Jasmin |date=December 1, 2018 |title=Lawmakers demand answers from Amazon on facial recognition tech |url=https://www.nbcnews.com/tech/tech-news/eight-lawmakers-demand-answers-amazon-facial-recognition-tech-n942476 |work=[[NBC News]] |access-date= August 27, 2019}}</ref>

===2019===
In January 2019, [[MIT]] researchers published a peer-reviewed study asserting that Rekognition had more difficulty in identifying dark-skinned females than competitors such as [[IBM]] and [[Microsoft]].<ref name="HK"/> In the study, Rekognition misidentified darker-skinned women as men 31% of the time, but made no mistakes for light-skinned men.<ref name="EC"/> Amazon called the report "misinterpreted results" of the research with an improper "default confidence threshold."<ref name="HK"/>

In January 2019, Amazon's shareholders "urged Amazon to stop selling Rekognition software to law enforcement agencies." Amazon in response defended its use of Rekognition, but supported new federal oversight and guidelines to "make sure facial recognition technology cannot be used to discriminate."<ref name="HJ"/> In February 2019, it was reported that Amazon was collaborating with the [[National Institute of Standards and Technology]] (NIST) on developing standardized tests to improve accuracy and remove bias with facial recognition.<ref name="HI">{{cite news|last=Lacy |first=Lisa |date=February 19, 2019 |title=Amazon Rekognition May Finally Be Audited and Ranked Alongside Other Vendors |url=https://www.adweek.com/digital/amazon-rekognition-may-finally-be-audited-and-ranked-alongside-other-vendors/ |work=[[Adweek]] |access-date= August 27, 2019}}</ref><ref name="EB">{{cite news|last=Hale |first=Kori |date=March 12, 2019 |title=Auditing Amazon's 'Rekognition' A.I. Could Remove Bias |url=https://www.forbes.com/sites/korihale/2019/03/12/auditing-amazons-rekognition-a-i-could-remove-bias/#1b3027865b21 |work= [[Forbes]]|access-date= August 27, 2019}}</ref>

In March 2019, an open letter regarding Rekognition was sent by a group of prominent AI researchers to Amazon, criticizing its sale to law enforcement<ref name="HJ">{{cite news|last=Crist |first=Ry |date=March 19, 2019 |title=Amazon's Rekognition software lets cops track faces: Here's what you need to know |url=https://www.cnet.com/news/what-is-amazon-rekognition-facial-recognition-software/ |work=[[CNET]] |access-date= August 27, 2019}}</ref> with around 50 signatures.<ref name="HK"/>

In April 2019, Amazon was told by the [[Securities and Exchange Commission]] that they had to vote on two shareholder proposals seeking to limit Rekognition. Amazon argued that the proposals were an "insignificant public policy issue for the Company" not related to Amazon's ordinary business, but their appeal was denied.<ref name="HK">{{cite news|last=Pasternack |first=Alex |date=April 4, 2019 |title=Amazon says face recognition fears are "insignificant." The SEC disagrees |url=https://www.fastcompany.com/90329464/amazon-cant-block-investor-vote-on-face-recognition-says-sec |work=[[Fast Company]] |access-date= August 27, 2019}}</ref> The vote was set for May.<ref name="EG"/><ref name="EF">{{cite news|last=Singer |first=Natasha |date=May 5, 2019 |title=Amazon Faces Investor Pressure Over Facial Recognition |url=https://www.nytimes.com/2019/05/20/technology/amazon-facial-recognition.html |work=[[The New York Times]] |access-date= August 27, 2019}}</ref> The first proposal was tabled by shareholders.<ref name="ED">{{cite news|last=Whittaker |first=Zack |date=May 20, 2019 |title=Amazon under greater shareholder pressure to limit sale of facial recognition tech to the government |url=https://techcrunch.com/2019/05/20/amazon-shareholder-pressure-face-recognition/ |work=[[TechCrunch]] |access-date= August 27, 2019}}</ref> On May 24, 2019, 2.4% of shareholders voted to stop selling Rekognition to government agencies, while a second proposal calling for a study into Rekognition and civil rights had 27.5% support.<ref name="DE">{{cite news|last=Dastin |first=Jeffrey |date=May 24, 2019 |title=Amazon facial recognition ban won just 2% of shareholder vote |url=https://www.reuters.com/article/us-amazon-com-facial-recognition/at-amazon-facial-recognition-ban-won-just-2-of-shareholder-vote-idUSKCN1SU2H5 |work=[[Reuters]] |access-date= August 27, 2019}}</ref>
 
In August 2019, the ACLU again used Rekognition on members of government, with 26 of 120 lawmakers in California flagged as matches to mugshots. Amazon stated the ACLU was "misusing" the software in the tests, by not dismissing results that did not meet Amazon's recommended accuracy threshold of 99%.<ref name="HAH">{{cite news|last=Wehner |first=Mike |date=August 14, 2019 |title=Amazon's facial recognition system flags dozens of California lawmakers as criminals |url=https://bgr.com/2019/08/14/rekognition-test-amazon-facial-software/ |work=[[Boy Genius Report|BGR]] |access-date= August 27, 2019}}</ref> By August 2019, there had been protests against ICE's use of Rekognition to surveil immigrants.<ref name="DB">{{cite news|last=Protalinski |first=Emil |date=August 16, 2019 |title=ProBeat: Breakthrough or BS, Amazon's Rekognition is dangerous |url=https://venturebeat.com/2019/08/16/probeat-breakthrough-or-bs-amazons-rekognition-is-dangerous/ |work=[[VentureBeat]] |access-date= August 27, 2019}}</ref>

In March 2019, Amazon announced a Rekognition update that would improve emotional detection,<ref name="EG"/> and in August 2019, "fear" was added to emotions that Rekognition could detect.<ref name="DA">{{cite news|last=Menegus |first=Bryan |date=August 13, 2019 |title=Amazon Rekognition Can Now Identify the Emotion It Provokes in Rational People |url=https://gizmodo.com/amazon-rekognition-can-now-identify-the-emotion-it-prov-1837214151 |work=[[Gizmodo]] |access-date= August 27, 2019}}</ref><ref name="DC">{{cite news|last=Crowe |first=Michael |date=August 15, 2019 |title=Amazon says facial recognition can detect fear, raising concern for some privacy advocates |url=https://www.king5.com/article/news/local/amazon-says-facial-recognition-can-detect-fear-raising-concern-for-some-privacy-advocates/281-257712b2-5947-43b1-af93-37f064b7b902 |work=[[King5]] |access-date= August 27, 2019}}</ref><ref name="AA">{{cite news|last=Mihalcik |first=Carrie |date=August 15, 2019 |title=Amazon's Rekognition software can now spot fear |url=https://www.cnet.com/news/amazons-rekognition-software-can-now-detect-fear/ |work=[[CNET]] |access-date= August 27, 2019}}</ref>

===2020===
In June 2020, Amazon announced it was implementing a one-year [[Moratorium (law)|moratorium]] on police use of Rekognition, in response to the [[George Floyd protests]].<ref name="BLM">{{cite news|url=https://blog.aboutamazon.com/policy/we-are-implementing-a-one-year-moratorium-on-police-use-of-rekognition|date=June 10, 2020|title=We are implementing a one-year moratorium on police use of Rekognition|access-date=June 19, 2020}}</ref>

== Controversy regarding facial analysis ==

=== Racial and gender bias ===
In 2018, [[MIT]] researchers [[Joy Buolamwini]] and [[Timnit Gebru]] published a study called Gender Shades.<ref>{{Cite journal|last=Buolamwini|first=Joy|last2=Gebru|first2=Timnit|date=2018|title=Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification|url=http://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf|journal=Proceedings of Machine Learning Research}}</ref><ref>{{Cite news|url=https://www.theregister.co.uk/2018/02/13/facial_recognition_software_is_better_at_white_men_than_black_women|title=Facial recognition software easily IDs white men, but error rates soar for black women|last=Quach|first=Katyanna|date=2018-02-13|work=The Register|access-date=2019-07-21}}</ref> In this study, a set of images was collected, and faces in the images were labeled with face position, gender, and skin tone information. The images were run through [[SaaS]] facial recognition platforms from [[Megvii|Face++]], [[IBM]], and [[Microsoft]]. In all three of these platforms, the classifiers performed best on male faces (with error rates on female faces being 8.1% to 20.6% higher than error rates on male faces), and they performed worst on dark female faces (with error rates ranging from 20.8% to 30.4%). The authors hypothesized that this discrepancy is due principally to Megvii, IBM, and Microsoft having more light males than dark females in their training data, i.e. dataset bias.

In January 2019, researchers Inioluwa Deborah Raji and Joy Buolamwini published a follow-up paper that ran the experiment again a year later, on the latest versions same three SaaS facial recognition platforms, plus two additional platforms: Kairos, and Amazon Rekognition.<ref>{{Cite journal|last=Raji|first=Inioluwa Deborah|last2=Buolamwini|first2=Joy|date=2019-01-27|title=Actionable Auditing: Investigating the Impact of Publicly Naming Biased Performance Results of Commercial AI Products|url=http://www.aies-conference.com/wp-content/uploads/2019/01/AIES-19_paper_223.pdf|journal=AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society}}</ref><ref>{{Cite news|url=https://venturebeat.com/2019/01/24/amazon-rekognition-bias-mit/|title=MIT researchers: Amazon's Rekognition shows gender and ethnic bias (updated)|last=Wiggers|first=Kyle|date=2019-01-24|work=Venture Beat|access-date=2019-07-21}}</ref> While the systems' overall error-rates improved over the previous year, all five of the systems again performed better on male faces than on dark female faces.

== See also ==

* [[Amazon Lex]]
* [[Amazon Mechanical Turk]]
* [[Amazon Polly]]
* [[Amazon SageMaker]]
* [[Amazon Web Services]]
*[[Facial recognition system]]
* [[Timeline of Amazon Web Services]]

== References ==

<references />

{{Amazon}}

[[Category:2016 software]]
[[Category:Amazon (company)|Rekognition]]
[[Category:Amazon Web Services|Rekognition]]
[[Category:Cloud infrastructure]]
[[Category:Computer vision software]]
[[Category:Data mining and machine learning software]]
[[Category:Facial recognition software]]
[[Category:Object recognition and categorization]]