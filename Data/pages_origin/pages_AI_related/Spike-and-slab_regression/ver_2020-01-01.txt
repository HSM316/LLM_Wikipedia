In statistics, '''spike-and-slab regression''' is a Bayesian [[Feature selection|variable selection]] technique that is particularly useful when the number of possible predictors is larger than the number of observations.<ref>{{Cite web|url=http://people.ischool.berkeley.edu/~hal/Papers/2013/ml.pdf|title=Big Data: New Tricks for Econometrics|last=|first=|date=|website=|publisher=|access-date=}}</ref>

Initially, the idea of the spike-and-slab model was proposed by Mitchell & Beauchamp (1988).<ref>{{Cite web|url=https://www2.stat.duke.edu/courses/Fall05/sta395/joelucas1.pdf|title=Bayesian variable selection in linear regression|last=|first=|date=|website=|publisher=|access-date=}}</ref> The approach was further significantly developed by Madigan & Raftery (1994)<ref>{{Cite web|url=http://www.stat.cmu.edu/~fienberg/Statistics36-756/MadiganRaftery-JASA-1994.pdf|title=Model selection and accounting for model uncertainty in graphical models using occam’s window|last=|first=|date=|website=|publisher=|access-date=}}</ref> and George & McCulloch (1997).<ref>{{Cite web|url=http://www-stat.wharton.upenn.edu/~edgeorge/Research_papers/GeorgeMcCulloch97.pdf|title=Approaches for Bayesian variable selection|last=|first=|date=|website=|publisher=|access-date=}}</ref> The final adjustments to the model were done by Ishwaran & Rao (2005).<ref>{{Cite web|url=https://arxiv.org/pdf/math/0505633.pdf|title=Spike and slab variable selection: frequentist and Bayesian strategies|last=|first=|date=|website=|publisher=|access-date=}}</ref>

== Model description ==
Suppose we have ''P'' possible predictors in some model. Vector ''γ'' has a length equal to ''P'' and consists of zeros and ones. This vector indicates whether a particular variable is included in the regression or not. If no specific prior information on initial inclusion probabilities of particular variables is available, a [[Bernoulli distribution|Bernoulli prior]] distribution is a common default choice.<ref name=":0">{{Cite web|url=http://people.ischool.berkeley.edu/~hal/Papers/2013/pred-present-with-bsts.pdf|title=Predicting the present with bayesian structural time series|last=|first=|date=|website=|publisher=|access-date=}}</ref> Conditional on a predictor being in the regression, we identify a [[Prior probability|prior distribution]] for the model coefficient, which corresponds to that variable (''β''). A common choice on that step is to use a [[Normal distribution|Normal]] prior with mean equal to zero and a large variance calculated based on <math>(X^TX)^{-1}</math> (where <math>X</math> is a [[design matrix]] of explanatory variables of the model).<ref>{{Cite web|url=http://people.ischool.berkeley.edu/~hal/Papers/2012/fat.pdf|title=Bayesian variable selection for nowcasting economic time series|last=|first=|date=|website=|publisher=|access-date=}}</ref>

A draw of ''γ'' from its prior distribution is a list of the variables included in the regression. Conditional on this set of selected variables, we take a draw from the prior distribution of the regression coefficients (if ''γ''<sub>''i''</sub> = 1 then ''β''<sub>''i''</sub> ≠ 0 and if ''γ''<sub>''i''</sub> = 0 then ''β''<sub>''i''</sub> = 0). ''βγ'' denotes the subset of ''β'' for which ''γ''<sub>''i''</sub> = 1. In the next step, we calculate a [[posterior probability]] distribution for both inclusion and coefficients by applying a standard statistical procedure.<ref>{{Cite web|url=http://research.google.com/pubs/pub41854.html|title=Inferring causal impact using Bayesian structural time-series models|last=|first=|date=|website=|publisher=|access-date=}}</ref> All steps of the described algorithm are repeated thousands of times using [[Markov chain Monte Carlo]] (MCMC) technique. As a result, we obtain a posterior distribution of ''γ'' (variable inclusion in the model), ''β'' (regression coefficient values) and the corresponding prediction of ''y''.

The model got its name (spike-and-slab) due to the shape of the two prior distributions. The "spike" is the probability of a particular coefficient in the model to be zero. The "slab" is the prior distribution for the regression coefficient values.

An advantage of Bayesian variable selection techniques is that they are able to make use of prior knowledge about the model. In the absence of such knowledge, some reasonable default values can be used; to quote Scott and Varian (2013): "For the analyst who prefers simplicity at the cost of some reasonable assumptions, useful prior information can be reduced to an expected model size, an expected ''R''<sup>2</sup>, and a sample size ''ν'' determining the weight given to the guess at ''R''<sup>2</sup>."<ref name=":0" /> Some researchers suggest the following default values: ''R''<sup>2</sup> = 0.5, ''ν'' = 0.01, and {{pi}} = 0.5 (parameter of a prior Bernoulli distribution).<ref name=":0" />

A possible drawback of the Spike-and-Slab model can be its mathematical complexity (in comparison to linear regression). A deep understanding of this model requires sound knowledge in [[stochastic process]]es. On the other hand, some modern statistical software (e.g. [[R (programming language)|R]]) have ready-to-use solutions for calculating various Bayesian variable selection models.<ref>{{Cite web|url=https://cran.r-project.org/web/packages/spikeslab/spikeslab.pdf|title=spikeslab|last=|first=|date=|website=|publisher=|access-date=}}</ref><ref>{{Cite web|url=https://cran.r-project.org/web/packages/spikeSlabGAM/vignettes/UsingSpikeSlabGAM.pdf|title=spikeSlabGAM|last=|first=|date=|website=|publisher=|access-date=}}</ref><ref>{{Cite web|url=https://cran.r-project.org/web/packages/bsts/bsts.pdf|title=bsts|last=|first=|date=|website=|publisher=|access-date=}}</ref> In this case, it would be enough for a researcher to know the idea of the method, required model parameters and input variables. The analysis of the model outcomes (distribution of ''γ'', ''β'', and corresponding predictions of ''y'') can be more challenging in comparison to linear regression case. The spike-and-slab model produces inclusion probabilities for each of possible predictors. This can cause difficulties when comparing results to the studies with simple regression (usually only regression coefficients with corresponding statistics are available).

== See also ==
* [[Bayesian inference using Gibbs sampling]]
* [[Bayesian structural time series]]

== Notes ==

{{Empty section|date=April 2016}}

==References==
{{Reflist}}

[[Category:Machine learning]]
[[Category:Bayesian inference]]
[[Category:Bayesian statistics]]