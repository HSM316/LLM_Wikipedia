{{short description|Social Humanoid Robot}}
{{Infobox robot
| name             = Nadine
| image            = Nadine Robot.jpg
| imsize           = 150px
| alt              = 
| caption          = 
| year_of_creation = 2013
}}

'''Nadine''' is a female humanoid [[social robot]] that is modelled on [[Nadia Magnenat Thalmann|Professor Nadia Magnenat Thalmann]].<ref>{{Cite news|url=https://www.srf.ch/sendungen/reporter/nadia-und-nadine|title=Nadia und Nadine|last= Gieriet|first= Marc|date=2016-10-09|work=SRF Schweizer Radio und Fernsehen|access-date=2016-10-10}}</ref> The robot has a strong human-likeness with a natural-looking skin and hair and realistic hands. Nadine is a socially intelligent robot which returns a greeting, makes eye contact, and can remember all the conversations had with it. It is able to answer questions autonomously in several languages, simulate emotions both in gestures and facially, depending on the content of the interaction with the user.<ref>[http://www.8days.sg/seeanddo/thingstodo/chat-with-a-female-robot-who-s-made-to-look-just-like-her-8882876 Media coverage on Nadine exhibition]</ref><ref>{{Cite news|url=https://www.bbc.com/news/business-39255244|title=Is robotics a solution to the growing needs of the elderly?|last=Mulligan|first=Gabriella|date=2017-03-17|work=BBC|access-date=2017-03-17}}</ref><ref>{{Cite news|url=https://www.reuters.com/article/singapore-humanoid-idUSKCN0W9120|title=Now you're talking: human-like robot may one day care for dementia patients|last= Lim|first= Paige|date=2016-03-07|work=Reuters|access-date=2016-03-09}}</ref> Nadine can recognise persons it has previously seen, and engage in flowing conversation.<ref>{{Cite news|url=https://www.8days.sg/seeanddo/thingstodo/chat-with-a-female-robot-who-s-made-to-look-just-like-her-8882876|title=Chat With A Female Robot (Who's Made To Look Just Like Her Creator)|last= Lee|first= Jocelyn|date=2017-05-27|work=8 Days|access-date=2017-06-08}}</ref><ref>J Ren, X Jiang and J Yuan, [http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=7178221&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D7178221 Quantized Fuzzy LBP for Face Recognition], 40th IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2015, Brisbane, Australia, 2015</ref><ref>{{Cite news|url=http://media.ntu.edu.sg/NewsReleases/Pages/newsdetail.aspx?news=fde9bfb6-ee3f-45f0-8c7b-f08bc1a9a179|title=NTU scientists unveil social and telepresence robots|date=2015-12-29|work=Nanyang Technological University|access-date=2016-01-14}}</ref> Nadine has been programmed with a "personality", in that its demeanour can change according to what is said to it.<ref>Kochanowicz J, A. H. Tan and D. Thalmann, [http://dl.acm.org/citation.cfm?id=2915951 Modeling human-like non-rationality for social agents], Proceedings of the ACM 29th International Conference on Computer Animation and Social Agents (CASA 2016), pp. 11-20, Geneva, Switzerland, May 23–25, 2016</ref> Nadine has a total of 27 [[Degrees of freedom (mechanics)|degrees of freedom]] for facial expressions and upper body movements. With persons it has previously encountered, it remembers facts and events related to each person.<ref>J. Zhang J, N. Magnenat Thalmann and J. Zheng, [http://dl.acm.org/citation.cfm?id=2915952 Combining Memory and Emotion With Dialog on Social Companion: A Review], Proceedings of the ACM 29th International Conference on Computer Animation and Social Agents (CASA 2016), pp. 1-9, Geneva, Switzerland, May 23–25, 2016</ref><ref>{{Cite news|url=https://www.ibtimes.com/humanlike-social-robot-nadine-can-feel-emotions-has-good-memory-scientists-claim-2245600|title=Humanlike, Social Robot 'Nadine' Can Feel Emotions And Has A Good Memory, Scientists Claim|last= Berger|first= Sarah|date=2015-12-31|work=International Business Times|access-date=2016-01-12}}</ref> It can assist people with special needs by reading stories, showing images, put on [[Skype]] sessions, send emails, and communicate with other members of the family.<ref>A. Beck, Z. Zhang and N. Magnenat Thalmann, [https://link.springer.com/chapter/10.1007%2F978-3-319-19947-4_11 Motion Control for Social Behaviors], Context Aware Human-Robot and Human-Agent Interaction, Springer International Publishing, 237-256, 2015</ref><ref>Z.P. Bian, J. Hou, L.P. Chau and N. Magnenat Thalmann, [http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=6804646&url=http%3A%2F%2Fieeexplore.ieee.org%2Fiel7%2F6221020%2F6363502%2F06804646.pdf%3Farnumber%3D6804646 Fall Detection Based on Body Part Tracking Using a Depth Camera], IEEE Journal of Biomedical and Health Informatics, Vol. 19, No. 2, Pp. 430-439, 2015</ref><ref name= PCMD2015>J. Zhang, J. Zheng and N. Magnenat Thalmann, [https://onlinelibrary.wiley.com/doi/abs/10.1002/cav.1660 PCMD: personality‐characterized mood dynamics model toward personalized virtual characters], Computer Animation and Virtual Worlds, Vol. 26, Issue 3-4, Pp. 237-245, 2015</ref><ref>J. Zhang, J. Zheng and N. Magnenat Thalmann, [https://link.springer.com/chapter/10.1007%2F978-3-319-19947-4_10 Modeling Personality, Mood, and Emotions], Context Aware Human-Robot and Human-Agent Interaction, Springer International Publishing, 211-236, 2015</ref> It can play the role of a receptionist in an office or be dedicated to be a personal coach.<ref>Y. Xiao, Z. Zhang, A. Beck, J. Yuan and D. Thalmann, [http://dl.acm.org/citation.cfm?id=2812351 Human-Robot Interaction by Understanding Upper Body Gestures], MIT Press Journals - Presence: Teleoperators and Virtual Environments, Vol. 23, No. 2, Pp. 133-154, 2014</ref><ref>Z. Yumak, J. Ren, N. Magnenat Thalmann, and J. Yuan, [http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=6894039&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D6894039 Modelling Multi-Party Interactions among Virtual Characters, Robots, and Humans], MIT Press Journals - Presence: Teleoperators and Virtual Environments, Vol. 23, No. 2, Pp. 172-190, 2014</ref>

Nadine interacted with more than 100,000 visitors at the ArtScience Museum in Singapore during the exhibition, "HUMAN+: The Future of our Species", that was held from May to October 2017.<ref>{{Cite news|url= https://www.channelnewsasia.com/news/lifestyle/singapore-robot-nadine-public-debut-art-science-museum-8857788 |title= Singapore's receptionist robot makes her public debut at ArtScience Museum's futuristic show|last=Martin|first=Mayo|date=2017-05-19|work= Channel NewsAsia|access-date=2017-05-19}}</ref><ref>{{Cite news|url=https://www.straitstimes.com/lifestyle/entertainment/conversation-with-a-humanoid-robot|title=Conversation with a humanoid robot|last= Wong|first= Cara|date=2017-05-19|work=The Straits Times|access-date=2016-03-09}}</ref><ref>[https://www.8days.sg/seeanddo/thingstodo/chat-with-a-female-robot-who-s-made-to-look-just-like-her-8882876 Chat With A Female Robot (Who's Made To Look Just Like Her Creator)]</ref> Presently, Nadine is working as a customer service agent in AIA Insurance Company in Singapore.<ref name= AIAPress>{{Cite news|url= https://www.aia.com.sg/en/about-aia/media-centre/press-releases/2018/aia-to-pioneer-adoption-of-artificial-intelligence-in-singapores-life-insurance-sector.html|title= AIA To Pioneer Adoption Of Artificial Intelligence In Singapore's Life Insurance Sector |date=2018-10-12|work= AIA Singapore|access-date=2018-10-26}}</ref><ref name= AsiaInsuranceReview>{{Cite news|url=http://www3.asiainsurancereview.com/News/View-NewsLetter-Article/id/44576/Type/agent/Singapore-AIA-transforms-customer-service-with-insurance-industry-s-first-humanoids#|title=Singapore: AIA transforms customer service with insurance industry's first humanoids|last=Benjamin|first=Ang|date=2018-10-22|work=Asia Insurance Review|access-date=2018-10-26|archive-url=https://web.archive.org/web/20190202042647/http://www3.asiainsurancereview.com/News/View-NewsLetter-Article/id/44576/Type/agent/Singapore-AIA-transforms-customer-service-with-insurance-industry-s-first-humanoids|archive-date=2019-02-02|url-status=dead}}</ref><ref name= InsuranceBusinessAsia>{{Cite news|url= https://www.insurancebusinessmag.com/asia/news/technology/aia-singapore-welcomes-two-new-robotic-hires-114145.aspx|title= AIA Singapore welcomes two new robotic hires |last=Gabriel|first=Olano|date=2018-10-19|work= Insurance Business Asia|access-date=2018-10-20}}</ref> This is the first time in the world that a humanoid robot is used as a customer service agent.

==History==
Nadine is a next-generation humanoid robot that is a successor from Eva,<ref>[https://www.youtube.com/watch?v=ZQW898n8UK0 Social Robotics]</ref> a humanoid robot head manufactured by [[Hanson Robotics]] in 2008. Eva's software platform was developed at MIRALab,<ref>[http://www.miralab.ch/ MIRALab]</ref> [[University of Geneva]]. Eva's head shows very realistic moods and emotions<ref>C. Cig, Z. Kasap, A. Egges and N. Magnenat Thalmann, [https://link.springer.com/chapter/10.1007/978-3-642-16958-8_26 Realistic Emotional Gaze and Head Behavior Generation Based on Arousal and Dominance Factors], The 3rd International Conference on Motion in Games 2010, Springer, 2010</ref> and short term memory.<ref>Z. Kasap and N. Magnenat Thalmann, [https://link.springer.com/article/10.1007/s00371-011-0630-7 Building long-term relationships with virtual and robotic characters: the role of remembering], The Visual Computer (IF: 1.073), vol. 28, no. 1, pp. 87-97, January 2012</ref><ref>Z. Kasap, M. Ben Moussa, P. Chaudhuri and N. Magnenat Thalmann, [https://ieeexplore.ieee.org/document/4797513/ Making Them Remember—Emotional Virtual Characters with Memory], IEEE Computer Graphics and Applications (IF: 1.116), vol. 29, no. 2, pp. 20-29, March 2009</ref> Eva has also performed in a play in the Roten Fabrik Theatre at Zurich.<ref>[https://www.youtube.com/watch?v=ISFD76N1FZI The robot EVA playing in the Roten Fabrik theatre in Zurich]</ref>

Nadine has been created in 2013 by Kokoro, Japan and has been modelled after Professor [[Nadia Magnenat Thalmann]]. Nadine has a head and full body with a natural appearance. Nadine software platform which has been developed at the Institute for Media Innovation in Singapore's [[Nanyang Technological University]] is able to show emotions, speak naturally, understand some gestures, and remember and retrieve facts during dialogue sessions.<ref>[https://www.youtube.com/watch?v=sSOLAK33W04&t=264s ColdFusion, The Most Realistic Robots! (2018)]</ref><ref>J. Zhang J, N. Magnenat Thalmann and J.  Zheng, [https://dl.acm.org/citation.cfm?id=2915926.2915952 Combining Memory and Emotion With Dialog on Social Companion: A Review], Proceedings of the ACM 29th International Conference on Computer Animation and Social Agents (CASA 2016), pp. 1-9, Geneva, Switzerland, May 23–25, 2016</ref> Nadine also interacts with arm movements. Ongoing research provides the social robot with two articulated hands and natural grasping.<ref>L. Tian, N. Magnenat Thalmann, D. Thalmann, J. Zheng, [https://dl.acm.org/citation.cfm?id=3208182 A methodology to model and simulate customized human robotic realistic hand], Proceedings of the 35th Computer Graphics International (CGI 2018), ACM, Bintan, Indonesia, June 11–14, 2018</ref><ref>L. Tian, N. Magnenat Thalmann, D. Thalmann, J. Zheng, [https://www.frontiersin.org/articles/10.3389/frobt.2017.00065/full The Making of a 3D-Printed, Cable-Driven, Single-Model, Lightweight Humanoid Robotic Hand], Frontiers in Robotics and AI, DOI: 10.3389/frobt.2017.00065, pp. 65, December 04, 2017</ref><ref>N. Magnenat Thalmann, L. Tian and F. Yao, [https://link.springer.com/chapter/10.1007/978-981-10-4235-5_1 Nadine: A Social Robot that Can Localize Objects and Grasp Them in a Human Way], Frontiers in Electronic Technologies, Springer, pp. 1-23, 2017</ref><ref>H. Liang, J. Yuan, D. Thalmann and N. Magnenat Thalmann, [http://dl.acm.org/citation.cfm?id=2807972&dl=ACM&coll=DL&CFID=763558095&CFTOKEN=41833294 AR in Hand: Egocentric Palm Pose Tracking and Gesture Recognition for Augmented Reality Applications], ACM Multimedia Conference 2015 (ACMMM 2015), Brisbane, Australia, 2015</ref> Nadine is also linked to all kinds of databases such as its personal dataset, Wikipedia, weather channels, and many others.

==Platform==
Nadine (social robot) is built with a classic perception – processing/decision – interaction layer framework. The design of Nadine platform with objectives of maintaining human-like natural behavior even in complex situation, be generic to handle any kind of data and place of operation, multi-lingual support etc.

Nadine's functionalities are based on her understanding of environment and perception of users/people in front of her. Nadine's perception layer is focused on this task. Nadine uses a 3D depths cameras, webcam and microphone to pick up vision and audio inputs from her environment and users. Perception layer is composed of independent sub-modules that operate on different input streams of the above-mentioned devices to [[face recognition|recognize faces]],<ref>J. Ren, X. Jiang, and J. Yuan, [https://link.springer.com/chapter/10.1007/978-3-319-19947-4_1 Face and Facial Expressions Recognition and Analysis], Context Aware Human-Robot and Human-Agent Interaction, Springer International Publishing, 3-29, 2015</ref> emotions,<ref name= PCMD2015 /> gestures,<ref>L. Ge, H. Liang, J. Yuan and D. Thalmann, [https://ieeexplore.ieee.org/document/7780760/ Robust 3D Hand Pose Estimation in Single Depth Images: from Single-View CNN to Multi-View CNNs], IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Las Vegas, Nevada, USA, 24 June 2016</ref><ref>Q. Ke, M. Bennamoun, S. An, F. Sohel and F. Boussaid, [https://arxiv.org/abs/1703.03492 A New Representation of Skeleton Sequences for 3D Action Recognition], CVPR 2017</ref> user location, intention, behavior etc. and other environmental attributes such as [[object recognition]],<ref>Z. Fang, J. Yuan and N. Magnenat Thalmann, [https://dl.acm.org/citation.cfm?id=3208192 Understanding Human-Object Interaction in RGB-D videos for Human Robot Interaction], Proceedings of the 35th Computer Graphics International (CGI 2018), ACM, Indonesia, June 11–14, 2018</ref><ref>J. Redmon and A. Farhadi, [https://www.semanticscholar.org/paper/YOLO9000%3A-Better%2C-Faster%2C-Stronger-Redmon-Farhadi/7d39d69b23424446f0400ef603b2e3e22d0309d6 YOLO9000: Better, Faster, Stronger], arXiv preprint, 2017</ref> location etc.

The processing layer functions as Nadine's brain that uses the perception outputs to gauge the situation and decide on how to act according to it. The main component of this layer is a behavior tree planner, Nadine's central processing unit allows to process all perceived inputs. Based on the inputs received from perception layer, the behavior tree planner updates the other sub-modules of processing layer, which include processing dialog between user and Nadine, affective system and memories of her interaction. To process dialog, generic chatbots<ref>R.S Wallace, [https://link.springer.com/chapter/10.1007/978-1-4020-6710-5_13 The Anatomy of A.L.I.C.E.], In Parsing the Turing Test (pp. 181-210). Springer, Dordrecht, 2009</ref><ref>[https://chatterbot.readthedocs.io/en/stable/ Chatterbot]</ref> have been built to handle different situations and questions. An online search based on Google Assistant is also integrated to answer questions outside the trained corpus. Based on the user's speech, emotion and Nadine's current emotion, Nadine can exhibit different human motion to user.<ref name= PCMD2015 /> Nadine's memory model<ref>J. Zhang, J. Zheng and N. Magnenat Thalmann, [https://link.springer.com/article/10.1007/s00371-018-1537-3 MCAEM: Mixed-Correlation-Analysis based Episodic Memory for Companion-User Interactions], The Visual Computer, DOI: 10.1007/s00371-018-1537-3, Vol 34, Issue 6-8, pp. 1129-1141, May 10, 2018</ref> also allows her to remember specific facts about the user and context of current conversation in order to provide appropriate responses. Upon understanding the user interaction and environment context, an appropriate verbal or non-verbal response is decided. For this purpose, Nadine's processing layer maps each perception layer stimuli to an activation and threshold. Based on the processing of each stimulus by each sub-module, the activation levels are varied. When thresholds are reached, each winning action is passed on to interaction layer to show the various responses in Nadine.

The interaction layer or Nadine controller is responsible for executing each of the responses received from processing layer to show it in Nadine's face or gesture. For example, based on user location modify Nadine's head to maintain eye gaze with user. Apart from this, the interaction layer is also responsible for controlling her motors to show different gestures and facial expressions. For verbal responses, it includes a speech synthesizer and lip synchronization module. Based on the verbal response, corresponding phonemes and visemes are generated. The speech synthesizer also takes into account the tone of dialog (to show various emotions) while generating speech. The lip synchronization converts the visemes into corresponding facial motor position to move Nadine's lips according to her speech. Currently, Nadine can support six languages including English, German, French, Chinese, Hindi and Japanese.

==Events==
Nadine has participated in live demos on stage and engaged with people from all walks of life. Proclaimed as one of the world's most realistic humanoid robot,<ref>{{Cite news|url=https://www.cnet.com/pictures/human-plus-exhibition-artscience-museum-singapore/12/|title='Human+' exhibit explores the future of humanity|last=Aloysius|first=Low|date=2017-05-19|work=CNET|access-date=2017-06-08}}</ref> Nadine made her first public appearance as a key highlight at the “Human+: The Future of Our Species” exhibition held in Singapore's ArtScience Museum.<ref>[http://www.rosettemedia.com/2017/05/the-cyborgs-have-arrived/ Human+: The Future of Our Species]</ref>

She has interacted with many people from corporate companies across various industries such as Dentsu Aegis Network (DAN), Credit Suisse<ref>[https://www.youtube.com/watch?v=EDSkgc04ums Credit Suisse Global Megatrends Conference 2018]</ref> and Deutsche Bank.<ref>[https://www.youtube.com/watch?v=E-ZNTE0Fnpw 9th Annual deAccess Asia 2018 Conference Highlights]</ref>

Nadine also interacted with Prime Minister of India, His Excellency [[Narendra Modi]] during his historic visit to NTU Singapore, on 1 June 2018, which was one of the innovations he took special interest in.<ref>[http://media.ntu.edu.sg/news/Pages/NTU-marks-historic-visit-by-Indian-Prime-Minister.aspx NTU marks historic visit by Indian Prime Minister]</ref><ref>[https://www.youtube.com/watch?v=1kwVPnpGtyc&t=77s PM Modi Interacts With Robot In Nanyang Tech University In Singapore]</ref>

Presently, Nadine is working as a customer service agent at AIA Singapore.<ref name= AIAPress/><ref name= AsiaInsuranceReview /><ref name= InsuranceBusinessAsia /> She has been trained to handle questions that are usually asked to AIA customer service agents. She also encourages AIA customers to sign up with AIA e-care registration portal. Customer service interactions were used to train a machine-learning based conversational dialog engine. A client-server architecture was also set up between our platform and AIA portal to allow fast and secure communication.<ref>[https://www.youtube.com/watch?v=usif8BOBHgA NTU Singapore’s social robot Nadine starts work as a receptionist]</ref>

== References ==
{{Reflist}}

== External links ==

[[Category:Android (robot)]]
[[Category:Humanoid robots]]
[[Category:Social robots]]
[[Category:Robots of Singapore]]
[[Category:2013 robots]]