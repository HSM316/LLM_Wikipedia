{{context|date=March 2019}}
{{Underlinked|date=February 2019}}
[[File:Learning Curves (Naive Bayes).png|thumb|Learning curve showing training score and cross validation score]]
{{Machine learning bar}}

A '''learning curve''' shows the validation and training score of an estimator for varying numbers of training samples. It is a tool to find out how much a [[machine learning]] model benefits from adding more training data and whether the estimator suffers more from a variance error or a bias error. If both the validation score and the training score converge to a value that is too low with increasing size of the training set, it will not benefit much from more training data.<ref name="scikit-learn_learning-curve">{{cite web |url=https://scikit-learn.org/stable/modules/learning_curve.html#learning-curve |title=Validation curves: plotting scores to evaluate models — scikit-learn 0.20.2 documentation |date=  |author=scikit-learn developers |accessdate= February 15, 2019}}</ref>

The machine learning curve is useful for many purposes including comparing different algorithms,<ref>{{cite web|last=Madhavan|first=P.G.|title=A New Recurrent Neural Network Learning  Algorithm for Time Series Prediction|url=http://www.jininnovation.com/RecurrentNN_JIntlSys_PG.pdf|work=Journal of Intelligent Systems|page=113 Fig. 3|volume=7|issue=1–2|date=1997}}</ref>  choosing model parameters during design,<ref>{{cite web|title=Machine Learning 102: Practical Advice|url=https://astroml.github.com/sklearn_tutorial/practical.html#learning-curves|work=Tutorial: Machine Learning for Astronomy with Scikit-learn}}</ref> adjusting optimization to improve convergence, and determining the amount of data used for training.<ref>{{cite journal|last=Meek|first=Christopher|author2=Thiesson, Bo |author3=Heckerman, David |title=The Learning-Curve Sampling Method Applied to Model-Based Clustering|journal=Journal of Machine Learning Research|date=Summer 2002|volume=2|issue=3|page=397|url=http://connection.ebscohost.com/c/articles/7188676/learning-curve-sampling-method-applied-model-based-clustering}}</ref>

In the machine learning domain, there are two connotations of learning curves differing in the x-axis of the curves, with experience of the model graphed either as the number of training examples used for learning or the number of iterations used in training the model.<ref>{{cite book|last1=Sammut|first1=Claude|title=Encyclopedia of Machine Learning|publisher=Springer|isbn=978-0-387-30768-8|page=578|url=https://books.google.com/books?id=i8hQhp1a62UC&pg=PT604&dq=neural+network+learning+curve&hl=en&sa=X&ei=83VQUcy9GKT90gHTzoHoBQ&ved=0CEkQ6AEwAw|edition=1st|last2=Webb |first2 = Geoffrey I. (Eds.)}}</ref>

==See also==
*[[Overfitting]]
*[[Bias–variance tradeoff]]
*[[Model selection]]
*[[Cross-validation (statistics)]]
*[[Validity (statistics)]]
*[[Verification and validation]]

==References==
{{Reflist}}


{{compu-ai-stub}}
{{statistics-stub}}

[[Category:Model selection]]
[[Category:Machine learning]]
[[Category:Artificial intelligence]]