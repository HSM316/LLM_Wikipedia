'''Product of experts''' (PoE) is a [[machine learning]] technique. It models a probability distribution by combining the output from several simpler distributions.
It was proposed by [[Geoff Hinton]], along with an algorithm for training the parameters of such a system.

The core idea is to combine several probability distributions ("experts") by multiplying their density functions—making the PoE classification similar to an "and" operation. This allows each expert to make decisions on the basis of a few dimensions without having to cover the full dimensionality of a problem.

This is related to (but quite different from) a [[mixture model]], where several probability distributions are combined via an "or" operation, which is a weighted sum of their density functions.

==External links==
*{{Cite journal|doi=10.1162/089976602760128018|last=Hinton |first=Geoffrey E.|year=2002|title=Training Products of Experts by Minimizing Contrastive Divergence|journal=Neural Computation|volume=14|issue=8|pages=1771–1800|url=http://www.cs.toronto.edu/~hinton/absps/nccd.pdf|accessdate=2009-10-25|pmid=12180402|citeseerx=10.1.1.35.8613 }}

{{DEFAULTSORT:Product Of Experts}}
[[Category:Machine learning]]


{{Compu-stub}}