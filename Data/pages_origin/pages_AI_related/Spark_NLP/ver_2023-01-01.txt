{{short description|Text processing programming library}}
{{Infobox software
| title = Spark NLP
| name = Spark NLP
| author = John Snow Labs
| released = October 2017<ref>{{cite web |last1=Talby |first1=David |title=Introducing the Natural Language Processing Library for Apache Spark |url=https://databricks.com/blog/2017/10/19/introducing-natural-language-processing-library-apache-spark.html |website=databricks.com |date=19 October 2017 |publisher=databricks |access-date=29 March 2019}}</ref>
| latest release version = 4.2.0
| latest release date = {{Start date and age|2022|09|df=yes}}
| repo = {{URL|https://github.com/JohnSnowLabs/spark-nlp}}
| programming language = [[Python (programming language)|Python]], [[Scala (programming language)|Scala]]
| operating system = Linux, Windows, macOS, OS X
| genre = [[Natural language processing]]
| license = [[Apache licence]]
| website = {{URL|https://nlp.johnsnowlabs.com/}}
}}

'''Spark NLP''' is an [[Open-source software|open-source]] text processing library for advanced natural language processing for the [[Python (programming language)|Python]], [[Java (programming language)|Java]] and [[Scala (programming language)|Scala]] programming languages.<ref>{{Cite web|url=https://www.oreilly.com/ideas/comparing-production-grade-nlp-libraries-running-spark-nlp-and-spacy-pipelines|title=Comparing production-grade NLP libraries: Running Spark-NLP and spaCy pipelines|last=Ellafi|first=Saif Addin|date=2018-02-28|website=O'Reilly Media|language=en|access-date=2019-03-29}}</ref><ref name=":1">{{Cite web|url=https://www.oreilly.com/ideas/comparing-production-grade-nlp-libraries-accuracy-performance-and-scalability|title=Comparing production-grade NLP libraries: Accuracy, performance, and scalability|last=Ellafi|first=Saif Addin|date=2018-02-28|website=O'Reilly Media|language=en|access-date=2019-03-29}}</ref><ref>{{Cite web|url=https://www.i-programmer.info/news/80-java/11251-spark-gets-nlp-library.html|title=Spark Gets NLP Library|last=Ewbank|first=Kay|website=www.i-programmer.info}}</ref> The library is built on top of [[Apache Spark]] and its Spark ML library.<ref name="SparkNLPBook">{{cite book |last1=Thomas |first1=Alex |title=Natural Language Processing with Spark NLP: Learning to Understand Text at Scale |date=July 2020 |publisher=O'Reilly Media |location=United States of America |isbn=978-1492047766 |edition=First }}</ref> 

Its purpose is to provide an [[API]] for [[natural language processing]] pipelines that implements recent academic research results as production-grade, scalable, and trainable software. The library offers pre-trained neural network models, pipelines, and embeddings, as well as support for training custom models.<ref name="SparkNLPBook" />

== Features ==

The design of the library make use of the concept of a pipeline which is an ordered set of text annotators.<ref>{{Cite web|url=https://databricks.com/blog/2017/10/19/introducing-natural-language-processing-library-apache-spark.html|title=Introducing the Natural Language Processing Library for Apache Spark - The Databricks Blog|last=Talby|first=David|date=2017-10-19|website=Databricks|language=en-US|access-date=2019-08-27}}</ref> Out of the box annotators include, [[tokenizer]], normalizer, [[stemming]], [[lemmatizer]], [[regular expression]], TextMatcher, [[shallow parsing|chunker]], DateMatcher, SentenceDetector, DeepSentenceDetector, [[Part-of-speech tagging|POS tagger]], ViveknSentimentDetector, [[sentiment analysis]], [[Named-entity recognition|named entity recognition]], [[conditional random field]] annotator, [[Deep learning|deep learning]] annotator, [[Spell checker|spell checking]] and correction, dependency parser, typed dependency parser, [[Document classification|document classification]], and [[Language identification|language detection]].<ref name="auto">{{Cite journal|url=https://www.annalsofrscb.ro/index.php/journal/article/view/4269|title=Sentiment Analysis for E-Commerce Products Using Natural Language Processing|first1=Bineet Kumar|last1=Jha|first2=Sivasankari G.|last2=G|first3=Venugopal K.|last3=R|date=May 2, 2021|journal=Annals of the Romanian Society for Cell Biology|pages=166–175|via=www.annalsofrscb.ro}}</ref>

The Models Hub is a platform for sharing open-source as well as licensed pretrained models and pipelines. It includes pre-trained pipelines with tokenization, lemmatization, part-of-speech tagging, and named entity recognition exist for more than thirteen languages; word embeddings including [[GloVe (machine learning)|GloVe]], [[ELMo]], [[BERT (language model)|BERT]], ALBERT, XLNet, Small BERT, and ELECTRA; sentence embeddings including Universal Sentence Embeddings (USE)<ref>{{cite arXiv |last1=Cer |first1=Daniel |last2=Yang |first2=Yinfei |last3=Kong |first3=Sheng-yi |last4=Hua |first4=Nan |last5=Limtiaco |first5=Nicole |last6=John |first6=Rhomni St |last7=Constant |first7=Noah |last8=Guajardo-Cespedes |first8=Mario |last9=Yuan |first9=Steve |last10=Tar |first10=Chris |last11=Sung |first11=Yun-Hsuan |last12=Strope |first12=Brian |last13=Kurzweil |first13=Ray |title=Universal Sentence Encoder |date=12 April 2018  |class=cs.CL |eprint=1803.11175 }}</ref> and Language Agnostic BERT Sentence Embeddings (LaBSE).<ref>{{cite arXiv |last1=Feng |first1=Fangxiaoyu |last2=Yang |first2=Yinfei |last3=Cer |first3=Daniel |last4=Arivazhagan |first4=Naveen |last5=Wang |first5=Wei |title=Language-agnostic BERT Sentence Embedding |date=3 July 2020 |class=cs.CL |eprint=2007.01852 }}</ref> It also includes resources and pre-trained models for more than two hundred languages. Spark NLP base code includes support for East Asian languages such as tokenizers for Chinese, Japanese, Korean; for right-to-left languages such as Urdu, Farsi, Arabic, Hebrew and pre-trained multilingual word and sentence embeddings such as LaUSE and a translation annotator.

== Usage in healthcare ==
Spark NLP for Healthcare is a commercial extension of Spark NLP for  clinical and biomedical text mining.<ref>{{Cite web|url=https://insidebigdata.com/2018/09/03/use-nlp-extract-unstructured-medical-data-text/|title=The Use of NLP to Extract Unstructured Medical Data From Text|last=Team|first=Editorial|date=2018-09-04|website=insideBIGDATA|language=en-US|access-date=2019-08-27}}</ref> It provides healthcare-specific annotators, pipelines, models, and embeddings for clinical entity recognition, clinical entity linking, entity normalization, assertion status detection, de-identification, relation extraction, and spell checking and correction.

The library offers access to several clinical and biomedical transformers: JSL-BERT-Clinical, BioBERT, ClinicalBERT,<ref>{{cite journal |last1=Alsentzer |first1=Emily |last2=Murphy |first2=John |last3=Boag |first3=William |last4=Weng |first4=Wei-Hung |last5=Jindi |first5=Di |last6=Naumann |first6=Tristan |last7=McDermott |first7=Matthew |title=Publicly Available Clinical BERT Embeddings |journal=Proceedings of the 2nd Clinical Natural Language Processing Workshop |date=June 2019 |pages=72–78 |doi=10.18653/v1/W19-1909 |url=https://www.aclweb.org/anthology/W19-1909/ |publisher=Association for Computational Linguistics|arxiv=1904.03323 |s2cid=102352093 }}</ref> GloVe-Med, GloVe-ICD-O. It also includes over 50 pre-trained healthcare models, that can recognize the entities such as clinical, drugs, risk factors, anatomy, demographics, and sensitive data.

== Spark OCR ==
Spark OCR is another commercial extension of Spark NLP for [[optical character recognition]] (OCR) from images, scanned [[PDF]] documents, and [[DICOM]] files.<ref name="auto"/> It is a software library built on top of [[Apache Spark]]. It provides several image pre-processing features for improving text recognition results such as adaptive [[thresholding (image processing)|thresholding]] and [[noise reduction|denoising]], skew detection & correction, adaptive scaling, [[document layout analysis|layout analysis]] and region detection, [[cropping (image)|image cropping]], removing background objects.

Due to the tight coupling between Spark OCR and Spark NLP, users can combine [[Natural language processing|NLP]] and OCR pipelines for tasks such as extracting text from images, extracting data from tables, recognizing and highlighting named entities in PDF documents or masking sensitive text in order to de-identify images.<ref>{{cite web |title=A Unified CV, OCR & NLP Model Pipeline for Document Understanding at DocuSign |url=https://www.nlpsummit.org/a-unified-cv-ocr-nlp-model-pipeline-for-document-understanding-at-docusign/ |publisher=NLP Summit |access-date=18 September 2020 }}</ref>

Several output formats are supported by Spark OCR such as [[PDF]], images, or [[DICOM]] files with annotated or masked entities, digital text for downstream processing in Spark NLP or other libraries, structured data formats ([[JSON]] and [[Comma-separated values|CSV]]), as files or [[Apache Spark|Spark]] data frames. 

Users can also distribute the OCR jobs across multiple nodes in a [[Apache Spark|Spark]] [[computer cluster|cluster]].

== License and availability ==
Spark NLP is licensed under the [[Apache License|Apache 2.0]] license. The source code is publicly available on GitHub as well as documentation and a tutorial. Prebuilt versions of Spark NLP are available in PyPi and Anaconda Repository for Python development, in Maven Central for Java & Scala development, and in Spark Packages for Spark development.

==Award==
In March 2019, Spark NLP received Open Source Award for its contributions in natural language processing in Python, Java, and Scala.<ref>[https://www.oreilly.com/pub/pr/3277 Civis Analytics, Okera, Sigma Computing and Spark NLP Named Winners of Strata Data Awards<!-- Bot generated title -->]</ref>
 
== References ==
{{reflist}}

== Sources ==
* {{cite book |last=Thomas |first=Alex |date=21 July 2020 |title=Natural Language Processing with Spark NLP: Learning to Understand Text at Scale |url= |publisher=O'Reilly Media |isbn=978-1492047766}}
* {{cite book |last=Quinto |first=Butch |title=Next-Generation Machine Learning with Spark |year=2020 |url=https://link.springer.com/book/10.1007%2F978-1-4842-5669-5 |location=Berkeley, California |publisher=Apress |doi=10.1007/978-1-4842-5669-5 |isbn=978-1-4842-5668-8|s2cid=211234215 }}

== External links ==
* [https://github.com/JohnSnowLabs/spark-nlp Spark NLP]

[[Category:2017 software]]
[[Category:Open-source artificial intelligence]]
[[Category:Software using the Apache license]]
[[Category:Free software programmed in Python]]
[[Category:Free software programmed in Scala]]
[[Category:Natural language processing toolkits]]