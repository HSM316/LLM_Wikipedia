{{Orphan|date=July 2016}}

In [[statistical learning theory]], a '''learnable function class''' is a [[Set (mathematics)|set]] of [[Function (mathematics)|functions]] for which an algorithm can be devised to asymptotically minimize the [[expected risk]], uniformly over all probability distributions. The concept of learnable classes are closely related to [[Regularization (mathematics)|regularization]] in [[machine learning]], and provides large sample justifications for certain learning algorithms.

== Definition ==

=== Background ===
{{See also|Statistical learning theory}}
Let <math>\Omega = \mathcal{X} \times \mathcal{Y} = \{(x, y)\}</math> be the sample space, where <math>y</math> are the labels and <math>x</math> are the covariates (predictors). <math>\mathcal{F} = \{ f: \mathcal{X} \mapsto \mathcal{Y} \}</math> is a collection of mappings (functions) under consideration to link <math>x</math> to <math>y</math>. <math>L: \mathcal{Y} \times \mathcal{Y} \mapsto \mathbb{R}</math> is a pre-given loss function (usually non-negative). Given a probability distribution <math>P(x, y)</math> on <math>\Omega</math>, define the expected risk <math>I_P( f )</math> to be:
:<math>I_P (f) = \int L( f(x), y ) d P( x, y )</math>
The general goal in statistical learning is to find the function in <math>\mathcal{F}</math> that minimizes the expected risk. That is, to find solutions to the following problem:<ref name="Vapnik2013">{{cite book|author=Vladimir N. Vapnik|title=The Nature of Statistical Learning Theory|url=https://books.google.com/books?id=EoDSBwAAQBAJ|date=17 April 2013|publisher=Springer Science & Business Media|isbn=978-1-4757-2440-0}}</ref>
:<math> \hat{f} = \arg \min_{f \in \mathcal{F}} I_P (f) </math>
But in practice the distribution <math>P</math> is unknown, and any learning task can only be based on finite samples. Thus we seek instead to find an algorithm that asymptotically minimizes the empirical risk, i.e., to find a sequence of functions <math>\{\hat{f}_n\}_{n=1}^\infty</math> that satisfies
:<math>\lim_{n \rightarrow \infty} \mathbb{P}( I_P (\hat{f}_n) - \inf_{f \in \mathcal{F}}I_P( f ) > \epsilon ) = 0</math>
One usual algorithm to find such a sequence is through [[empirical risk minimization]].

=== Learnable function class ===
We can make the condition given in the above equation stronger by requiring that the convergence is uniform for all probability distributions. That is:

{{NumBlk|:|<math> \lim_{n \rightarrow \infty} \sup_P \mathbb{P}( I_P (\hat{f}_n) - \inf_{f \in \mathcal{F}}I_P( f ) > \epsilon ) = 0</math> |{{EquationRef|1}}}}

The intuition behind the more strict requirement is as such: the rate at which sequence <math>\{\hat{f}_n\}</math> converges to the minimizer of the expected risk can be very different for different <math>P(x, y)</math>. Because in real world the true distribution <math>P</math> is always unknown, we would want to select a sequence that performs well under all cases.

However, by the [[no free lunch theorem]], such a sequence that satisfies ({{EquationNote|1}}) does not exist if <math>\mathcal{F}</math> is too complex. This means we need to be careful and not allow too "many" functions in <math>\mathcal{F}</math> if we want ({{EquationNote|1}}) to be a meaningful requirement. Specifically, function classes that ensure the existence of a sequence <math>\{\hat{f}_n\}</math> that satisfies ({{EquationNote|1}}) are known as '''learnable classes'''.<ref name="Vapnik2013" />

It is worth noting that at least for supervised classification and regression problems, if a function class is learnable, then the empirical risk minimization automatically satisfies ({{EquationNote|1}}).<ref name=":0">{{cite journal |title = Learnability, stability and uniform convergence|journal = The Journal of Machine Learning Research}}</ref> Thus in these settings not only do we know that the problem posed by ({{EquationNote|1}}) is solvable, we also immediately have an algorithm that gives the solution.

== Interpretations ==
If the true relationship between <math>y</math> and <math>x</math> is <math>y \sim f^*(x)</math>, then by selecting the appropriate loss function, <math>f^*</math> can always be expressed as the minimizer of the expected loss across all possible functions. That is,

:<math>f^* = \arg\min_{f \in \mathcal{F}^*} I_P( f )</math>

Here we let <math>\mathcal{F}^*</math> be the collection of all possible functions mapping <math>\mathcal{X}</math> onto <math>\mathcal{Y}</math>. <math>f^*</math> can be interpreted as the actual data generating mechanism. However, the no free lunch theorem tells us that in practice, with finite samples we cannot hope to search for the expected risk minimizer over <math>\mathcal{F}^*</math>. Thus we often consider a subset of <math>\mathcal{F}^*</math>, <math>\mathcal{F}</math>, to carry out searches on. By doing so, we risk that <math>f^*</math> might not be an element of <math>\mathcal{F}</math>. This tradeoff can be mathematically expressed as

{{NumBlk|:|<math> I_P (\hat{f}_n) - \inf_{f \in \mathcal{F}^*}I_P( f ) = \underbrace{I_P (\hat{f}_n) - \inf_{f \in \mathcal{F}}I_P( f )}_{(a)} + \underbrace{\inf_{f \in \mathcal{F}}I_P( f ) - \inf_{f \in \mathcal{F}^*}I_P( f )}_{(b)} </math> |{{EquationRef|2}}}}

In the above decomposition, part <math>(b)</math> does not depend on the data and is non-stochastic. It describes how far away our assumptions (<math>\mathcal{F}</math>) are from the truth (<math>\mathcal{F}^*</math>). <math>(b)</math> will be strictly greater than 0 if we make assumptions that are too strong (<math>\mathcal{F}</math> too small). On the other hand, failing to put enough restrictions on <math>\mathcal{F}</math> will cause it to be not learnable, and part <math>(a)</math> will not stochastically converge to 0. This is the well-known [[overfitting]] problem in statistics and machine learning literature.

== Example: Tikhonov regularization ==
A good example where learnable classes are used is the so-called [[Tikhonov regularization]] in [[reproducing kernel Hilbert space]] (RKHS). Specifically, let <math>\mathcal{F^*}</math> be an RKHS, and <math>||\cdot||_2</math> be the norm on <math>\mathcal{F^*}</math> given by its inner product. It is shown in <ref>{{cite journal |title=Learnability in Hilbert spaces with reproducing kernels |journal=Journal of Complexity }}</ref> that <math>\mathcal{F} = \{f: ||f||_2 \leq \gamma  \}</math> is a learnable class for any finite, positive <math>\gamma</math>. The empirical minimization algorithm to the [[Duality (mathematics)|dual form]] of this problem is

:<math>\arg\min_{f \in \mathcal{F}^*} \left\{ \sum_{i = 1}^n L( f(x_i), y_i) + \lambda ||f||_2 \right\}</math>

This was first introduced by Tikhonov<ref name="TikhonovArsenin1977">{{cite book|author1=Andreĭ Nikolaevich Tikhonov|author2=Vasiliĭ I︠A︡kovlevich Arsenin|title=Solutions of ill-posed problems|url=https://books.google.com/books?id=ECrvAAAAMAAJ|year=1977|publisher=Winston|isbn=978-0-470-99124-4}}</ref> to solve ill-posed problems. Many statistical learning algorithms can be expressed in such a form (for example, the well-known [[ridge regression]]).

The tradeoff between <math>(a)</math> and <math>(b)</math> in ({{EquationNote|2}}) is geometrically more intuitive with Tikhonov regularization in RKHS. We can consider a sequence of <math>\{\mathcal{F}_\gamma\}</math>, which are essentially balls in  <math>\mathcal{F^*}</math> with centers at 0. As <math>\gamma</math> gets larger, <math>\mathcal{F}_\gamma</math> gets closer to the entire space, and <math>(b)</math> is likely to become smaller. However we will also suffer smaller convergence rates in <math>(a)</math>. The way to choose an optimal <math>\gamma</math> in finite sample settings is usually through [[Cross-validation (statistics)|cross-validation]].

== Relationship to empirical process theory ==

Part <math>(a)</math> in ({{EquationNote|2}}) is closely linked to [[empirical process]] theory in statistics, where the empirical risk <math>\{\sum_{i=1}^n L( y_i, f(x_i) ), f \in \mathcal{F}\}</math> are known as empirical processes.<ref name="vaartWellner2013">{{cite book|author1=A.W. van der vaart|author2=Jon Wellner|title=Weak Convergence and Empirical Processes: With Applications to Statistics|url=https://books.google.com/books?id=zdDkBwAAQBAJ&pg=PA116|date=9 March 2013|publisher=Springer Science & Business Media|isbn=978-1-4757-2545-2|pages=116–}}</ref> In this field, the function class <math>\mathcal{F}</math> that satisfies the stochastic convergence

{{NumBlk|:|<math> \sup_P \mathbb{E} \sup_{f \in \mathcal{F}} | \sum_{i=1}^n L( y_i, f(x_i) ) - I_P(f) | = 0  </math> |{{EquationRef|3}}}}

are known as uniform [[Glivenko–Cantelli class]]es. It has been shown that under certain regularity conditions, learnable classes and uniformly Glivenko-Cantelli classes are equivalent.<ref name="Vapnik2013" /> Interplay between <math>(a)</math> and <math>(b)</math> in statistics literature is often known as the [[bias-variance tradeoff]].

However, note that in <ref name=":0" /> the authors gave an example of [[stochastic convex optimization]] for [[General Setting of Learning]] where learnability is not equivalent with uniform convergence.

== References ==
<references />

[[Category:Machine learning]]