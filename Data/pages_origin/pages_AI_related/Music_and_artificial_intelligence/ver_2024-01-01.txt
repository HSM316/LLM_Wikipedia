{{Short description|Common subject in the International Computer Music Conference}}
{{multiple issues|
{{cleanup|date=December 2010}}
{{advert|date=December 2010}}
{{update|date=May 2023}}
}}
{{Artificial intelligence}}
'''Artificial intelligence and music''' ('''AIM''') is a common subject in the [[International Computer Music Conference]], the Computing Society Conference<ref>[http://www-rcf.usc.edu/~echew/INFORMS/ics2005.html INFORMS Computing Society Conference: Annapolis: Music, Computation and AI] {{webarchive|url=https://archive.today/20120630221600/http://www-rcf.usc.edu/~echew/INFORMS/ics2005.html |date=2012-06-30 }}. Rcf.usc.edu. Retrieved on 2010-12-22.</ref> and the [[International Joint Conference on Artificial Intelligence]]. The first International Computer Music Conference (ICMC) was held in 1974 at [[Michigan State University]].<ref>[http://www.computermusic.org/page/23/ International Computer Music Association - ICMC]. Computermusic.org (2010-11-15). Retrieved on 2010-12-22.</ref> Current research includes the application of AI in [[Musical composition|music composition]], [[performance]], theory and digital [[Audio signal processing|sound processing]].

A key part of this field is the development of [[music software]] programs which use AI to produce music.<ref>{{cite journal| title = A Functional Taxonomy of Music Generation Systems
| author1 = D. Herremans |author2=C.H. |author3=Chuan, E. Chew
| year = 2017
| journal = ACM Computing Surveys
| volume = 50
| issue = 5
| doi = 10.1145/3108242
| pages = 69:1–30| arxiv = 1812.04186
| s2cid = 3483927 }}</ref> As with applications in other fields, AI in music also simulates mental tasks. A prominent feature is the capability of an AI algorithm to learn based on past data, such as in computer accompaniment technology, wherein the AI is capable of listening to a human performer and performing accompaniment.<ref>{{Cite web|url=https://pdfs.semanticscholar.org/f275/4c359d7ef052ab5997d71dc3e9443404565a.pdf|archive-url=https://web.archive.org/web/20180823141845/https://pdfs.semanticscholar.org/f275/4c359d7ef052ab5997d71dc3e9443404565a.pdf|url-status=dead|archive-date=August 23, 2018|title=Artificial Intelligence, Machine Learning, and Music Understanding|last=Dannenberg|first=Roger|website=Semantic Scholar|s2cid=17787070 |access-date=August 23, 2018}}</ref> Artificial intelligence also drives interactive composition technology, wherein a computer composes music in response to a live performance. There are other AI applications in music that cover not only music composition, production, and performance but also how music is marketed and consumed. Several music player programs have also been developed to use voice recognition and natural language processing technology for music voice control.

==History==
In 1960, Russian researcher Rudolf Zaripov published worldwide first paper on algorithmic music composing using the "[[Ural (computer)|Ural-1]]" computer.<ref>{{cite journal|last=Zaripov|first=Rudolf|title=Об алгоритмическом описании процесса сочинения музыки (On algorithmic description of process of music composition)|journal=[[Proceedings of the USSR Academy of Sciences]]|year=1960|volume=132|issue=6}}</ref>

In 1965, inventor [[Ray Kurzweil]] premiered a piano piece created by a computer that was capable of pattern recognition in various compositions. The computer was then able to analyze and use these patterns to create novel melodies. The computer debuted on the quiz show [[I've Got a Secret]], and stumped the hosts until film star [[Henry Morgan (humorist)|Henry Morgan]] guessed Ray's secret.<ref>{{Cite web | url=http://www.kurzweiltech.com/raybio.html | title=About Ray Kurzweil}}</ref>

In 1997, an artificial intelligence program named [[Experiments in Musical Intelligence]] (EMI) appeared to outperform a human composer at the task of composing a piece of music to imitate the style of [[Bach]].<ref>{{cite news |last1=Johnson |first1=George |title=Undiscovered Bach? No, a Computer Wrote It |url=https://www.nytimes.com/1997/11/11/science/undiscovered-bach-no-a-computer-wrote-it.html |accessdate=29 April 2020 |work=The New York Times |date=11 November 1997| quote=Dr. Larson was hurt when the audience concluded that his piece -- a simple, engaging form called a two-part invention -- was written by the computer. But he felt somewhat mollified when the listeners went on to decide that the invention composed by EMI (pronounced ''Emmy'') was genuine Bach.}}</ref>

==Software applications==

===Interactive scores===
Multimedia Scenarios in interactive scores are represented by
temporal objects,
temporal relations, and
interactive objects. Examples of temporal objects are sounds, videos and light controls.
Temporal objects can be triggered by interactive objects (usually launched by the user) and
several temporal objects can be executed simultaneously.  A temporal object may contain
other temporal objects:  this hierarchy allows us to control the start or end of a temporal
object by controlling the start or end of its parent.  Hierarchy is ever-present in all kinds
of music:  Music pieces are often hierarchized by movements, parts, motives, measures,
among other segmentations.<ref>Mauricio Toro, Myriam Desainte-Catherine, Camilo Rueda. Formal semantics for interactive music scores: a framework to design, specify properties and execute interactive scenarios. Journal of Mathematics and Music 8 (1)</ref><ref>{{cite web|title=Open Software System for Interactive Applications|url=https://ossia.io/|accessdate=23 January 2018|language=en-EN}}</ref>

===Computer Accompaniment (Carnegie Mellon University)===
The Computer Music Project at CMU develops computer music and interactive performance technology to enhance human musical experience and creativity. This interdisciplinary effort draws on [[music theory]], [[cognitive science]], [[artificial intelligence]] and [[machine learning]], [[human computer interaction]], [[real-time systems]], [[computer graphics]] and animation, [[multimedia]], [[programming languages]], and [[signal processing]].<ref>[http://www-2.cs.cmu.edu/~music/ Computer Music Group]. 2.cs.cmu.edu. Retrieved on 2010-12-22.</ref>

===ChucK===
{{main|ChucK}}

Developed at Princeton University by Ge Wang and Perry Cook, ChucK is a text-based, cross-platform language that allows real-time synthesis, composition, performance, and analysis of music.<ref>[http://chuck.cs.princeton.edu/ ChucK => Strongly-timed, On-the-fly Audio Programming Language]. Chuck.cs.princeton.edu. Retrieved on 2010-12-22.</ref> It is used by [[SLOrk]] (Stanford Laptop Orchestra)<ref>Driver, Dustin. (1999-03-26) [https://www.apple.com/pro/profiles/slork/ Pro - Profiles - Stanford Laptop Orchestra (SLOrk), pg. 1]. Apple. Retrieved on 2010-12-22.</ref> and [[PLOrk]] (Princeton Laptop Orchestra).

===Jukedeck===
{{main|Jukedeck}}
Jukedeck was a website that let people use artificial intelligence to generate original, royalty-free music for use in videos.<ref name="nyt">{{Cite news |title=From Jingles to Pop Hits, A.I. Is Music to Some Ears |url=https://www.nytimes.com/2017/01/22/arts/music/jukedeck-artificial-intelligence-songwriting.html |access-date=2023-01-03 |website=[[The New York Times]] |date=22 January 2017 |language=en}}</ref><ref name="techcrunch">{{Cite web |title=Need Music For A Video? Jukedeck's AI Composer Makes Cheap, Custom Soundtracks |url=https://techcrunch.com/2015/12/07/jukedeck/?guccounter=1 |access-date=2023-01-03 |website=techcrunch.com | date=7 December 2015 |language=en}}</ref> The team started building the music generation technology in 2010,<ref name="mother jones">{{Cite web |title=What Will Happen When Machines Write Songs Just as Well as Your Favorite Musician? |url=https://www.motherjones.com/media/2019/03/what-will-happen-when-machines-write-songs-just-as-well-as-your-favorite-musician |access-date=2023-01-03 |website=motherjones.com |language=en}}</ref> formed a company around it in 2012,<ref>{{Cite news |title=Jukedeck's computer composes music at touch of a button |url=https://www.ft.com/content/16e9f2dc-9c3e-11e5-b45d-4812f209f861 |access-date=2023-01-03 |newspaper=Financial Times |date=7 December 2015 |language=en |last1=Cookson |first1=Robert }}</ref> and launched the website publicly in 2015.<ref name="techcrunch" /> The technology used was originally a rule-based [[algorithmic composition]] system,<ref>{{Cite magazine |title=Jukedeck: the software that writes music by itself, note by note |url=https://www.wired.co.uk/article/shuffle-your-tunes |access-date=2023-01-03 |magazine=Wired UK |language=en }}</ref> which was later replaced with [[artificial neural networks]].<ref name="nyt" /> The website was used to create over 1 million pieces of music, and brands that used it included [[Coca-Cola]], [[Google]], [[UKTV]], and the [[Natural History Museum, London]].<ref>{{Cite web |title=Robot rock: how AI singstars use machine learning to write harmonies |url=https://www.standard.co.uk/tech/jukedeck-maching-learning-ai-startup-music-a3779296.html |access-date=2023-01-03 |website=standard.co.uk |date=March 2018 |language=en}}</ref> In 2019, the company was acquired by [[ByteDance]].<ref>{{Cite web |title=TIKTOK OWNER BYTEDANCE BUYS AI MUSIC COMPANY JUKEDECK |url=https://www.musicbusinessworldwide.com/tiktok-parent-bytedance-buys-ai-music-company-jukedeck/ |access-date=2023-01-03 |website=musicbusinessworldwide.com |date=23 July 2019 |language=en}}</ref><ref>{{Cite web |title=As TikTok's Music Licensing Reportedly Expires, Owner ByteDance Purchases AI Music Creation Startup JukeDeck |url=https://www.digitalmusicnews.com/2019/07/23/tiktok-bytedance-acquires-jukedeck/ |access-date=2023-01-03 |website=digitalmusicnews.com |date=23 July 2019 |language=en}}</ref><ref>{{Cite web |title=An AI-generated music app is now part of the TikTok group |url=https://sea.mashable.com/entertainment/5205/an-ai-generated-music-app-is-now-part-of-the-tiktok-group |access-date=2023-01-03 |website=sea.mashable.com |date=24 July 2019 |language=en}}</ref>

===MorpheuS===
MorpheuS<ref>{{cite journal| title = MorpheuS: Automatic music generation with recurrent pattern constraints and tension profiles
| author1 = D. Herremans |author2=E. Chew
| year = 2016
| journal = IEEE Transactions on Affective Computing
| volume = PP(1)
| doi = 10.1109/TAFFC.2017.2737984| arxiv = 1812.04832
| s2cid = 54475410 }}</ref> is a research project by [[Dorien Herremans]] and Elaine Chew at [[Queen Mary University of London]], funded by a Marie Skłodowská-Curie EU project. The system uses an optimization approach based on a [[variable neighborhood search]] algorithm to morph existing template pieces into novel pieces with a set level of tonal tension that changes dynamically throughout the piece. This optimization approach allows for the integration of a pattern detection technique in order to enforce long term structure and recurring themes in the generated music. Pieces composed by MorpheuS have been performed at concerts in both Stanford and London.

===AIVA===
{{main|AIVA}}
Created in February 2016, in [[Luxembourg]], [[AIVA]] is a program that produces soundtracks for any type of media. The algorithms behind AIVA are based on deep learning architectures<ref>[http://www.aiva.ai]. AIVA 2016</ref> AIVA has also been used to compose a Rock track called ''On the Edge'',<ref>[https://medium.com/@aivatech/the-making-of-ai-generated-rock-music-with-aiva-9ae0257e6d5c] AI-generated Rock Music: the Making Of</ref> as well as a pop tune ''Love Sick''<ref>[https://www.youtube.com/watch?v=gQSPjAYTlx8] Love Sick | Composed with Artificial Intelligence - Official Video with Lyrics | Taryn Southern</ref> in collaboration with singer [[Taryn Southern]],<ref>[https://techcrunch.com/2018/05/10/ai-is-the-future-of-rhythm-nation/] Algo-Rhythms: the future of album collaboration</ref> for the creation of her 2018 album "I am AI".

===Google Magenta===
[[File:Hypnotic ambient electronic music by MusicLM.mp3|right|thumb|20-second music clip generated by MusicLM using the prompt "hypnotic ambient electronic music"]]
Google's Magenta team has published several AI music applications and technical papers since their launch in 2016.<ref>[https://magenta.tensorflow.org/blog/2016/06/01/welcome-to-magenta/] Welcome to Magenta. Douglas Eck. Published June 1, 2016.</ref> In 2017 they released the [[NSynth]] algorithm and dataset,<ref>{{Cite journal |last1=Engel |first1=Jesse |last2=Resnick |first2=Cinjon |last3=Roberts |first3=Adam |last4=Dieleman |first4=Sander |last5=Eck |first5=Douglas |last6=Simonyan |first6=Karen |last7=Norouzi |first7=Mohammad |date=2017 |title=Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders |arxiv=1704.01279 }}</ref> and an [[open source]] hardware musical instrument, designed to facilitate musicians in using the algorithm.<ref>{{Citation |title=Open NSynth Super |date=2023-02-13 |url=https://github.com/googlecreativelab/open-nsynth-super |publisher=Google Creative Lab |access-date=2023-02-14}}</ref> The instrument was used by notable artists such as [[Grimes]] and [[Yacht (band)|YACHT]] in their albums.<ref>{{Cite web |title=Cover Story: Grimes is ready to play the villain |url=https://crackmagazine.net/article/long-reads/grimes-is-ready-to-play-the-villain/ |access-date=2023-02-14 |website=Crack Magazine}}</ref><ref>{{Cite web |date=2019-09-18 |title=What Machine-Learning Taught the Band YACHT About Themselves |url=https://losangeleno.com/people/what-machine-learning-taught-the-band-yacht-about-themselves/ |access-date=2023-02-14 |website=Los Angeleno |language=en-US}}</ref> In 2018, they released a piano improvisation app called Piano Genie. This was later followed by Magenta Studio, a suite of 5 MIDI plugins that allow music producers to elaborate on existing music in their DAW.<ref>[https://magenta.tensorflow.org/studio/] Magenta Studio</ref> In 2023, their machine learning team published a technical paper on Github that described MusicLM, a private text-to-music generator developed.<ref>[https://google-research.github.io/seanet/musiclm/examples/] MusicLM on Github. Authored by Andrea Agostinelli, Timo I. Denk, Zalán Borsos, Jesse Engel, Mauro Verzetti, Antoine Caillon, Qingqing Huang, Aren Jansen, Adam Roberts, Marco Tagliasacchi, Matt Sharifi, Neil Zeghidour, Christian Frank. Published January 26, 2023.</ref><ref>[https://www.audiocipher.com/post/musiclm] Understanding What Makes MusicLM Unique. Published January 27, 2023.</ref>

===Riffusion===
{{excerpt|Riffusion}}

==Copyright==
{{Further|Artificial intelligence and copyright}}

The question of who owns the copyright to AI music outputs remain uncertain. When AI is used as a collaborative tool as a function of the human creative process, current US copyright laws are likely to apply.<ref>{{Cite web |title=Art created by AI cannot be copyrighted, says US officials – what does this mean for music? |url=https://musictech.com/news/industry/art-created-by-ai-cannot-be-copyrighted-says-us-officials-what-does-this-mean-for-music/ |access-date=2022-10-27 |website=MusicTech |language=en-GB}}</ref> However, music outputs solely generated by AI are not granted copyright protection. In the Compendium of U.S. Copyright Office Practices, the Copyright Office has stated that it would not grant copyrights to “works that lack human authorship” and “the Office will not register works produced by a machine or mere mechanical process that operates randomly or automatically without any creative input or intervention from a human author.”<ref>{{Cite web |date=2022-02-28 |title=Can (and should) AI-generated works be protected by copyright? |url=https://www.hypebot.com/hypebot/2022/02/can-and-should-ai-generated-works-be-protected-by-copyright.html |access-date=2022-10-27 |website=Hypebot |language=en-US}}</ref> In February 2022, the Copyright Review Board rejected an application to copyright AI-generated artwork on the basis that it "lacked the required human authorship necessary to sustain a claim in copyright."<ref>{{cite report|url=https://www.copyright.gov/rulings-filings/review-board/docs/a-recent-entrance-to-paradise.pdf|title=Re: Second Request for Reconsideration for Refusal to Register A Recent Entrance to Paradise (Correspondence ID 1-3ZPC6C3; SR # 1-7100387071)|publisher=Copyright Review Board, [[United States Copyright Office]]|date=2022-02-14}}</ref>

==See also==
* [[Algorithmic composition]]
* [[Automatic content recognition]]
* [[Computational models of musical creativity]]
* [[Generative artificial intelligence]]
* [[List of music software]]
* [[Music information retrieval]]
* {{section link|OpenAI|MuseNet and Jukebox (music)}}

==References==
{{Reflist|30em}}

==Further reading==
*[http://www.aaai.org/Press/Books/balaban.php Understanding Music with AI: Perspectives on Music Cognition] {{Webarchive|url=https://web.archive.org/web/20210110041609/https://www.aaai.org/Press/Books/balaban.php |date=2021-01-10 }}. Edited by Mira Balaban, Kemal Ebcioglu, and Otto Laske. AAAI Press.
*[http://portal.acm.org/citation.cfm?id=647303&coll=GUIDE&dl=GUIDE Proceedings of a Workshop held as part of AI-ED 93], World Conference on Artificial Intelligence in Education on Music Education: An Artificial Intelligence Approach
*{{Cite book|last=Tanguiane (Tangian) |first=Andranick |date=1993
|title= Artificial Perception and Music Recognition|series= Lecture Notes in Artificial Intelligence|volume=746
|publisher=Springer |location=Berlin-Heidelberg|isbn=978-3-540-57394-4}}

==External links==
*[http://www.dai.ed.ac.uk/groups/aimusic/ The Music Informatics Research Group]
*[https://web.archive.org/web/20160607023834/http://www.ircam.fr/accueil.html?&L=1 Institut de Recherche et Coordination Acoustique/ Musique]
*[https://web.archive.org/web/20190330070355/http://www.leeds.ac.uk/icsrim/ Interdisciplinary Centre for Research in Music]
*[https://mixdevil.com/ai-generated-music-good-or-bad Mixdevil - Is AI Good Gor Music Producers]
*[https://opendream.ai/ OpenDream]

{{Computer music}}

{{DEFAULTSORT:Music And Artificial Intelligence}}
[[Category:Artificial intelligence art| ]]
[[Category:Cognitive musicology]]
[[Category:Computer music]]