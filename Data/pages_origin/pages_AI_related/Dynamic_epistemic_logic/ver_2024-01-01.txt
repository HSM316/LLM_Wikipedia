'''Dynamic epistemic logic''' (DEL) is a logical framework dealing with knowledge and information change. Typically, DEL focuses on situations involving multiple [[Intelligent agent|agents]] and studies how their knowledge changes when [[Event (philosophy)|events]] occur. These events can change factual properties of the actual world (they are called ''ontic events''): for example a red card is painted in blue. They can also bring about changes of knowledge without changing factual properties of the world (they are called ''epistemic events''): for example a card is revealed publicly (or privately) to be red. Originally, DEL focused on epistemic events. We only present in this entry some of the basic ideas of the original DEL framework; more details about DEL in general can be found in the references.

Due to the nature of its object of study and its abstract approach, DEL is related and has applications to numerous research areas, such as [[computer science]] ([[artificial intelligence]]), [[philosophy]] ([[formal epistemology]]), [[economics]] ([[game theory]]) and [[cognitive science]]. In computer science, DEL is for example very much related to [[multi-agent systems]], which are systems where multiple intelligent agents interact and exchange information.

As a combination of [[Dynamic logic (modal logic)|dynamic logic]] and [[epistemic logic]], dynamic epistemic logic is a young field of research. It really started in 1989 with Plaza's logic of public announcement.<ref>{{Cite journal|title = Logics of public communications|journal = Synthese|date = 2007-07-26|issn = 0039-7857|pages = 165–179|volume = 158|issue = 2|doi = 10.1007/s11229-007-9168-7|first = Jan|last = Plaza| s2cid=41619205 }}</ref>  Independently, Gerbrandy and Groeneveld<ref>{{Cite journal|title = Reasoning about Information Change|journal = Journal of Logic, Language and Information|date = 1997-04-01|issn = 0925-8531|pages = 147–169|volume = 6|issue = 2|doi = 10.1023/A:1008222603071|first1 = Jelle|last1 = Gerbrandy|first2 = Willem|last2 = Groeneveld| s2cid=1700635 }}</ref>  proposed a system dealing moreover with private announcement and that was inspired by the work of Veltman.<ref>{{Cite journal|title = Defaults in update semantics|journal = Journal of Philosophical Logic|date = 1996-06-01|issn = 0022-3611|pages = 221–261|volume = 25|issue = 3|doi = 10.1007/BF00248150|first = Frank|last = Veltman|citeseerx = 10.1.1.77.9349| s2cid=19377671 }}</ref> Another system was proposed by van Ditmarsch whose main inspiration was the [[Cluedo]] game.<ref>{{Cite journal|title = Descriptions of Game Actions|journal = Journal of Logic, Language and Information|date = 2002-06-01|issn = 0925-8531|pages = 349–365|volume = 11|issue = 3|doi = 10.1023/A:1015590229647|first = Hans P. van|last = Ditmarsch| s2cid=195220171 }}</ref> But the most influential and original system was the system proposed by Baltag, Moss and Solecki.<ref name=":0" /><ref name=":1">{{Cite journal|title = Logics for Epistemic Programs|journal = Synthese|date = 2004-03-01|issn = 0039-7857|pages = 165–224|volume = 139|issue = 2|doi = 10.1023/B:SYNT.0000024912.56773.5e|first1 = Alexandru|last1 = Baltag|first2 = Lawrence S.|last2 = Moss| s2cid=18793176 }}</ref> This system can deal with all the types of situations studied in the works above and its underlying methodology is conceptually grounded. We will present in this entry some of its basic ideas.

Formally, DEL extends ordinary epistemic logic by the inclusion of event models to describe actions, and a product update operator that defines how epistemic models are updated as the consequence of executing actions described through event models. Epistemic logic will first be recalled. Then, actions and events will enter into the picture and we will introduce the DEL framework.<ref>A distinction is sometimes made between events and actions, an action being a specific type of event performed by an agent.
</ref>

== Epistemic Logic ==

Epistemic logic is a [[modal logic]] dealing with the notions of knowledge and belief. As a [[logic]], it is concerned with understanding the process of ''reasoning'' about knowledge and belief: which principles relating the notions of knowledge and belief are intuitively plausible? Like epistemology, it stems from the Greek word <math>\epsilon\pi\iota\sigma\tau\eta\mu\eta</math> or ‘episteme’ meaning knowledge. [[Epistemology]] is nevertheless more concerned with analyzing the very ''nature'' and ''scope'' of knowledge, addressing questions such as “What is the definition of knowledge?” or “How is knowledge acquired?”. In fact, epistemic logic grew out of epistemology in the Middle Ages thanks to the efforts of Burley and Ockham.<ref>{{Cite book|title = Epistemic Logic in the later Middle Ages|last = Boh|first = Ivan|publisher = Routledge|year = 1993|isbn = 978-0415057264}}</ref> The formal work, based on modal logic, that inaugurated contemporary research into epistemic logic dates back only to 1962 and is due to [[Hintikka]].<ref>{{Cite book|title = Knowledge and Belief, An Introduction to the Logic of the Two Notions|last = Jaako|first = Hintikka|publisher = Cornell University Press|year = 1962|isbn = 978-1904987086|location = Ithaca and London}}</ref> It then sparked in the 1960s discussions about the principles of knowledge and belief and many axioms for these notions were proposed and discussed.<ref name=":3">{{Cite journal|title = Recent Work in Epistemic Logic|last = Lenzen|first = Wolfgang|date = 1978|journal = Acta Philosophica Fennica}}</ref> For example, the interaction axioms <math>K p\rightarrow B p</math> and <math>B p\rightarrow KB p</math> are often considered to be intuitive principles: if an agent Knows <math>p</math> then (s)he also Believes <math>p</math>, or if an agent Believes <math>p</math>, then (s)he Knows that (s)he Believes <math>p</math>. More recently, these kinds of philosophical theories were taken up by researchers in [[economics]],<ref>{{Cite journal|title = Recent results on belief, knowledge and the epistemic foundations of game theory|journal = Research in Economics|date = 1999-06-01|pages = 149–225|volume = 53|issue = 2|doi = 10.1006/reec.1999.0187|first1 = Pierpaolo|last1 = Battigalli|first2 = Giacomo|last2 = Bonanno|hdl = 10419/189483|url = http://repec.dss.ucdavis.edu/files/rfM2rUmEkFZMsfwVAGgXj8TM/98-14.pdf}}</ref> [[artificial intelligence]] and [[theoretical computer science]]<ref name=":4">{{Cite book|title = Reasoning about Knowledge|author1=Ronald Fagin |author2=Joseph Halpern |author3=Yoram Moses |author4=Moshe Vardi |publisher = MIT Press|year = 1995|isbn = 9780262562003}}</ref> where reasoning about knowledge is a central topic. Due to the new setting in which epistemic logic was used, new perspectives and new features such as [[Computability theory|computability]] issues were then added to the research agenda of epistemic logic.

=== Syntax ===

In the sequel, <math>AGTS=\{1,\ldots,n\}</math> is a finite set whose elements are called agents and <math>PROP</math> is a set of propositional letters.

The epistemic language is an extension of the basic multi-modal language of modal logic with a [[Common knowledge (logic)|common knowledge]] operator <math>C_{A}</math> and a [[distributed knowledge]] operator <math>D_{A}</math>. Formally, the '''epistemic language''' <math>\mathcal{L}_{\textsf{EL}}^{C}</math> is defined inductively by the following [[Formal grammar|grammar]] in [[BNF grammar|BNF]]:

<math>\mathcal{L}_{\textsf{EL}}^{C}:\phi~~::=~~ p~\mid~\neg\phi~\mid~(\phi\land\phi)~\mid~
K_j\phi~\mid~ C_{A}\phi ~\mid~  D_{A}\phi</math>

where <math>p\in PROP</math>, <math>j\in {AGTS}</math> and <math>A\subseteq {AGTS}</math>. The '''basic epistemic language''' <math>\mathcal{L}_{EL}</math> is the language <math>\mathcal{L}_{EL}^{C}</math> without the common knowledge and distributed knowledge operators. The formula <math>\bot</math> is an abbreviation for <math>\neg p \land p</math> (for a given <math>p\in PROP</math>),  <math>\langle K_{j}\rangle\phi</math> is an abbreviation for <math>\neg K_j\neg\phi</math>, <math>E_{A}\phi</math> is an abbreviation for <math>\bigwedge\limits_{j\in A} K_j\phi</math> and <math>C\phi</math> an abbreviation for <math>C_{AGTS}\phi</math>.

'''Group notions: general, common and distributed knowledge.'''

In a multi-agent setting there are three important epistemic concepts: general knowledge, distributed knowledge and common knowledge. The notion of common knowledge was first studied by [[David Lewis (philosopher)|Lewis]] in the context of conventions.<ref>{{Cite book|title = Convention, a Philosophical Study|last = Lewis|first = David|publisher = Harvard University Press|year = 1969|isbn = 978-0674170254}}</ref> It was then applied to [[distributed systems]]<ref name=":4" />  and to [[game theory]],<ref>{{Cite journal|title = Agreeing to Disagree|jstor = 2958591|journal = The Annals of Statistics|date = 1976-11-01|pages = 1236–1239|volume = 4|issue = 6|first = Robert J.|last = Aumann|doi=10.1214/aos/1176343654|doi-access = free}}</ref> where it allows to express that the rationality of the players, the rules of the game and the set of players are commonly known.

''General knowledge.''

General knowledge of <math>\phi</math> means that everybody in the group of agents <math>{AGTS}</math> knows that <math>\phi</math>. Formally, this corresponds to the following formula:

<math>E\phi:=\underset{j\in {AGTS}}\bigwedge K_j\phi.</math>

''Common knowledge.''

Common knowledge of <math>\phi</math> means that everybody knows <math>\phi</math> but also that everybody knows that everybody knows <math>\phi</math>, that everybody knows that everybody knows that everybody knows <math>\phi</math>, and so on ''ad infinitum''. Formally, this corresponds to the following formula

<math>C\phi:=E\phi\land E E\phi\land E E E\phi\land\ldots</math>

As we do not allow infinite conjunction the notion of common knowledge will have to be introduced as a primitive in our language.

Before defining the language with this new operator, we are going to give an example introduced by [[David Lewis (philosopher)|Lewis]] that illustrates the difference between the notions of general knowledge and common knowledge. Lewis wanted to know what kind of knowledge is needed so that the statement <math>p</math>: “every driver must drive on the right” be a convention among a group of agents. In other words, he wanted to know what kind of knowledge is needed so that everybody feels safe to drive on the right. Suppose there are only two agents <math>i</math> and <math>j</math>. Then everybody knowing <math>p</math> (formally <math>E p</math>) is not enough. Indeed, it might still be possible that the agent <math>i</math> considers possible that the agent <math>j</math> does not know <math>p</math> (formally <math>\neg K_i K_j p</math>). In that case the agent <math>i</math> will not feel safe to drive on the right because he might consider that the agent <math>j</math>, not knowing <math>p</math>, could drive on the left. To avoid this problem, we could then assume that everybody knows that everybody knows that <math>p</math> (formally <math>E E p</math>). This is again not enough to ensure that everybody feels safe to drive on the right. Indeed, it might still be possible that agent <math>i</math> considers possible that agent <math>j</math> considers possible that agent <math>i</math> does not know <math>p</math> (formally <math>\neg K_i K_j K_i p</math>). In that case and from <math>i</math>’s point of view, <math>j</math> considers possible that <math>i</math>, not knowing <math>p</math>, will drive on the left. So from <math>i</math>’s point of view, <math>j</math> might drive on the left as well (by the same argument as above). So <math>i</math> will not feel safe to drive on the right. Reasoning by induction, Lewis showed that for any <math>k\in \mathbb{N}</math>, <math>E p\land E^1 p\land \ldots \land E^k p</math> is not enough for the drivers to feel safe to drive on the right. In fact what we need is an infinite conjunction. In other words, we need common knowledge of <math>p</math>: <math>C p</math>.

''Distributed knowledge.''

Distributed knowledge of <math>\phi</math> means that if the agents pulled their knowledge altogether, they would know that <math>\phi</math> holds. In other words, the knowledge of <math>\phi</math> is ''distributed'' among the agents. The formula <math>D_{A}\phi</math> reads as ‘it is distributed knowledge among the set of agents <math>A</math> that <math>\phi</math> holds’.

=== Semantics ===

Epistemic logic is a modal logic. So, what we call an '''epistemic model''' <math>\mathcal{M}=(W, R_1,\ldots, R_n,I)</math> is just a [[Kripke model]] as defined in modal logic. The set <math>W</math> is a non-empty set whose elements are called ''possible worlds'' and the ''interpretation'' <math>I:W\rightarrow 2^{PROP}</math> is a [[Function (mathematics)|function]] specifying which propositional facts (such as ‘Ann has the red card’) are true in each of these worlds. The ''accessibility relations'' <math>R_j\subseteq W\times W</math> are [[binary relation]]s for each agent <math>j\in AGTS</math>; they are intended to capture the uncertainty of each agent (about the actual world and about the other agents' uncertainty). Intuitively, we have <math>(w,v)\in R_j</math> when the world <math>v</math> is compatible with agent <math>j</math>’s information in world <math>w</math> or, in other words, when agent <math>j</math> considers that world <math>v</math> might correspond to the world <math>w</math> (from this standpoint). We abusively write <math>w\in\mathcal{M}</math> for <math>w\in W</math> and <math>R_j(w)</math> denotes the set of worlds <math>\{v\in W; (w,v)\in R_j\}</math>.

Intuitively, a '''pointed epistemic model''' <math>(\mathcal{M},w)</math>, where <math>w\in\mathcal{M}</math>, represents from an external point of view how the actual world <math>w</math> is perceived by the agents <math>{AGTS}</math>.

For every epistemic model <math>\mathcal{M}</math>, every <math>w\in \mathcal{M}</math> and every <math>\phi\in\mathcal{L}_{\textsf{EL}}</math>, we define <math>\mathcal{M},w\models\phi</math> inductively by the following [[truth conditions]]:

{|
|<math>\mathcal{M},w\models p</math>
|iff
|<math>p\in I(w)</math>
|-
|<math>\mathcal{M},w\models \neg\phi</math>
|iff
|<math>\textrm{it~is~not~the~case~that~}\mathcal{M},w\models\phi</math>
|-
|<math>\mathcal{M},w\models \phi\land\psi</math>
|iff
|<math>\mathcal{M},w\models\phi\textrm{~and~}\mathcal{M},w\models\psi</math>
|-
|<math>\mathcal{M},w\models K_j\phi</math>
|iff
|<math display="inline">\textrm{for~all~} v\in R_j(w),  \mathcal{M},v\models\phi</math>
|-
|<math>\mathcal{M},w\models C_{A}\phi</math>
|iff
|<math>\textrm{for~all~}v\in \left(\underset{j\in A}{\bigcup}R_j\right)^+(w), \mathcal{M},v\models\phi</math>
|-
|<math>\mathcal{M},w\models D_{A}\phi</math>
|iff
|<math>\textrm{for~all~}v\in \underset{j\in A}{\bigcap}R_j (w), \mathcal{M},v\models\phi</math>
|}

where <math>\left(\underset{j\in A}{\bigcup}R_j\right)^+</math> is the [[transitive closure]] of <math>\underset{j\in A}{\bigcup}R_j</math>: we have that <math>v\in\left(\underset{j\in A}{\bigcup}R_j\right)^+(w)</math> if, and only if, there are <math>w_0,\ldots,w_m\in\mathcal{M}</math> and <math>j_1,\ldots,j_m\in A</math> such that <math>w_0=w, w_m=v</math> and for all <math>i\in\{1,\ldots,m\}</math>, <math>w_{i-1} R_{j_i} w_i</math>.

Despite the fact that the notion of common belief has to be introduced as a primitive in the language, we can notice that the definition of epistemic models does not have to be modified in order to give truth value to the common knowledge and distributed knowledge operators.

'''Card Example:'''

Players <math>A</math>, <math>B</math> and <math>C</math> (standing for Ann, Bob and Claire) play a card game with three cards: a red one, a green one and a blue one. Each of them has a single card but they do not know the cards of the other players. Ann has the red card, Bob has the green card and Claire has the blue card. This example is depicted in the pointed epistemic model <math>(\mathcal{M},w)
</math> represented below. In this example, <math>AGTS:=\{A,B,C\}</math> and <math>PROP:=\{{\color{red}{A}},{\color{green}{B}},{\color{blue}{C}},{\color{red}{B}},{\color{green}{C}},{\color{blue}{A}},{\color{red}{C}},{\color{green}{A}},{\color{blue}{B}}\}</math>. Each world is labelled by the propositional letters which are true in this world and <math>w</math> corresponds to the actual world. There is an arrow indexed by agent <math>j\in\{A,B,C\}
</math> from a possible world <math>u</math> to a possible world <math>v</math> when <math>(u,v)\in R_j</math>. Reflexive arrows are omitted, which means that for all <math>j\in \{A,B,C\}</math> and all <math>v\in \mathcal{M}</math>, we have that <math>(v,v)\in R_j</math>.
[[File:WikiDEL1b.png|frame|Card Example: pointed epistemic model <math>(\mathcal{M},w)</math>]]
<math>{\color{red}{A}}</math> stands for : "<math>A</math> has the red card<nowiki>''</nowiki>

<math>{\color{blue}{C}}</math> stand for: "<math>C</math> has the blue card<nowiki>''</nowiki>

<math>{\color{green}{B}}</math> stands for: "<math>B</math> has the green card<nowiki>''</nowiki>

and so on...

When accessibility relations are equivalence relations (like in this example) and we have that <math>(w,v)\in R_j</math>, we say that agent <math>j</math> ''cannot distinguish'' world <math>w</math> from world <math>v</math> (or world <math>w</math> is indistinguishable from world <math>v</math> for agent <math>j</math>). So, for example, <math display="inline">A</math> cannot distinguish the actual world <math>w</math> from the possible world where <math>B</math> has the blue card (<math>{\color{blue}{B}}</math>), <math>C</math> has the green card (<math>{\color{green}{C}}</math>) and <math>A</math> still has the red card (<math>{\color{red}{A}}</math>).

In particular, the following statements hold:

<math>\mathcal{M},w\models({\color{red}{A}}\land K_A{\color{red}{A}})\land({\color{blue}{C}}\land K_C{\color{blue}{C}})\land ({\color{green}{B}}\land K_B{\color{green}{B}})</math>

'All the agents know the color of their card'.

<math>\mathcal{M},w\models K_A({\color{blue}{B}}\vee{\color{green}{B}})\land K_A({\color{blue}{C}}\vee{\color{green}{C}})</math>

'<math>A</math> knows that <math>B</math> has either the blue or the green card and that <math>C</math> has either the blue or the green card'.

<math>\mathcal{M},w\models E({\color{red}{A}}\vee{\color{blue}{A}}\vee{\color{green}{A}})\land C({\color{red}{A}}\vee{\color{blue}{A}}\vee{\color{green}{A}})</math>

'Everybody knows that <math>A</math> has either the red, green or blue card and this is even common knowledge among all agents'.

=== Knowledge versus Belief ===
We use the same notation <math>K_j</math> for both knowledge and belief. Hence, depending on the context, <math>K_j\phi</math> will either read ‘the agent <math>j</math> ''K''nows that <math>\phi</math> holds’ or ‘the agent <math>j</math> ''B''elieves that <math>\phi</math> holds’. A crucial difference is that, unlike knowledge, beliefs can be ''wrong'': the axiom <math>K_j\phi\rightarrow \phi</math> holds only for knowledge, but not necessarily for belief. This axiom called axiom T (for Truth) states that if the agent knows a proposition, then this proposition is true. It is often considered to be the hallmark of knowledge and it has not been subjected to any serious attack ever since its introduction in the [[Theaetetus (dialogue)|Theaetetus]] by [[Plato]].

The notion of knowledge might comply to some other constraints (or axioms) such as <math>K_j\phi\rightarrow  K_j K_j\phi</math>: if agent <math>j</math> knows something, she knows that she knows it. These constraints might affect the nature of the accessibility relations <math>R_j</math> which may then comply to some extra properties. So, we are now going to define some particular classes of epistemic models that all add some extra constraints on the accessibility relations <math>R_j</math>. These constraints are matched by particular axioms for the knowledge operator <math>K_j</math>. Below each property, we give the axiom which ''defines''<ref>{{Cite book|title = Modal Logic|author1=Patrick Blackburn |author2=Maarten de Rijke |author3=Yde Venema |publisher = Cambridge University Press|year = 2001|isbn = 978-0521527149}}</ref> the class of epistemic frames that fulfill this property. (<math>K\phi</math> stands for <math>K_j\phi</math> for any <math>j\in AGTS</math>.)

{| class="wikitable"
|+
'''Properties of accessibility relations and corresponding axioms'''

|-
| align="center" |'''serial'''
|<math>R(w)\neq\emptyset</math>
|-
| align="center" |'''D'''
|<math>K\phi\rightarrow  \langle K\rangle\phi</math>
|-
| align="center" |[[Transitive relation|'''transitive''']]
|<math>\textrm{If }~w'\in R(w) ~\textrm{ and }~ w''\in R(w'), ~\textrm{ then}~  w''\in R(w)</math>
|-
| align="center" |'''4'''
|<math>K\phi\rightarrow  KK\phi</math>
|-
| align="center" |'''Euclidicity'''
|<math>\textrm{If }~ w'\in R(w) ~\textrm{ and }~ w''\in R(w), ~\textrm{ then }~ w'\in R(w'')</math>
|-
| align="center" |'''5'''
|<math>\neg K \phi\rightarrow  K \neg K\phi</math>
|-
| align="center" |[[Reflexive relation|'''reflexive''']]
|<math>w\in R(w)</math>
|-
| align="center" |'''T'''
|<math>K\phi\rightarrow \phi</math>
|-
| align="center" |'''symmetric'''
|<math>\textrm{If }~ w'\in R(w), ~\textrm{ then }~ w\in R(w')</math>
|-
| align="center" |'''B'''
|<math>\phi\rightarrow K\neg K\neg\phi</math>
|-
| align="center" |'''confluent'''
|<math>\textrm{If }~ w'\in R(w) \textrm{~and~} w''\in R(w), \textrm{then~there~is~} v \textrm{~such~ that }~ v\in R(w') \textrm{~and~} v\in R(w'')</math>
|-
| align="center" |'''.2'''
|<math>\langle K\rangle K\phi\rightarrow  K\langle K\rangle\phi</math>
|-
| align="center" |'''weakly connected'''
|<math>\textrm{If }~ w'\in R(w) \textrm{~and~} w''\in R(w), \textrm{~then~}  w'=w'' \textrm{~or~} w'\in R(w'') \textrm{~or~} w''\in R(w')</math>
|-
| align="center" |'''.3'''
|<math>\langle K\rangle\phi\land\langle K\rangle\psi\rightarrow \langle K\rangle(\phi\land\psi)\vee\langle K\rangle(\psi\land\langle K\rangle\phi)\vee\langle K\rangle(\phi\land\langle K\rangle\psi)</math>
|-
| align="center" |'''semi-Euclidean'''
|<math>\textrm{If~} w''\in R(w) \textrm{~and~}  w\notin R(w'') \textrm{~and~} w'\in R(w), \textrm{~then~}  w''\in R(w')</math>
|-
| align="center" |'''.3.2'''
|<math>(\langle K\rangle\phi\land\langle K\rangle K\psi)\rightarrow  K(\langle K\rangle\phi\vee\psi)</math>
|-
| align="center" |'''R1'''
|<math>\textrm{If~} w''\in R(w) \textrm{~and~} w\neq w'' \textrm{~and~} w'\in R(w), \textrm{~then~}  w''\in R(w')</math>
|-
| align="center" |'''.4'''
|<math>(\phi\land\langle K\rangle K \phi)\rightarrow  K\phi</math>
|}

We discuss the axioms above. Axiom 4 states that if the agent knows a proposition, then she knows that she knows it (this axiom is also known as the “KK-principle”or “KK-thesis”). In epistemology, axiom 4 tends to be accepted by [[internalists]], but not by [[externalists]].<ref>{{Cite web|title = Internet Encyclopedia of Philosophy » KK Principle (Knowing that One Knows) Internet Encyclopedia of Philosophy » Print|url = http://www.iep.utm.edu/kk-princ/print/|website = www.iep.utm.edu|access-date = 2015-12-11|archive-url = https://web.archive.org/web/20160304205052/http://www.iep.utm.edu/kk-princ/print/|archive-date = 2016-03-04|url-status = dead}}</ref> Axiom 4 is nevertheless widely accepted by computer scientists (but also by many philosophers, including [[Plato]], [[Aristotle]], [[Augustine of Hippo|Saint Augustine]], [[Baruch Spinoza|Spinoza]] and [[Arthur Schopenhauer|Schopenhauer]], as [[Jaakko Hintikka|Hintikka]] recalls ). A more controversial axiom for the logic of knowledge is axiom 5 for Euclidicity: this axiom states that if the agent does not know a proposition, then she knows that she does not know it. Most philosophers (including Hintikka) have attacked this axiom, since numerous examples from everyday life seem to invalidate it.<ref name=":6">For example, assume that a university professor believes (is certain) that one of her colleague’s seminars is on Thursday (formally <math>B p</math>). She is actually wrong because it is on Tuesday (<math>\neg p</math>). Therefore, she does not know that her colleague’s seminar is on Tuesday (<math>\neg K p</math>). If we assume that axiom is valid then we should conclude that she knows that she does not know that her colleague’s seminar is on Tuesday (<math>K \neg K p</math>) (and therefore she also believes that she does not know it: <math>B\neg K p</math>). This is obviously counterintuitive.
</ref> In general, axiom 5 is invalidated when the agent has mistaken beliefs, which can be due for example to misperceptions, lies or other forms of deception. Axiom B states that it cannot be the case that the agent considers it possible that she knows a false proposition (that is, <math>\neg(\neg\phi\land\neg K\neg K\phi)</math>). If we assume that axioms T and 4 are valid, then axiom B falls prey to the same attack as the one for axiom 5 since this axiom is derivable. Axiom D states that the agent's beliefs are consistent. In combination with axiom K (where the knowledge operator is replaced by a belief operator), axiom D is in fact equivalent to a simpler axiom D' which conveys, maybe more explicitly, the fact that the agent's beliefs cannot be inconsistent: <math>\neg B \bot</math>. The other intricate axioms .2, .3, .3.2 and .4 have been introduced by epistemic logicians such as Lenzen and Kutchera in the 1970s<ref name=":3" /><ref name=":5" /> and presented for some of them as key axioms of epistemic logic. They can be characterized in terms of intuitive interaction axioms relating knowledge and beliefs.<ref>{{Cite journal|title = Intricate Axioms as Interaction Axioms|journal = Studia Logica|date = 2015-03-18|issn = 0039-3215|pages = 1035–1062|volume = 103|issue = 5|doi = 10.1007/s11225-015-9609-0|first = Guillaume|last = Aucher| s2cid=255074436 |url = https://hal.inria.fr/hal-01193284/file/FinalRevisedStudiaLogica2014.pdf}}</ref>

=== Axiomatization ===

The Hilbert [[proof system]] K for the basic modal logic is defined by the following [[axiom]]s and [[inference rules]]: for all <math>j\in AGTS</math>,

{| class="wikitable"
|+Proof system <math>\textsf{K}</math> for <math>\mathcal{L}_{EL}</math>
|-
|'''Prop'''
|All axioms and inference rules of [[propositional logic]]
|-
|'''K'''
|<math>K_j(\phi\rightarrow\psi)\rightarrow(K_j\phi\rightarrow K_j\psi)</math>
|-
|'''Nec'''
|If <math>\phi</math> then <math>K_j\phi</math>
|}

The axioms of an epistemic logic obviously display the way the agents reason. For example, the axiom K together with the rule of inference Nec entail that if I know <math>\phi</math> (<math>K\phi</math>) and I know that <math>\phi</math> implies <math>\psi</math>  (<math>K(\phi\rightarrow \psi))</math> then I know that <math>\psi</math> (<math>K\psi</math>). Stronger constraints can be added. The following  [[proof system]]s for <math>\mathcal{L}_{\textsf{EL}}</math> are often used in the literature.

{|
|+'''Common proof systems for <math> \mathcal{L}_{EL}</math>'''
|KD45
|=
|K+D+4+5                                    
|
|
|
|S4.2
|=
|S4+.2              
|
|
|
|S4.3.2
|=
|S4+.3.2
|
|
|
|S5
|=
|S4+5
|-
|S4
|=
|K+T+4
|
|
|
|S4.3
|=
|S4+.3
|
|
|
|S4.4
|=
|S4+.4
|
|
|
|Br
|=
|K+T+B
|}

We define the set of proof systems <math>\mathbb{L}_{\textsf{EL}}:=\{\textsf{K}, \textsf{KD45},\textsf{S4},\textsf{S4.2},\textsf{S4.3},\textsf{S4.3.2},\textsf{S4.4},\textsf{S5}\}</math>.

Moreover, for all <math>\mathcal{H}\in\mathbb{L}_{\textsf{EL}}</math>, we define the proof system <math>\mathcal{H}^{\textsf{C}}</math> by adding the following [[Axiom schema|axiom schemes]] and [[Rule of inference|rules of inference]] to those of <math>\mathcal{H}</math>. For all <math>A\subseteq AGTS</math>,

{| 
|'''Dis'''
|<math>K_j\phi\rightarrow  D_A\phi</math>
|-
|'''Mix'''
|<math>C_{A}\phi\rightarrow  E_{A}(\phi\land C_{A}\phi)</math>
|-
|'''Ind'''
|<math>\textrm{if~} \phi\rightarrow  E_{A}(\psi\land\phi) \textrm{~then~} \phi\rightarrow  C_{A}\psi</math>
|}

The relative strength of the proof systems for knowledge is as follows:

<math>\textsf{S4}\subset \textsf{S4.2}\subset \textsf{S4.3}\subset\textsf{S4.3.2}\subset\textsf{S4.4}\subset \textsf{S5}.</math>

So, all the [[theorem]]s of <math>\textsf{S4.2}</math> are also theorems of <math>\textsf{S4.3}, \textsf{S4.3.2}, \textsf{S4.4}</math> and <math>\textsf{S5}</math>. Many philosophers claim that in the most general cases, the logic of knowledge is <math>\textsf{S4.2}</math> or <math>\textsf{S4.3}</math>.<ref name=":5">{{Cite journal|title = Epistemologische betrachtungen zu [S4, S5]|journal = Erkenntnis|date = 1979-03-01|issn = 0165-0106|pages = 33–56|volume = 14|issue = 1|doi = 10.1007/BF00205012|language = de|first = Wolfgang|last = Lenzen| s2cid=122982410 }}</ref><ref>{{Cite journal|title = On Logics of Knowledge and Belief|journal = Philosophical Studies|date = 2006-03-01|issn = 0031-8116|pages = 169–199|volume = 128|issue = 1|doi = 10.1007/s11098-005-4062-y|first = Robert|last = Stalnaker| s2cid=170320855 }}</ref> Typically, in computer science and in many of the theories developed in artificial intelligence, the logic of belief (''doxastic'' logic) is taken to be <math>\textsf{KD45}</math> and the logic of knowledge (''epistemic'' logic) is taken to be <math>\textsf{S5}</math>, even if <math>\textsf{S5}</math> is only suitable for situations where the agents do not have mistaken beliefs.<ref name=":6" /> <math>\textsf{Br}</math> has been propounded by Floridi as the logic of the notion of 'being informed’ which mainly differs from the logic of knowledge by the absence of introspection for the agents.<ref>{{Cite book|chapter-url = http://www.oxfordscholarship.com/view/10.1093/acprof:oso/9780199232383.001.0001/acprof-9780199232383-chapter-10|pages = 224–243|doi = 10.1093/acprof:oso/9780199232383.003.0010|first = Luciano|last = Floridi|isbn = 9780191594809|publisher = Oxford University Press|date = 2011-01-27|title = The Philosophy of Information|chapter = The logic of being informed}}</ref>

For all <math>\mathcal{H}\in\mathbb{L}_{\textsf{EL}}</math>, the '''class of <math>\mathcal{H}</math>–models''' or '''<math>\mathcal{H}^{\textsf{C}}</math>–models''' is the class of epistemic models whose accessibility relations satisfy the properties listed above defined by the axioms of <math>\mathcal{H}</math> or <math>\mathcal{H}^{\textsf{C}}</math>. Then, for all <math>\mathcal{H}\in\mathbb{L}_{\textsf{EL}}</math>, <math>\mathcal{H}</math> is [[Soundness|sound]] and [[Completeness (logic)|strongly complete]] for <math>\mathcal{L}_{\textsf{EL}}</math> w.r.t. the class of <math>\mathcal{H}</math>–models, and <math>\mathcal{H}^{\textsf{C}}</math> is [[Soundness|sound]] and [[Completeness (logic)|strongly complete]] for <math>\mathcal{L}_{\textsf{EL}}^{\textsf{C}}</math> w.r.t. the class of <math>\mathcal{H}^{\textsf{C}}</math>–models.

=== Decidability and Complexity ===

The [[satisfiability problem]] for all the logics introduced is [[Decidable problem|decidable]]. We list below the [[Complexity class|computational complexity]] of the satisfiability problem for each of them. Note that it becomes linear in time if there are only finitely many propositional letters in the language. For <math>n\geq 2</math>, if we restrict to finite nesting, then the satisfiability problem is [[NP-completeness|NP-complete]] for all the modal logics considered. If we then further restrict the language to having only finitely many primitive propositions, the complexity goes down to linear in time in all cases.<ref>{{Cite journal|title = A guide to completeness and complexity for modal logics of knowledge and belief|journal = Artificial Intelligence|pages = 319–379|volume = 54|issue = 3|doi = 10.1016/0004-3702(92)90049-4|first1 = Joseph Y.|last1 = Halpern|first2 = Yoram|last2 = Moses|year = 1992}}</ref><ref>{{Cite journal|title = The effect of bounding the number of primitive propositions and the depth of nesting on the complexity of modal logic|journal = Artificial Intelligence|date = 1995-06-01|pages = 361–372|volume = 75|issue = 2|doi = 10.1016/0004-3702(95)00018-A|first = Joseph Y.|last = Halpern|doi-access = free}}</ref>

{| class="wikitable"
|+Complexity of the satisfiability problem
|-
!Logic
!<math>n=1</math>
!<math>n\geq 2</math>
!with common knowledge
|-
|K, S4
|PSPACE
|PSPACE
|EXPTIME
|-
|KD45
|NP
|PSPACE
|EXPTIME
|-
|S5
|NP
|PSPACE
|EXPTIME
|}

The computational complexity of the [[Model checking|model checking problem]] is in [[Polynomial time|P]] in all cases.

== Adding Dynamics ==

Dynamic Epistemic Logic (DEL) is a logical framework for modeling epistemic situations involving several agents, and changes that occur to these situations as a result of incoming information or more generally incoming action. The methodology of DEL is such that it splits the task of representing the agents’ beliefs and knowledge into three parts:

# One represents their beliefs about an initial situation thanks to an ''epistemic model'';
# One represents their beliefs about an event taking place in this situation thanks to an ''event model'';
# One represents the way the agents update their beliefs about the situation after (or during) the occurrence of the event thanks to a ''product update''.

Typically, an informative event can be a public announcement to all the agents of a formula <math>\psi</math>: this public announcement and correlative update constitute the dynamic part. However, epistemic events can be much more complex than simple public announcement, including hiding information for some of the agents, cheating, lying, bluffing, ''etc.'' This complexity is dealt with when we introduce the notion of event model. We will first focus on public announcements to get an intuition of the main underlying ideas of DEL.

=== Public Events ===

In this section, we assume that all events are public. We start by giving a concrete example where DEL can be used, to better understand what is going on. This example is called the [[Induction puzzles#Muddy Children Puzzle|muddy children puzzle]]. Then, we will present a formalization of this puzzle in a logic called [[Public Announcement Logic]] (PAL). The muddy children puzzle is one of the most well known puzzles that played a role in the development of DEL. Other significant puzzles include the [[Sum and Product Puzzle|sum and product puzzle]], the [[Monty Hall problem|Monty Hall dilemma]], the [[Russian cards problem]], the [[two envelopes problem]], [[Moore's paradox]], the [[hangman paradox]], ''etc''.<ref>{{Cite book |title= One Hundred Prisoners and a Light Bulb - Springer |doi= 10.1007/978-3-319-16694-0 |first1= Hans |last1= van Ditmarsch |first2= Barteld |last2= Kooi|year= 2015 |isbn= 978-3-319-16693-3 }}</ref>

'''Muddy Children Example:'''

We have two children, A and B, both dirty. A can see B but not himself, and B can see A but not herself. Let <math>p</math> be the proposition stating that A is dirty, and <math>q</math> be the proposition stating that B is dirty.

# We represent the initial situation by the pointed epistemic model <math>(\mathcal{N},s)</math> represented below, where relations between worlds are equivalence relations. States <math>s,t,u,v</math> intuitively represent possible worlds, a proposition (for example <math>p</math>) satisfiable at one of these worlds intuitively means that in the corresponding possible world, the intuitive interpretation of <math>p</math> (A is dirty) is true. The links between worlds labelled by agents (A or B) intuitively express a notion of indistinguishability for the agent at stake between two possible worlds. For example, the link between <math>s</math> and <math>t</math> labelled by A intuitively means that A can not distinguish the possible world <math>s</math> from <math>t</math> and vice versa. Indeed, A cannot see himself, so he cannot distinguish between a world where he is dirty and one where he is not dirty. However, he can distinguish between worlds where B is dirty or not because he can see B. With this intuitive interpretation we are brought to assume that our relations between worlds are equivalence relations.[[File:WikiDEL2b.png|centre|frame|Initial situation: pointed epistemic model <math>(\mathcal{N},s)</math>]]
# Now, suppose that their father comes and announces that at least one is dirty (formally, <math>p\vee q</math>). Then we update the model and this yields the pointed epistemic model represented below. What we actually do is suppressing the worlds where the content of the announcement is not fulfilled. In our case this is the world where <math>\neg p</math> and <math>\neg q</math> are true. This suppression is what we call the update. We then get the model depicted below. As a result of the announcement, both A and B do know that at least one of them is dirty. We can read this from the epistemic model.[[File:WikiDEL3b.png|centre|frame|Updated epistemic model after the first announcement <math>p\vee q</math>]]
# Now suppose there is a second (and final) announcement that says that neither knows they are dirty (an announcement can express facts about the situation as well as epistemic facts about the knowledge held by the agents). We then update similarly the model by suppressing the worlds which do not satisfy the content of the announcement, or equivalently by keeping the worlds which do satisfy the announcement. This update process thus yields the pointed epistemic model represented below. By interpreting this model, we get that A and B both know that they are dirty, which seems to contradict the content of the announcement. However, if we assume that A and B are both perfect reasoners and that this is common knowledge among them, then this inference makes perfect sense.
[[File:WikiDEL4b.png|centre|Updated epistemic model after the second announcement|frame]]

'''Public announcement logic (PAL):'''

We present the syntax and semantic of [[Public Announcement Logic]] (PAL), which combines features of epistemic logic and [[propositional dynamic logic]].<ref name=":2">{{Cite book|title = Dynamic Logic|author1 = David Harel|author2 = Dexter Kozen|author3 = Jerzy Tiuryn|publisher = MIT Press|year = 2000|isbn = 978-0262082891|url-access = registration|url = https://archive.org/details/dynamiclogicfoun00davi_0}}</ref>

We define the '''language <math>{\mathcal{L}_{PAL}}</math>''' inductively by the following [[Formal grammar|grammar]] in [[BNF grammar|BNF]]:

<math>{\mathcal{L}_{PAL}}:\phi~~::=~~  p~\mid~\neg\phi~\mid~(\phi\land\phi)~\mid~K_j\phi~\mid~[\phi!]\phi</math>

where <math>j\in AGTS</math>.

The language '''<math>{\mathcal{L}_{PAL}}</math>''' is interpreted over epistemic models. The [[truth conditions]] for the connectives of the epistemic language are the same as in epistemic logic (see above). The truth condition for the new dynamic action modality <math>[\psi!]\phi</math> is defined as follows:
{|
|<math>\mathcal{M},w\models [\psi!]\phi</math>
|iff
|<math> \mbox{if } \mathcal{M},w\models\psi\mbox{ then } \mathcal{M}^\psi,w\models\phi</math>
|}
where <math>\mathcal{M}^\psi:=(W^\psi,R_1^\psi,\ldots, R_n^\psi,I^\psi)</math> with

<math>W^\psi:=\{w\in W; \mathcal{M},w\models\psi\}</math>,

<math>R_j^\psi:=R_j\cap (W^\psi\times W^\psi)</math> for all <math>j\in\{1,\ldots,n\}</math> and

<math>I^\psi(w):=I(w)\textrm{~for~all~} w\in W^{\psi}</math>.

The formula <math>[\psi!]\phi</math> intuitively means that after a truthful announcement of <math>\psi</math>, <math>\phi</math> holds. A public announcement of a proposition <math>\psi</math> changes the current epistemic model like in the figure below.[[File:WikiDEL5b.png|centre|Eliminate all worlds which currently do not satisfy <math>\psi</math>|frame]]

The proof system <math>\mathcal{H}_{PAL}</math> defined below is sound and strongly complete for <math>{\mathcal{L}_{PAL}}</math> w.r.t. the class of all pointed epistemic models.

{|
|<math>\textsf{K}</math>
|
|The Axioms and the rules of inference of the proof system <math>\textsf{K}</math>(see above)
|-
|'''Red 1'''
|
|<math>[\psi!] p\leftrightarrow (\psi \rightarrow  p)</math>
|-
|'''Red 2'''
|
|<math>[\psi!]\neg \phi \leftrightarrow (\psi \rightarrow  \neg [\psi!]\phi)</math>
|-
|'''Red 3'''
|
|<math>[\psi!](\phi \land \chi) \leftrightarrow ([\psi!]\phi \land [\psi!]\chi)</math>
|-
|'''Red 4'''
|
|<math>[\psi!] K_i\phi \leftrightarrow \left(\psi \rightarrow  K_i (\psi\rightarrow  [\psi!]\phi)\right)</math>
|}

The axioms Red 1 - Red 4 are called ''reduction axioms'' because they allow to reduce any formula of '''<math>{\mathcal{L}_{PAL}}</math>''' to a provably equivalent formula of <math>\mathcal{L}_{EL}</math> in <math>\mathcal{H}_{PAL}</math>. The formula <math>[q!]K q</math> is a [[theorem]] provable in <math>\mathcal{H}_{PAL}</math>. It states that after a public announcement of <math>q</math>, the agent knows that <math>q</math> holds.

PAL is [[Decidable problem|decidable]], its [[Model checking|model checking problem]] is solvable in [[polynomial time]] and its [[satisfiability problem]] is [[PSPACE-complete]].<ref>{{Cite book|publisher = ACM|date = 2006-01-01|location = New York, NY, USA|isbn = 978-1-59593-303-4|pages = 137–143|series = AAMAS '06|doi = 10.1145/1160633.1160657|first = Carsten|last = Lutz| title=Proceedings of the fifth international joint conference on Autonomous agents and multiagent systems | chapter=Complexity and succinctness of public announcement logic | s2cid=1083518 | url=https://tud.qucosa.de/api/qucosa%3A79335/attachment/ATT-0/ }}</ref>

'''Muddy children puzzle formalized with PAL:'''

Here are some of the statements that hold in the muddy children puzzle formalized in PAL.

<math>\mathcal{N},s\models p\land q</math>

'In the initial situation, A is dirty and B is dirty'.

<math>\mathcal{N},s\models(\neg K_Ap\land \neg K_A\neg p)\land (\neg K_B q \land\neg K_B\neg q)</math>

'In the initial situation, A does not know whether he is dirty and B neither'.

<math>\mathcal{N},s\models[p\vee q!](K_A(p\vee q)\land K_B(p\vee q))</math>

'After the public announcement that at least one of the children A and B is dirty, both of them know that at least one of them is dirty'. However:

<math>\mathcal{N},s\models[p\vee q!]((\neg K_Ap\land \neg K_A\neg p)\land (\neg K_B q \land\neg K_B\neg q))</math>

'After the public announcement that at least one of the children A and B is dirty, they still do not know that they are dirty'. Moreover:

<math>\mathcal{N},s\models[p\vee q!][(\neg K_Ap\land \neg K_A\neg p)\land (\neg K_B q \land\neg K_B\neg q)!](K_A p\land K_B q)</math>

'After the successive public announcements that at least one of the children A and B is dirty and that they still do not know whether they are dirty, A and B then both know that they are dirty'.

In this last statement, we see at work an interesting feature of the update process: a formula is not necessarily true after being announced. That is what we technically call “self-persistence” and this problem arises for epistemic formulas (unlike propositional formulas). One must not confuse the announcement and the update induced by this announcement, which might cancel some of the information encoded in the announcement.<ref>{{Cite journal|title = The Secret of My Success|journal = Synthese|date = 2006-07-01|issn = 0039-7857|pages = 201–232|volume = 151|issue = 2|doi = 10.1007/s11229-005-3384-9|first1 = Hans Van|last1 = Ditmarsch|first2 = Barteld|last2 = Kooi| s2cid=39421146 }}</ref>

=== Arbitrary Events ===

In this section, we assume that events are not necessarily public and we focus on items 2 and 3 above, namely on how to represent events and on how to update an epistemic model with such a representation of events by means of a product update.

==== Event Model ====

Epistemic models are used to model how agents perceive the actual world. Their perception can also be described in terms of knowledge and beliefs about the world and about the other agents’ beliefs. The insight of the DEL approach is that one can describe how an event is perceived by the agents in a very similar way. Indeed, the agents’ perception of an event can also be described in terms of knowledge and beliefs. For example, the private announcement of <math>A</math> to <math>B</math> that her card is red can also be described in terms of knowledge and beliefs: while <math>A</math> tells <math>B</math> that her card is red (event <math>e</math>) <math>C</math> ''believes'' that nothing happens (event <math>f</math>). This leads to define the notion of event model whose definition is very similar to that of an epistemic model.

A pointed event model <math>(\mathcal{E},e)</math> represents how the actual event represented by <math>e</math> is perceived by the agents. Intuitively, <math>f\in R_j(e)</math> means that while the possible event represented by <math>e</math> is occurring, agent <math>j</math> considers possible that the possible event represented by <math>f</math> is actually occurring.

An '''event model''' is a tuple <math>\mathcal{E}=(W^\alpha,R_1^{\alpha},\ldots,R_m^{\alpha},I^{\alpha})</math> where:

* <math>W^\alpha</math> is a non-empty set of ''possible events'',
* <math>R_j^{\alpha}\subseteq W^\alpha\times W^\alpha</math> is a binary relation called an ''accessibility relation'' on <math>W^\alpha</math>, for each <math>j\in AGTS</math>,
* <math>I^{\alpha}:W^{\alpha}\rightarrow  \mathcal{L}_{\textsf{EL}}</math> is a function called the ''precondition function'' assigning to each possible event a formula of <math>\mathcal{L}_{\textsf{EL}}</math>.

<math>R_j^{\alpha}(e)</math> denotes the set <math>\{f\in W^{\alpha};  (e,f)\in R_j^{\alpha} \}</math> .We write <math>e\in \mathcal{E}</math> for <math>e\in W^\alpha</math>, and <math>(\mathcal{E},e)</math> is called a '''pointed event model''' (<math>e</math> often represents the actual event).

'''Card Example:'''

Let us resume the card example and assume that players <math>A</math> and <math>B</math> show their card to each other. As it turns out, <math>C</math> noticed that <math>A</math> showed her card to <math>B</math> but did not notice that <math>B</math> did so to <math>A</math>. Players <math>A</math> and <math>B</math> know this. This event is represented below in the event model <math>(\mathcal{E},e)</math>.

The possible event <math>e</math> corresponds to the actual event ‘players <math>A</math> and <math>B</math> show their and cards respectively to each other’ (with precondition <math>{\color{red}{A}}\land {\color{green}{B}}</math>), <math>f</math> stands for the event ‘player <math>A</math> shows her green card’ (with precondition <math>{\color{green}{A}}</math>) and <math>g</math> stands for the atomic event ‘player <math>A</math> shows her red card’ (with precondition <math>{\color{red}{A}}</math>). Players <math>A</math> and <math>B</math> show their cards to each other, players <math>A</math> and <math>B</math> know this and consider it possible, while player <math>C</math> considers possible that player <math>A</math> shows her red card and also considers possible that player <math>A</math> shows her green card, since he does not know her card. In fact, that is all that player <math>C</math> considers possible because she did not notice that <math>B
</math> showed her card.

[[File:WikiDEL6b.png|centre|frame|Pointed event model <math>(\mathcal{E},e)</math>: Players A and B show their cards to each other in front of player C]]

Another example of event model is given below. This second example corresponds to the event whereby Player <math>A</math> shows her red card publicly to everybody. Player <math>A</math> shows her red card, players <math>A</math>, <math>B</math> and <math>C</math> ‘know’ it, players <math>A</math>, <math>B</math> and <math>C</math> ‘know’ that each of them ‘knows’ it, ''etc.'' In other words, there is ''common knowledge'' among players <math>A</math>, <math>B</math> and <math>C</math> that player <math>A</math> shows her red card.

[[File:WikiDEL7b.png|centre|frame|Pointed event model <math>(\mathcal{F},e)</math>]]

==== Product Update ====

The DEL product update is defined below.<ref name=":0">{{Cite journal|title = The Logic of Public Announcements and Common Knowledge and Private Suspicions|author1=Alexandru Baltag |author2=Lawrence S. Moss |author3=Slawomir Solecki |date = 1998|journal = Theoretical Aspects of Rationality and Knowledge (TARK)}}</ref> This update yields a new pointed epistemic model <math>(\mathcal{M},w)\otimes (\mathcal{E},e)</math> representing how the new situation which was previously represented by <math>(\mathcal{M},w)</math> is perceived by the agents after the occurrence of the event represented by <math>(\mathcal{E},e)</math>.

Let <math>\mathcal{M}=(W,R_1,\ldots,R_n,I)</math> be an epistemic model and let <math>\mathcal{E}=(W^{\alpha},R_1^{\alpha},\ldots,R_n^{\alpha},I^{\alpha})</math> be an event model. The '''product update''' of <math>\mathcal{M}</math> and <math>\mathcal{E}</math> is the epistemic model <math>\mathcal{M}\otimes\mathcal \mathcal{E}=(W^\otimes,R^\otimes_1,\ldots,R^{\otimes}_n,I^\otimes)</math> defined as follows: for all <math>v\in W</math> and all <math>f\in W^\alpha</math>,
{|
|<math>W^\otimes</math>
|=
|<math>\{(v,f)\in W\times W^\alpha; \mathcal{M},v\models I^{\alpha}(f)\}</math>
|-
|<math>R_j^\otimes(v,f)</math>
|=
|<math>\{(u,g)\in W^\otimes; u\in R_j(v)\textrm{~and~}g\in R^{\alpha}_j(f)\}</math>
|-
|<math>I^\otimes(v,f)</math>
|=
|<math>I(v)</math>
|}
If <math>w\in W</math> and <math>e\in W^{\alpha}</math> are such that <math>\mathcal{M},w\models I^{\alpha}(e)</math> then <math>(\mathcal{M},w)\otimes(\mathcal{E},e)</math> denotes the pointed epistemic model <math>(\mathcal{M}\otimes\mathcal{E},(w,e))</math>. This definition of the product update is conceptually grounded.<ref name=":1" />

'''Card Example:'''

As a result of the first event described above (Players <math>A</math> and <math>B</math> show their cards to each other in front of player <math>C</math>), the agents update their beliefs. We get the situation represented in the pointed epistemic model <math>(\mathcal{M},w)\otimes(\mathcal{E},e)</math> below. In this pointed epistemic model, the following statement holds: <math>(\mathcal{M},w)\otimes(\mathcal{E},e)\models ({\color{green}{B}}\land K_{A} {\color{green}{B}}) \land K_{C}\neg K_{A} {\color{green}{B}}.</math> It states that player <math>A</math> knows that player <math>B</math> has the card but player <math>C</math> 'believes' that it is not the case.

[[File:WikiDEL8b.png|centre|frame|Updated pointed epistemic model <math>(\mathcal{M},w)\otimes(\mathcal{E},e)</math>]]The result of the second event is represented below. In this pointed epistemic model, the following statement holds: <math>(\mathcal{M},w)\otimes(\mathcal{F},e)\models C_{\{B,C\}}({\color{red}{A}}\land{\color{green}{B}}\land{\color{blue}{C}})\land  \neg K_A({\color{green}{B}}\land{\color{blue}{C}})</math>. It states that there is common knowledge among <math>B</math> and <math>C</math> that they know the true state of the world (namely <math>A</math> has the red card, <math>B</math> has the green card and <math>C</math> has the blue card), but <math>A</math> does not know it.

[[File:WikiDEL9b.png|centre|frame|Updated pointed epistemic model <math>(\mathcal{M},w)\otimes(\mathcal{F},e)</math>]]

Based on these three components (epistemic model, event model and product update), Baltag, Moss and Solecki defined a general logical language inspired from the logical language of [[propositional dynamic logic]]<ref name=":2" /> to reason about information and knowledge change.<ref name=":0" /><ref name=":1" />

==See also==
{{Portal|Philosophy}}
* [[Epistemic logic]]
* [[Epistemology]]
* [[Logic in computer science]]
* [[Modal logic]]

==Notes==
{{reflist}}

==References==
*{{cite book |first1 = Johan|last1 = van Benthem|title = Logical Dynamics of Information and Interaction|publisher = Cambridge University Press|year = 2011|isbn = 978-0521873970}}
*{{cite book |first1 = van Ditmarsch|last1 = Hans|first2 = Joseph|last2 = Halpern|first3 = Wiebe|last3 = van der Hoek|first4 = Barteld|last4 = Kooi|title = Handbook of Epistemic Logic|location = London|publisher = College publication|year = 2015|isbn = 978-1848901582}}
*{{cite book |last1 = van Ditmarsch, Hans, van der Hoek, Wiebe, and Kooi, Barteld|title = Dynamic Epistemic Logic|location = Ithaca|publisher = volume 337 of Synthese library. Springer.|year = 2007|isbn = 978-1-4020-5839-4}}
* {{cite book |first1 = Ronald|last1 = Fagin|first2 = Joseph|last2 = Halpern|first3 = Yoram|last3 = Moses|first4 = Moshe|last4 = Vardi|title = Reasoning about Knowledge|location = Cambridge|publisher = [[MIT Press]]|year = 2003|isbn = 978-0-262-56200-3}} A classic reference.
* {{cite book |first1 = Jaakko|last1 = Hintikka|title = Knowledge and Belief - An Introduction to the Logic of the Two Notions|url = https://archive.org/details/knowledgebeliefi00hint_0|url-access = registration|location = Ithaca|publisher = [[Cornell University Press]]|year = 1962|isbn = 978-1-904987-08-6}}.

==External links==
* {{cite SEP |url-id=dynamic-epistemic |title=Dynamic Epistemic Logic |last=Baltag|first=Alexandru|last2=Renne|first2=Bryan}}
* {{cite IEP |url-id=de-logic |title=Dynamic Epistemic Logic|last=van Ditmarsch|first=Hans|last2=van der Hoek|first2=Wiebe|last3=Kooi|first3=Barteld}}
*{{cite SEP |url-id=logic-epistemic |title=Epistemic Logic |last=Hendricks|first=Vincent|last2=Symons|first2=John}}
*{{cite SEP |url-id=logic-modal |title=Modal logic |last=Garson |first=James}}
{{Non-classical logic}}

[[Category:Artificial intelligence]]
[[Category:Epistemic logic]]
[[Category:Belief revision]]