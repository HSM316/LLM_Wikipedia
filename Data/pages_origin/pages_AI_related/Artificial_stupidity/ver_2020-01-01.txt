{{original research|date=December 2010}}

'''Artificial Stupidity''' is commonly used as a humorous opposite of the term [[artificial intelligence]] (AI), often as a [[derogatory]] reference to the inability of an AI program to adequately perform basic tasks.{{citation needed|date=December 2010}} However, within the field of [[computer science]], ''artificial stupidity'' is also used to refer to a technique of "[[dumbing down]]" [[computer programs]] in order to deliberately introduce errors in their responses.

== History ==

[[Alan Turing]], in his 1952 paper ''[[Computing Machinery and Intelligence]]'', proposed a test for intelligence which has since become known as the [[Turing test]].<ref name="turing">{{Turing 1950}}</ref> While there are a number of different versions, the original test, described by Turing as being based on the "[[Imitation Game (Turing test)|Imitation Game]]", involved a "machine intelligence" (a computer running an AI program), a female participant, and an interrogator. Both the AI and the female participant were to claim that they were female, and the interrogator's task was to work out which was the female participant and which was not by examining the participant's responses to typed questions.<ref name="turing" /> While it is not clear whether or not Turing intended that the interrogator was to know that one of the participants was a computer, while discussing some of the possible objections to his argument Turing raised the concern that "machines cannot make mistakes".<ref name="turing" />

{{quote|It is claimed that the interrogator could distinguish the machine from the man simply by setting them a number of problems in arithmetic. The machine would be unmasked because of its deadly accuracy.|Turing, 1950|page 448}}

As Turing then noted, the reply to this is a simple one: the machine should ''not'' attempt to "give the ''right'' answers to the arithmetic problems".<ref name="turing" /> Instead, deliberate errors should be introduced to the computer's responses.

== Applications ==

Within computer science, there are at least two major applications for artificial stupidity: the generation of deliberate errors in [[chatbots]] attempting to pass the Turing test or to otherwise fool a participant into believing that they are human; and the deliberate limitation of computer AIs in [[video games]] in order to control the game's difficulty.

=== Chatbots ===

The first [[Loebner prize]] competition was run in 1991. As reported in ''[[The Economist]]'', the winning entry incorporated deliberate errors&nbsp;– described by ''The Economist'' as "artificial stupidity"&nbsp;– to fool the judges into believing that it was human.<ref name="economist">{{Citation | title = Artificial Stupidity | date = 1992-09-01 | journal = [[The Economist]] | volume = 324 | issue = 7770 | pages = 14 |url= http://archive.salon.com/tech/feature/2003/02/26/loebner_part_one/ |quote= the first event was held in 1991}}</ref> This technique has remained a part of the subsequent Loebner prize competitions, and reflects the issue first raised by Turing.

=== Game design ===

Lars Lidén argues that good game design involves finding a balance between the computer's "intelligence" and the player's ability to win. By finely tuning the level of "artificial stupidity", it is possible to create computer controlled plays that allow the player to win, but do so "without looking unintelligent".<ref name="liden">{{citation | last = Lidén | first = Lars | year = 2004 | title = Artificial Stupidity: The art of making intentional mistakes | editor = S. Rabin | work = AI Game Programming Wisdom 2 | pages = 41–48 | publisher = Charles River Media, Inc.}}</ref>

''Algorithms''

There are many ways to deliberately introduce poor decision-making in search algorithms. Take the [[minimax]] algorithm for example. The [[minimax]] algorithm is an adversarial search algorithm that is popularly used in games that require more than one player to compete against each other. The main purpose in this algorithm is to choose a move that maximizes your chance of winning and avoid moves that maximizes the chance of your opponent winning. An algorithm like this would be extremely beneficial to the computer as computers are able to search thousands of moves ahead. To "dumb down" this algorithm to allow for different difficulty levels, [[heuristic]] functions have to be tweaked. Normally, huge points are given in winning states. Tweaking the [[heuristic]] by reducing such big payoffs would reduce the chance of the algorithm in choosing the winning state.

Creating [[heuristic]] functions to allow for stupidity is more difficult than one might think. If a [[heuristic]] allows for the best move, the computer opponent would be too omniscient, making the game frustrating and unenjoyable. But if the [[heuristic]] is poor, the game might also be unenjoyable. Therefore, a balance of good moves and bad moves in an adversarial game relies on a well-implemented [[heuristic]] function.

=== Other applications ===
According to its definition, a sufficiently developed Artificial Stupidity program would be able to make all the worst cases regarding a given situation. This would enable computer programmers and analysts to find flaws immediately while minimizing errors that are within the code.

However, it is mostly expected to be used within the development and debugging stages of computer software.

=== Arguments on artificial stupidity ===

The Economist states that if we are to achieve Alan Turing's prediction, "it will be a dreadful anticlimax." It is a much pointless attempt to create a machine that mimics the behaviour and intelligent level of a human being. The purpose of the invention of the computer is to assist humans in performing tasks that would be deemed too tedious or time consuming to perform by hand.<ref name="economist"/>

As mentioned in the passage regarding the Loebnizer prize competition, the computer was able to trick judges by introducing deliberate typing errors. The Economist argues that nobody would want a computer that couldn't type properly.<ref name="economist"/>

Durham, T., an author of the journal "On Artificial Stupidity," seems to view computers as naturally possessing intelligence. It is only due to bad programming that a computer appears unintelligent. Durham states the opposite in what people would normally believe as "there is no such thing as AI, only artificial stupidity, which is what happens when computers are not given the knowledge they need."<ref>Durham, T. (21 March 1985), "On Artificial Stupidity", ''Computing, The Magazine'' pp: 4-5</ref>

=== Artificial stupidity as a limitation of artificial intelligence ===

Artificial stupidity is not just delivering deliberate errors into the computer, but it could also be seen as a limitation of computer artificial intelligence. Dr. Jay Liebowitz argues that "if intelligence and stupidity naturally exist, and if AI is said to exist, then is there something that might be called "artificial stupidity?""<ref>{{cite journal|last=Liebowitz|first=Jay|title=If There is Artificial Intelligence, Is There Such Thing As Artificial Stupidity?|journal=SIGART Newsletter|date=July 1989|volume=109}}</ref>

Liebowitz pointed out that the limitations are:

{{quote|
* Ability to possess and use common sense
* Development of deep reasoning systems
* Ability to vary an expert system's explanation capability
* Ability to get expert systems to learn
* Ability to have distributed expert systems
* Ability to easily acquire and update knowledge|Liebowitz, 1989|Page 109}}

== References ==

{{reflist}}

== Further reading ==
*[http://www.c2.com/cgi/wiki?ArtificialStupidity http://www.c2.com/cgi/wiki?ArtificialStupidity] Describes Artificial Stupidity in the humorous context
* TEDx: "The Turing Test, Artificial Intelligence and the Human Stupidity" [https://www.youtube.com/watch?v=O7KrwO3pVZ8]

[[Category:Philosophy of artificial intelligence]]