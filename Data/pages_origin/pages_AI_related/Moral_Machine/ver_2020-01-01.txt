'''Moral Machine''' is an online platform, developed by [[Iyad Rahwan]]'s Scalable Cooperation group at the [[Massachusetts Institute of Technology]], that generates [[Ethical dilemma|moral dilemmas]] and collects information on the decisions that people make between two destructive outcomes.<ref>{{Cite news|url=http://www.nbcnews.com/tech/innovation/driverless-cars-moral-dilemma-who-lives-who-dies-n708276|title=Driverless cars face a moral dilemma: Who lives and who dies?|newspaper=NBC News|access-date=2017-02-16|language=en}}</ref><ref>{{Cite news|url=http://www.slate.com/blogs/future_tense/2016/08/11/moral_machine_from_mit_poses_self_driving_car_thought_experiments.html|title=Should a Self-Driving Car Kill Two Jaywalkers or One Law-Abiding Citizen?|last=Brogan|first=Jacob|date=2016-08-11|newspaper=Slate|access-date=2017-02-16|language=en-US|issn=1091-2339}}</ref> The platform is the brain child of Iyad Rahwan and social psychologists Azim Shariff and Jean-François Bonnefon,<ref>{{Cite web|url=https://socialsciences.nature.com/users/182414-edmond-awad/posts/40067-inside-the-moral-machine|title=Inside the Moral Machine|last=Awad|first=Edmond|date=2018-10-24|website=Behavioural and Social Sciences at Nature Research|language=en|archive-url=|archive-date=|access-date=2019-07-04}}</ref> who conceived of the idea ahead of the publication of their article about the ethics of self-driving cars.<ref>{{Cite journal|last=Bonnefon|first=Jean-François|last2=Shariff|first2=Azim|last3=Rahwan|first3=Iyad|date=2016-06-24|title=The social dilemma of autonomous vehicles|journal=Science|language=en|volume=352|issue=6293|pages=1573–1576|doi=10.1126/science.aaf2654|issn=0036-8075|pmid=27339987|arxiv=1510.03346}}</ref>

The presented scenarios are often variations of the [[trolley problem]], and the information collected would be used for further research regarding the decisions that [[Artificial intelligence|machine intelligence]] must make in the future.<ref>{{Cite web|url=https://www.media.mit.edu/research/groups/10005/moral-machine|title=Moral Machine {{!}} MIT Media Lab|website=www.media.mit.edu|language=en|access-date=2017-02-16}}</ref><ref>{{Cite news|url=http://learningenglish.voanews.com/a/mit-moral-machine/3556873.html|title=MIT Seeks 'Moral' to the Story of Self-Driving Cars|newspaper=VOA|access-date=2017-02-16|language=en}}</ref><ref>{{Cite web|url=http://moralmachine.mit.edu/|title=Moral Machine|website=Moral Machine|access-date=2017-02-16}}</ref><ref>{{Cite news|url=https://thenextweb.com/cars/2017/01/16/mits-moral-machine-wants-you-to-decide-who-dies-in-self-driving-car-accidents/|title=MIT's 'Moral Machine' wants you to decide who dies in a self-driving car accident|last=Clark|first=Bryan|date=2017-01-16|newspaper=The Next Web|access-date=2017-02-16|language=en-US}}</ref><ref>{{Cite news|url=http://www.popsci.com/mit-game-asks-who-driverless-cars-should-kill|title=MIT Game Asks Who Driverless Cars Should Kill|newspaper=Popular Science|access-date=2017-02-16|language=en}}</ref><ref>{{Cite web|url=https://techcrunch.com/2016/10/04/did-you-save-the-cat-or-the-kid/|title=Play this killer self-driving car ethics game|last=Constine|first=Josh|website=TechCrunch|access-date=2017-02-16}}</ref> For example, as artificial intelligence plays an increasingly significant role in [[autonomous driving]] technology, research projects like Moral Machine help to find solutions for challenging life-and-death decisions that will face self-driving vehicles.<ref>{{Cite web|url=http://fortune.com/2017/07/22/driverless-cars-autonomous-vehicles-self-driving-uber-google-tesla/|title=What's Taking So Long for Driverless Cars to Go Mainstream?|last=Chopra|first=Ajay|website=Fortune|access-date=2017-08-01}}</ref>

Analysis of the data collected through Moral Machine showed broad differences in relative preferences among different countries, and correlations between these preferences and various national metrics.<ref name="Awad2018">{{cite journal |last1=Awad |first1=Edmond |last2=Dsouza |first2=Sohan |last3=Kim |first3=Richard |last4=Schulz |first4=Jonathan |last5=Henrich |first5=Joseph |last6=Shariff |first6=Azim |last7=Bonnefon |first7=Jean-François |last8=Rahwan |first8=Iyad |title=The Moral Machine experiment |journal=Nature |date=24 October 2018 |volume=563 |issue=7729 |pages=59–64 |doi=10.1038/s41586-018-0637-6 |pmid=30356211 |hdl=10871/39187 }}</ref>

==References==
{{reflist}}

==External links==
*{{official|http://moralmachine.mit.edu}}

[[Category:Ethics]]
[[Category:Dilemmas]]
[[Category:Thought experiments in ethics]]
[[Category:Artificial intelligence]]
[[Category:Unsolved problems in computer science]]
[[Category:Massachusetts Institute of Technology]]
[[Category:MIT Media Lab]]