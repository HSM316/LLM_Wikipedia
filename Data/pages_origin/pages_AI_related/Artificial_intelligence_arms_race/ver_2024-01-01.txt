{{short description|Arms race for the most advanced AI-related technologies}}
A military '''artificial intelligence arms race''' is an [[arms race]] between two or more states to develop and deploy [[lethal autonomous weapon]]s systems (LAWS). Since the mid-2010s, many analysts have noted the emergence of such an arms race between global superpowers for better military AI,<ref name="Geist 318–321">{{Cite journal |last=Geist |first=Edward Moore |date=2016-08-15 |title=It's already too late to stop the AI arms race—We must manage it instead |journal=Bulletin of the Atomic Scientists |volume=72 |issue=5 |pages=318–321 |bibcode=2016BuAtS..72e.318G |doi=10.1080/00963402.2016.1216672 |issn=0096-3402 |s2cid=151967826}}</ref><ref name="Maas 285–311">{{Cite journal |last=Maas |first=Matthijs M. |date=2019-02-06 |title=How viable is international arms control for military artificial intelligence? Three lessons from nuclear weapons |journal=Contemporary Security Policy |volume=40 |issue=3 |pages=285–311 |doi=10.1080/13523260.2019.1576464 |issn=1352-3260 |s2cid=159310223}}</ref> driven by [[Second Cold War|increasing geopolitical and military tensions]]. An AI arms race is sometimes placed in the context of an [[AI Cold War]] between the US and China.<ref>{{cite news |last=Champion |first=Marc |date=12 December 2019|title= Digital Cold War |url=https://www.bloomberg.com/quicktake/how-u-s-china-tech-rivalry-looks-like-a-digital-cold-war|work= Bloomberg|access-date=3 July 2021}}</ref>

== Terminology ==
[[Lethal autonomous weapon]]s systems use artificial intelligence to identify and kill human targets without human intervention.<ref>{{Cite web |date=2021-10-20 |title=Homepage |url=https://autonomousweapons.org/ |access-date=2022-02-17 |website=Lethal Autonomous Weapons |language=en-US}}</ref> LAWS have colloquially been called "[[slaughterbots]]" or "killer robots". Broadly, any competition for superior AI is sometimes framed as an "arms race".<ref>{{Cite journal|last=Roff|first=Heather M.|date=2019-04-26|title=The frame problem: The AI "arms race" isn't one|journal=Bulletin of the Atomic Scientists|volume=75|issue=3|pages=95–98|doi=10.1080/00963402.2019.1604836|bibcode=2019BuAtS..75c..95R|s2cid=150835614|issn=0096-3402}}</ref><ref>{{cite news |title=For Google, a leg up in the artificial intelligence arms race |url=https://fortune.com/2014/02/05/for-google-a-leg-up-in-the-artificial-intelligence-arms-race/ |access-date=11 April 2020 |work=Fortune |date=2014 |language=en}}</ref> Advantages in military AI overlap with advantages in other sectors, as countries pursue both economic and military advantages.<ref name="Understanding China's AI Strategy" />

== History ==
In 2014, AI specialist [[Steve Omohundro]] warned that "An autonomous weapons arms race is already taking place".<ref>{{cite news|last1=Markoff|first1=John|title=Fearing Bombs That Can Pick Whom to Kill|url=https://www.nytimes.com/2014/11/12/science/weapons-directed-by-robots-not-humans-raise-ethical-questions.html|access-date=11 January 2018|work=The New York Times|date=11 November 2014}}</ref> According to [[Siemens]], worldwide military spending on robotics was US$5.1 billion in 2010 and US$7.5 billion in 2015.<ref>{{cite news|title=Getting to grips with military robotics|url=https://www.economist.com/news/special-report/21735478-autonomous-robots-and-swarms-will-change-nature-warfare-getting-grips|access-date=7 February 2018|newspaper=The Economist|date=25 January 2018|language=en}}</ref><ref>{{cite web|title=Autonomous Systems: Infographic|url=https://www.siemens.com/innovation/en/home/pictures-of-the-future/digitalization-and-software/autonomous-systems-infographic.html|website=www.siemens.com|access-date=7 February 2018|language=en|archive-date=7 February 2018|archive-url=https://web.archive.org/web/20180207122319/https://www.siemens.com/innovation/en/home/pictures-of-the-future/digitalization-and-software/autonomous-systems-infographic.html}}</ref>

China became a top player in artificial intelligence research in the 2010s. According to the ''[[Financial Times]]'', in 2016, for the first time, China published more AI papers than the entire European Union. When restricted to number of AI papers in the top 5% of cited papers, China overtook the United States in 2016 but lagged behind the European Union.<ref name="financial times"/> 23% of the researchers presenting at the 2017 [[American Association for the Advancement of Artificial Intelligence]] (AAAI) conference were Chinese.<ref name=qz>{{cite news|last1=Kopf|first1=Dan|title=China is rapidly closing the US's lead in AI research|url=https://qz.com/1197174/china-is-the-rising-artificial-intelligence-power/|access-date=7 February 2018|work=Quartz|date=2018}}</ref> [[Eric Schmidt]], the former chairman of [[Alphabet (company)|Alphabet]], has predicted China will be the leading country in AI by 2025.<ref>{{cite news|title=The battle for digital supremacy|url=https://www.economist.com/news/leaders/21738883-americas-technological-hegemony-under-threat-china-battle-digital-supremacy|access-date=19 March 2018|newspaper=The Economist|date=2018|language=en}}</ref>

{| class="wikitable"
|+ style="text-align: left;" | AAAI presenters:<ref name=qz/>
|-
! scope="col" | Country !! scope="col" | in 2012 !! scope="col" | in 2017
|-
! scope="row" | US
| 41% || 34%
|-
! scope="row" | China
| 10% || 23%
|-
! scope="row" | UK
| 5% || 5%
|}

== Risks ==
One risk concerns the AI race itself, whether or not the race is won by any one group. There are strong incentives for development teams to cut corners with regard to the safety of the system, which may result in increased [[algorithmic bias]].<ref name=":22">{{Cite journal |last1=Armstrong |first1=Stuart |last2=Bostrom |first2=Nick |last3=Shulman |first3=Carl |date=2015-08-01 |title=Racing to the precipice: a model of artificial intelligence development |journal=AI & Society |volume=31 |issue=2 |pages=201–206 |doi=10.1007/s00146-015-0590-y |issn=0951-5666 |s2cid=16199902}}</ref><ref name=":42">{{cite news |last1=Scharre |first1=Paul |date=18 February 2020 |title=Killer Apps: The Real Dangers of an AI Arms Race |url=https://www.foreignaffairs.com/articles/2019-04-16/killer-apps |access-date=15 March 2020}}</ref> This is in part due to the perceived advantage of being the first to develop advanced AI technology. One team appearing to be on the brink of a breakthrough can encourage other teams to take shortcuts, ignore precautions and deploy a system that is less ready. Some argue that using "race" terminology at all in this context can exacerbate this effect.<ref name=":14">{{Cite book |last1=Cave |first1=Stephen |last2=ÓhÉigeartaigh |first2=Seán S. |title=Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society |chapter=An AI Race for Strategic Advantage |date=2018 |location=New York, New York, USA |publisher=ACM Press |page=2 |doi=10.1145/3278721.3278780 |isbn=978-1-4503-6012-8 |doi-access=free}}</ref>

Another potential danger of an AI arms race is the possibility of losing control of the AI systems; the risk is compounded in the case of a race to artificial general intelligence, which may present an [[Existential risk from artificial general intelligence|existential risk]].<ref name=":14"/>

A third risk of an AI arms race is whether or not the race is actually won by one group. The concern is regarding the consolidation of power and technological advantage in the hands of one group.<ref name=":14"/> A US government report argued that "AI-enabled capabilities could be used to threaten  critical infrastructure, amplify disinformation campaigns, and wage war"<ref name=":0">{{Cite book |url=https://drive.google.com/file/d/153OrxnuGEjsUvlxWsFYauslwNeCEkvUb/view |title=Interim Report |publisher=National Security Commission on Artificial Intelligence |year=2019 |location=Washington, DC}}</ref><sup>:1</sup>, and that "global stability and nuclear deterrence could be undermined".<ref name=":0" /><sup>:11</sup>

== Stances toward military artificial intelligence ==
<!-- This section could be improved by sorting its subsections alphabetically or geographically-->

=== Russia ===
[[File:Russia_President_Vladimir_Putin_at_National_Knowledge_Day,_2017.jpg|thumb|alt=A cartoon centipede reads books and types on a laptop.|Putin (seated, center) at National Knowledge Day, 2017]]
Russian General [[Viktor Bondarev]], commander-in-chief of the Russian air force, stated that as early as February 2017, Russia was working on AI-guided missiles that could decide to switch targets mid-flight.<ref>{{cite news|title=Russia is building a missile that can makes its own decisions|url=http://www.newsweek.com/russia-military-challenge-us-china-missile-own-decisions-639926|access-date=24 December 2017|work=Newsweek|date=20 July 2017|language=en}}</ref> The [[Military-Industrial Commission of Russia]] has approved plans to derive 30 percent of Russia's combat power from remote controlled and AI-enabled robotic platforms by 2030.<ref>{{cite news |last1=Walters |first1=Greg |title=Artificial Intelligence Is Poised to Revolutionize Warfare |url=https://www.seeker.com/tech/artificial-intelligence/artificial-intelligence-is-poised-to-revolutionize-warfare |access-date=8 May 2022 |work=Seeker |date=7 September 2017 |language=en}}</ref> Reports by state-sponsored Russian media on potential military uses of AI increased in mid-2017.<ref>{{cite news|title=Why Elon Musk is right about the threat posed by Russian artificial intelligence|url=https://www.independent.co.uk/life-style/gadgets-and-tech/news/elon-musk-ai-artificial-intelligence-world-war-three-russia-china-robots-cyber-warfare-replicants-a7931981.html|access-date=24 December 2017|work=The Independent|date=6 September 2017}}</ref> In May 2017, the CEO of Russia's Kronstadt Group, a defense contractor, stated that "there already exist completely autonomous AI operation systems that provide the means for UAV clusters, when they fulfill missions autonomously, sharing tasks between them, and interact", and that it is inevitable that "swarms of drones" will one day fly over combat zones.<ref>{{cite news|title=Russia is developing autonomous "swarms of drones" it calls an inevitable part of future warfare|url=http://www.newsweek.com/drones-swarm-autonomous-russia-robots-609399|access-date=24 December 2017|work=Newsweek|date=15 May 2017|language=en}}</ref> Russia has been testing several autonomous and semi-autonomous combat systems, such as [[Kalashnikov Concern|Kalashnikov]]'s "neural net" combat module, with a machine gun, a camera, and an AI that its makers claim can make its own targeting judgements without human intervention.<ref name="bbc">{{cite news|last1=Smith|first1=Mark|title=Is 'killer robot' warfare closer than we think?|url=https://www.bbc.com/news/business-41035201|access-date=24 December 2017|work=BBC News|date=25 August 2017}}</ref>

In September 2017, during a National Knowledge Day address to over a million students in 16,000 Russian schools, Russian President [[Vladimir Putin]] stated "Artificial intelligence is the future, not only for Russia but for all humankind... Whoever becomes the leader in this sphere will become the ruler of the world". Putin also said it would be better to prevent any single actor achieving a monopoly, but that if Russia became the leader in AI, they would share their "technology with the rest of the world, like we are doing now with atomic and nuclear technology".<ref>{{cite news|title=Artificial Intelligence Fuels New Global Arms Race|url=https://www.wired.com/story/for-superpowers-artificial-intelligence-fuels-new-global-arms-race/|access-date=24 December 2017|magazine=WIRED}}</ref><ref>{{cite news|last1=Clifford|first1=Catherine|title=In the same way there was a nuclear arms race, there will be a race to build A.I., says tech exec|url=https://www.cnbc.com/2017/09/28/hootsuite-ceo-next-version-of-arms-race-will-be-a-race-to-build-ai.html|access-date=24 December 2017|work=CNBC|date=29 September 2017}}</ref><ref>{{cite news 
 |url= https://edition.cnn.com/2017/09/01/world/putin-artificial-intelligence-will-rule-world/index.html
 |title= Who Vladimir Putin thinks will rule the world
 |work= [[CNN]]
 |author= Radina Gigova
 |date = 2 September 2017
 |access-date= 22 March 2020
}}</ref>

Russia is establishing a number of organizations devoted to the development of military AI. In March 2018, the Russian government released a 10-point AI agenda, which calls for the establishment of an AI and Big Data consortium, a Fund for Analytical Algorithms and Programs, a state-backed AI training and education program, a dedicated AI lab, and a National Center for Artificial Intelligence, among other initiatives.<ref>{{Cite web|title=Here's How the Russian Military Is Organizing to Develop AI|url=https://www.defenseone.com/ideas/2018/07/russian-militarys-ai-development-roadmap/149900/|website=Defense One|date=20 July 2018 |access-date=2020-05-01}}</ref> In addition, Russia recently created a defense research organization, roughly equivalent to DARPA, dedicated to autonomy and robotics called the Foundation for Advanced Studies, and initiated an annual conference on "Robotization of the Armed Forces of the Russian Federation."<ref name=":2">{{Cite web|title=Red Robots Rising: Behind the Rapid Development of Russian Unmanned Military Systems|url=https://thestrategybridge.org/the-bridge/2017/12/12/red-robots-rising-behind-the-rapid-development-of-russian-unmanned-military-systems|website=The Strategy Bridge|date=12 December 2017 |language=en-US|access-date=2020-05-01}}</ref><ref name=":3">{{Cite book|publisher=Congressional Research Service|url=https://fas.org/sgp/crs/natsec/R45178.pdf|title=Artificial Intelligence and National Security|year=2019|location=Washington, DC}}{{PD-notice}}</ref>

The Russian military has been researching a number of AI applications, with a heavy emphasis on semiautonomous and autonomous vehicles. In an official statement on November 1, 2017, Viktor Bondarev, chairman of the Federation Council's Defense and Security Committee, stated that "artificial intelligence will be able to replace a soldier on the battlefield and a pilot in an aircraft cockpit" and later noted that "the day is nearing when vehicles will get artificial intelligence."<ref>{{Cite web|title=Should the U.S. Army Fear Russia's Killer Robots?|url=https://nationalinterest.org/blog/the-buzz/should-the-us-army-fear-russias-killer-robots-23098|last=Bendett|first=Samuel|date=2017-11-08|website=The National Interest|language=en|access-date=2020-05-01}}</ref> Bondarev made these remarks in close proximity to the successful test of Nerehta, an crewless Russian ground vehicle that reportedly "outperformed existing [crewed] combat vehicles." Russia plans to use Nerehta as a research and development platform for AI and may one day deploy the system in combat, intelligence gathering, or logistics roles.<ref>{{Cite web|title=Russia Says It Will Field a Robot Tank that Outperforms Humans|url=https://www.defenseone.com/technology/2017/11/russia-robot-tank-outperforms-humans/142376/|website=Defense One|date=8 November 2017 |access-date=2020-05-01}}</ref> Russia has also reportedly built a combat module for crewless ground vehicles that is capable of autonomous target identification—and, potentially, target engagement—and plans to develop a suite of AI-enabled autonomous systems.<ref>{{Cite web|title=Russia is developing AI missiles to dominate the new arms race|url=https://thenextweb.com/artificial-intelligence/2017/07/27/russia-is-developing-ai-missiles-to-dominate-the-new-arms-race/|last=Greene|first=Tristan|date=2017-07-27|website=The Next Web|language=en-us|access-date=2020-05-01}}</ref><ref>{{Cite web|title=Kalashnikov Will Make an A.I.-Powered Killer Robot|url=https://www.popularmechanics.com/military/weapons/news/a27393/kalashnikov-to-make-ai-directed-machine-guns/|last=Mizokami|first=Kyle|date=2017-07-19|website=Popular Mechanics|language=en-US|access-date=2020-05-01}}</ref><ref name=":3" />

In addition, the Russian military plans to incorporate AI into crewless aerial, naval, and undersea vehicles and is currently developing swarming capabilities.<ref name=":2" /> It is also exploring innovative uses of AI for remote sensing and electronic warfare, including adaptive frequency hopping, waveforms, and countermeasures.<ref>{{Cite web|title=Russia Tries to Get Smart about Artificial Intelligence|url=https://wilsonquarterly.com/quarterly/living-with-artificial-intelligence/russia-tries-to-get-smart-about-artificial-intelligence/|last1=Dougherty|first1=Jill|last2=Jay|first2=Molly|website=Wilson Quarterly}}</ref><ref>{{Cite web|title=Russian AI-Enabled Combat: Coming to a City Near You?|url=https://warontherocks.com/2019/07/russian-ai-enabled-combat-coming-to-a-city-near-you/|date=2019-07-31|website=War on the Rocks|language=en-US|access-date=2020-05-01}}</ref> Russia has also made extensive use of AI technologies for domestic propaganda and surveillance, as well as for information operations directed against the United States and U.S. allies.<ref>{{Cite web|title=Weapons of the weak: Russia and AI-driven asymmetric warfare|url=https://www.brookings.edu/research/weapons-of-the-weak-russia-and-ai-driven-asymmetric-warfare/|last=Polyakova|first=Alina|date=2018-11-15|website=Brookings|language=en-US|access-date=2020-05-01}}</ref><ref>{{Cite web|title=Disinformation Wars|url=https://foreignpolicy.com/2018/05/25/disinformation-wars/|last=Polyakova|first=Chris Meserole, Alina|website=Foreign Policy|date=25 May 2018 |language=en-US|access-date=2020-05-01}}</ref><ref name=":3" />

The Russian government has strongly rejected any ban on [[lethal autonomous weapon]] systems, suggesting that such an international ban could be ignored.<ref>{{cite news|title=Russia rejects potential UN 'killer robots' ban, official statement says|url=https://eandt.theiet.org/content/articles/2017/12/russia-rejects-potential-un-killer-robots-ban-official-statement-says/|access-date=12 January 2018|work=[[Institution of Engineering and Technology]]|date=1 December 2017}}</ref><ref>{{cite web|title=Examination of various dimensions of emerging technologies in the area of lethal autonomous weapons systems, Russian Federation, November 2017|url=https://admin.govexec.com/media/russia.pdf|access-date=12 January 2018}}</ref>

=== China ===
{{Further|Artificial intelligence industry in China}}
China is pursuing a strategic policy of [[military-civil fusion]] on AI for global [[technological supremacy]].<ref name=":0" /><ref>{{Cite web|url=https://www.uscc.gov/hearings/technology-trade-and-military-civil-fusion-chinas-pursuit-artificial-intelligence-new|title=Technology, Trade, and Military-Civil Fusion: China's Pursuit of Artificial Intelligence, New Materials, and New Energy {{!}} U.S.- CHINA {{!}} ECONOMIC and SECURITY REVIEW COMMISSION|website=www.uscc.gov|access-date=2020-04-04}}</ref> According to a February 2019 report by Gregory C. Allen of the [[Center for a New American Security]], [[China]]'s [[List of national leaders of the People's Republic of China|leadership]] – including [[paramount leader]] [[Xi Jinping]] – believes that being at the forefront in AI technology is critical to the future of global military and economic power competition.<ref name="Understanding China's AI Strategy">{{cite web |last1=Allen |first1=Gregory |title=Understanding China's AI Strategy |url=https://www.cnas.org/publications/reports/understanding-chinas-ai-strategy |website=Center for a New American Security |access-date=15 March 2019}}</ref> Chinese military officials have said that their goal is to incorporate commercial AI technology to "narrow the gap between the Chinese military and global advanced powers."<ref name="Understanding China's AI Strategy"/> The close ties between Silicon Valley and China, and the open nature of the American research community, has made the West's most advanced AI technology easily available to China; in addition, Chinese industry has numerous home-grown AI accomplishments of its own, such as [[Baidu]] passing a notable Chinese-language speech recognition capability benchmark in 2015.<ref name=nytimes>{{cite news|last1=Markoff|first1=John|last2=Rosenberg|first2=Matthew|title=China's Intelligent Weaponry Gets Smarter|url=https://www.nytimes.com/2017/02/03/technology/artificial-intelligence-china-united-states.html|access-date=24 December 2017|work=The New York Times|date=3 February 2017}}</ref> As of 2017, Beijing's roadmap aims to create a $150 billion AI industry by 2030.<ref name="financial times">{{cite news|title=China seeks dominance of global AI industry|url=https://www.ft.com/content/856753d6-8d31-11e7-a352-e46f43c5825d|access-date=24 December 2017|work=[[Financial Times]]|date=15 October 2017}}</ref> Before 2013, Chinese defense procurement was mainly restricted to a few conglomerates; however, as of 2017, China often sources sensitive emerging technology such as drones and artificial intelligence from private start-up companies.<ref>{{cite news|title=China enlists start-ups in high-tech arms race|url=https://www.ft.com/content/5883d3d2-62cd-11e7-91a7-502f7ee26895|access-date=24 December 2017|work=[[Financial Times]]|date=9 July 2017}}</ref> An October 2021 report by the [[Center for Security and Emerging Technology]] found that "Most of the [Chinese military]'s AI equipment suppliers are not state-owned defense enterprises, but private Chinese tech companies founded after 2010."<ref name=":1">{{Cite web |last1=Fedasiuk |first1=Ryan |last2=Melot |first2=Jennifer |last3=Murphy |first3=Ben |date=October 2021 |title=Harnessed Lightning: How the Chinese Military is Adopting Artificial Intelligence |url=https://cset.georgetown.edu/publication/harnessed-lightning/ |access-date=April 22, 2022 |website=Center for Security and Emerging Technology}}</ref> The report estimated that Chinese military spending on AI exceeded $1.6 billion each year.<ref name=":1" /> The ''[[Japan Times]]'' reported in 2018 that annual private Chinese investment in AI is under $7 billion per year. AI startups in China received nearly half of total global investment in AI startups in 2017; the Chinese filed for nearly five times as many AI patents as did Americans.<ref name="japan times editorial board">{{cite news|title=The artificial intelligence race heats up|url=https://www.japantimes.co.jp/opinion/2018/03/01/editorials/artificial-intelligence-race-heats/|access-date=5 March 2018|work=[[The Japan Times]]|date=1 March 2018}}</ref>

China published a position paper in 2016 questioning the adequacy of existing international law to address the eventuality of fully autonomous weapons, becoming the first permanent member of the [[Security Council|U. N. Security Council]] to broach the issue.<ref>{{cite news|title=Robots with Guns: The Rise of Autonomous Weapons Systems|url=https://www.snopes.com/2017/04/21/robots-with-guns/|access-date=24 December 2017|work=Snopes.com|date=21 April 2017}}</ref> In 2018, Xi called for greater international cooperation in basic AI research.<ref>{{cite news |last1=Pecotic |first1=Adrian |title=Whoever Predicts the Future Will Win the AI Arms Race |url=https://foreignpolicy.com/2019/03/05/whoever-predicts-the-future-correctly-will-win-the-ai-arms-race-russia-china-united-states-artificial-intelligence-defense/ |access-date=16 July 2019 |work=Foreign Policy |date=2019}}</ref> Chinese officials have expressed concern that AI such as drones could lead to accidental war, especially in the absence of international norms.<ref>{{cite news |last1=Vincent |first1=James |title=China is worried an AI arms race could lead to accidental war |url=https://www.theverge.com/2019/2/6/18213476/china-us-ai-arms-race-artificial-intelligence-automated-warfare-military-conflict |access-date=16 July 2019 |work=The Verge |date=6 February 2019}}</ref> In 2019, former [[United States Secretary of Defense]] [[Mark Esper]] lashed out at China for selling drones capable of taking life with no human oversight.<ref>{{cite news |title=Is China exporting killer robots to Mideast?
|url=https://www.asiatimes.com/2019/11/article/is-china-exporting-killer-robots-to-mideast/ |access-date=2019-12-21 |work=[[Asia Times]] |date=2019-11-28 |language=en}}</ref>

=== United States ===
[[File:Sea Hunter gets underway on the Willamette River following a christening ceremony in Portland, Ore. (25702146834).jpg|thumb|alt=The Sea Hunter sails out to sea|The ''[[Sea Hunter]]'', an autonomous US warship, 2016]]
In 2014, former Secretary of Defense [[Chuck Hagel]] posited the "[[Offset strategy|Third Offset Strategy]]" that rapid advances in artificial intelligence will define the next generation of warfare.<ref>{{cite news|title=US risks losing AI arms race to China and Russia|url=http://www.cnn.com/2017/11/29/politics/us-military-artificial-intelligence-russia-china/index.html|access-date=24 December 2017|work=CNN|date=29 November 2017}}</ref> According to data science and analytics firm Govini, the U.S. [[United States Department of Defense|Department of Defense]] increased investment in artificial intelligence, big data and cloud computing from $5.6 billion in 2011 to $7.4 billion in 2016.<ref>{{cite news|last1=Davenport|first1=Christian|title=Future wars may depend as much on algorithms as on ammunition, report says.|url=https://www.washingtonpost.com/business/economy/future-wars-may-depend-as-much-on-algorithms-as-on-ammunition-report-says/2017/12/03/4fa51f38-d6b7-11e7-b62d-d9345ced896d_story.html|access-date=24 December 2017|newspaper=Washington Post|date=3 December 2017}}</ref> However, the civilian [[National Science Foundation|NSF]] budget for AI saw no increase in 2017.<ref name="financial times"/> ''[[Japan Times]]'' reported in 2018 that the United States private investment is around $70 billion per year.<ref name="japan times editorial board" /> The November 2019 'Interim Report' of the United States' National Security Commission on Artificial Intelligence confirmed that AI is critical to US technological military superiority.<ref name=":0" />

The U.S. has many military AI combat programs, such as the ''[[Sea Hunter]]'' autonomous warship, which is designed to operate for extended periods at sea without a single crew member, and to even guide itself in and out of port.<ref name=bbc/> From 2017, a temporary US Department of Defense directive requires a human operator to be kept in the loop when it comes to the taking of human life by autonomous weapons systems.<ref>{{cite news|title=US general warns of out-of-control killer robots|url=http://www.cnn.com/2017/07/18/politics/paul-selva-gary-peters-autonomous-weapons-killer-robots/index.html|access-date=24 December 2017|work=CNN|date=18 July 2017}}</ref> On October 31, 2019, the United States Department of Defense's Defense Innovation Board published the draft of a report recommending principles for the ethical use of artificial intelligence by the Department of Defense that would ensure a human operator would always be able to look into the 'black box' and understand the [[Kill chain|kill-chain]] process. However, a major concern is how the report will be implemented.<ref>{{Cite book|last=United States. Defense Innovation Board.|title=AI principles: recommendations on the ethical use of artificial intelligence by the Department of Defense|oclc=1126650738}}</ref>

{{anchor|Project Maven}}Project Maven is a [[United States Department of Defense|Pentagon]] project involving using machine learning and engineering talent to distinguish people and objects in drone videos,<ref name="bbc1">{{cite news|url=https://www.bbc.com/news/business-44341490|title=Google 'to end' Pentagon Artificial Intelligence project|date=2 June 2018|work=[[BBC News]]|access-date=3 June 2018}}</ref> apparently giving the government real-time battlefield command and control, and the ability to track, tag and spy on targets without human involvement. Initially the effort was led by [[Robert O. Work]] who was concerned about China's military use of the emerging technology.<ref>Cade Metz. (15 March 2018). "Pentagon Wants Silicon Valley's Help on A.I.". [https://www.nytimes.com/2018/03/15/technology/military-artificial-intelligence.html?searchResultPosition=4 NY Times website] Retrieved 8 March 2022.</ref>  Reportedly, Pentagon development stops short of acting as an AI weapons system capable of firing on self-designated targets.<ref>{{Cite web|url=https://thenextweb.com/artificial-intelligence/2019/12/11/report-palantir-took-over-project-maven-the-military-ai-program-too-unethical-for-google/|title=Report: Palantir took over Project Maven, the military AI program too unethical for Google|date=11 December 2020|website=The Next Web|access-date=17 January 2020}}</ref> The project was established in a memo by the [[United States Deputy Secretary of Defense|U.S. Deputy Secretary of Defense]] on 26 April 2017.<ref>{{cite web|url=https://www.govexec.com/media/gbc/docs/pdfs_edit/establishment_of_the_awcft_project_maven.pdf|title=Establishment of an Algorithmic Warfare Cross-Functional Team (Project Maven)|author=Robert O. Work|author-link=Robert O. Work|date=26 April 2017|access-date=3 June 2018}}</ref> Also known as the [[Secretary of Defense-Empowered Cross-Functional Teams#Algorithmic Warfare Cross Functional Team (AWCFT)|Algorithmic Warfare Cross Functional Team]],<ref>{{cite news|url=https://www.fedscoop.com/google-employees-resign-project-maven/|title=Google employees resign in protest against Air Force's Project Maven|date=14 May 2018|work=Fedscoop|access-date=3 June 2018}}</ref> it is, according to Lt. Gen. of the [[United States Air Force]] Jack Shanahan in November 2017, a project "designed to be that pilot project, that pathfinder, that spark that kindles the flame front of artificial intelligence across the rest of the [Defense] Department".<ref>{{cite journal|last1=Allen|first1=Gregory C.|date=21 December 2017|title=Project Maven brings AI to the fight against ISIS|url=https://thebulletin.org/project-maven-brings-ai-fight-against-isis11374|journal=[[Bulletin of the Atomic Scientists]]|access-date=3 June 2018|archive-date=4 June 2018|archive-url=https://web.archive.org/web/20180604115846/https://thebulletin.org/project-maven-brings-ai-fight-against-isis11374|url-status=dead}}</ref> Its chief, [[United States Marine Corps|U.S. Marine Corps]] Col. Drew Cukor, said: "People and computers will work symbiotically to increase the ability of weapon systems to detect objects."<ref>{{cite web|url=https://www.military.com/daily-news/2018/06/03/google-backs-pentagon-project-after-uproar-report.html|title=Google Backs Off from Pentagon Project After Uproar: Report|author=Ethan Baron|date=3 June 2018|work=[[Military.com]]|access-date=3 June 2018|agency=Mercury.com}}</ref> Project Maven has been noted by allies, such as Australia's [[Ian Langford (soldier)|Ian Langford]], for the ability to identify adversaries by harvesting data from sensors on [[UAV]]s and satellite.<ref>{{Cite journal |last=Skinner |first=Dan |date=29 January 2020 |title=Signature Management in Accelerated Warfare {{!}} Close Combat in the 21st Century |url=https://cove.army.gov.au/article/signature-management-accelerated-warfare-close-combat-21st-century |journal=The Cove}}</ref> At the second [[Defense One]] Tech Summit in July 2017, Cukor also said that the investment in a "deliberate workflow process" was funded by the Department [of Defense] through its "rapid acquisition authorities" for about "the next 36 months".<ref>{{cite web|url=https://www.defense.gov/News/Article/Article/1254719/project-maven-to-deploy-computer-algorithms-to-war-zone-by-years-end/|title=Project Maven to Deploy Computer Algorithms to War Zone by Year's End|author=Cheryl Pellerin|date=21 July 2017|publisher=DoD News, Defense Media Activity|access-date=3 June 2018|agency=[[United States Department of Defense]]}}</ref>

The Joint Artificial Intelligence Center (JAIC) (pronounced "jake")<ref name=CRS1>{{cite report |author=Kelley M. Sayler |date=June 8, 2021 |title=Defense Primer: Emerging Technologies |url=https://fas.org/sgp/crs/natsec/IF11105.pdf |publisher=[[Congressional Research Service]] |access-date=July 22, 2021}}</ref> is an American organization on exploring the usage of AI (particularly [[edge computing]]), [[Network science|Network of Networks]], and AI-enhanced communication, for use in actual combat.<ref>{{Cite web|url=https://www.defense.gov/Explore/News/Article/Article/1755942/dod-unveils-its-artificial-intelligence-strategy/|title=DOD Unveils Its Artificial Intelligence Strategy|website=U.S. Department of Defense }}</ref><ref name=dodcio/><ref>{{Cite web|url=https://breakingdefense.com/2018/06/joint-artificial-intelligence-center-created-under-dod-cio/|title=Joint Artificial Intelligence Center Created Under DoD CIO|first=Paul|last=McLeary|date=29 June 2018 }}</ref><ref name="auto">{{cite web|last=Barnett |first=Jackson |url=https://www.fedscoop.com/military-ai-hardware-in-battle/ |title=For military AI to reach the battlefield, there are more than just software challenges |publisher=FedScoop |date=June 19, 2020 |access-date=June 26, 2020}}</ref> It is a subdivision of the [[United States Armed Forces]] and was created in June 2018. The organization's stated objective is to "transform the [[DoD|US Department of Defense]] by accelerating the delivery and adoption of AI to achieve mission impact at scale. The goal is to use AI to solve large and complex problem sets that span multiple combat systems; then, ensure the combat Systems and Components have real-time access to ever-improving libraries of data sets and tools."<ref name=dodcio>{{cite web|url=https://dodcio.defense.gov/About-DoD-CIO/Organization/JAIC/ |title=Joint Artificial Intelligence Center |publisher=Department of Defense |access-date=June 26, 2020}}</ref>

=== United Kingdom ===
In 2015, the UK government opposed a ban on lethal autonomous weapons, stating that "international humanitarian law already provides sufficient regulation for this area", but that all weapons employed by UK armed forces would be "under human oversight and control".<ref>{{cite news|last1=Gibbs|first1=Samuel|title=Elon Musk leads 116 experts calling for outright ban of killer robots|url=https://www.theguardian.com/technology/2017/aug/20/elon-musk-killer-robots-experts-outright-ban-lethal-autonomous-weapons-war|access-date=24 December 2017|work=[[The Guardian]]|date=20 August 2017}}</ref>

=== Israel ===
Israel's [[IAI Harpy|Harpy]] anti-radar "fire and forget" drone is designed to be launched by ground troops, and autonomously fly over an area to find and destroy radar that fits pre-determined criteria.<ref>{{cite news|title='Killer robots': autonomous weapons pose moral dilemma {{!}} World{{!}} Breakings news and perspectives from around the globe {{!}} DW {{!}} 14.11.2017|url=http://www.dw.com/en/killer-robots-autonomous-weapons-pose-moral-dilemma/a-41342616|access-date=12 January 2018|work=DW.COM|date=14 November 2017|language=en}}</ref> The application of artificial intelligence is also expected to be advanced in crewless ground systems and robotic vehicles such as the Guardium MK III and later versions.<ref>{{Cite journal|last=Slocombe|first=Geoff|date=2015|title=Uninhabited Ground Systems (Ugs)|journal=Asia-Pacific Defence Reporter|volume=41|issue=7|pages=28–29}}</ref> These robotic vehicles are used in border defense.

=== South Korea ===
The South Korean [[Sentry gun#Super aEgis II|Super aEgis II]] machine gun, unveiled in 2010, sees use both in South Korea and in the Middle East. It can identify, track, and destroy a moving target at a range of 4&nbsp;km. While the technology can theoretically operate without human intervention, in practice safeguards are installed to require manual input. A South Korean manufacturer states, "Our weapons don't sleep, like humans must. They can see in the dark, like humans can't. Our technology therefore plugs the gaps in human capability", and they want to "get to a place where our software can discern whether a target is friend, foe, civilian or military".<ref>{{cite news|last1=Parkin|first1=Simon|title=Killer robots: The soldiers that never sleep|url=http://www.bbc.com/future/story/20150715-killer-robots-the-soldiers-that-never-sleep|access-date=13 January 2018|work=BBC|date=16 July 2015}}</ref>

=== European Union ===
The European Parliament holds the position that humans must have oversight and decision-making power over lethal autonomous weapons.<ref>{{Cite web|title=Texts adopted - Autonomous weapon systems - Wednesday, 12 September 2018|url=https://www.europarl.europa.eu/doceo/document/TA-8-2018-0341_EN.html|access-date=2021-01-30|website=www.europarl.europa.eu|language=en}}</ref> However, it is up to each member state of the European Union to determine their stance on the use of autonomous weapons and the mixed stances of the member states is perhaps the greatest hindrance to the European Union's ability to develop autonomous weapons. Some members such as France, Germany, Italy, and Sweden are developing lethal autonomous weapons. Some members remain undecided about the use of autonomous military weapons and Austria has even called to ban the use of such weapons.<ref name=":02">{{Cite journal|last1=Haner|first1=Justin|last2=Garcia|first2=Denise|date=2019|title=The Artificial Intelligence Arms Race: Trends and World Leaders in Autonomous Weapons Development|journal=Global Policy|language=en|volume=10|issue=3|pages=331–337|doi=10.1111/1758-5899.12713|issn=1758-5899|doi-access=free}}</ref>

Some EU member states have developed and are developing automated weapons. Germany has developed an [[active protection system]], the Active Defense System, that can respond to a threat with complete autonomy in less than a millisecond.<ref name=":02" /><ref>{{Cite book|last1=Boulanin|first1=Vincent |title=Mapping the development of autonomy in weapon systems|last2=Verbruggen|first2=Maaike|date=2017|publisher=Stockholm International Peace Research Institute |isbn=|url=https://www.sipri.org/sites/default/files/2017-11/siprireport_mapping_the_development_of_autonomy_in_weapon_systems_1117_1.pdf |language=en|doi=10.13140/rg.2.2.22719.41127}}</ref> Italy plans to incorporate autonomous weapons systems into its future military plans.<ref name=":02" />

== Proposals for international regulation ==
The international regulation of autonomous weapons is an emerging issue for international law.<ref>{{Cite journal|url=https://dash.harvard.edu/handle/1/33813394|title=No Mere Deodands: Human Responsibilities in the Use of Violent Intelligent Systems Under Public International Law|last=Bento|first=Lucas|date=2017|website=Harvard Scholarship Depository|access-date=2019-09-14}}</ref> AI arms control will likely require the institutionalization of new international norms embodied in effective technical specifications combined with active monitoring and informal diplomacy by communities of experts, together with a legal and political verification process.<ref name="Geist 318–321"/><ref name="Maas 285–311"/> As early as 2007, scholars such as AI professor [[Noel Sharkey]] have warned of "an emerging arms race among the hi-tech nations to develop autonomous submarines, fighter jets, battleships and tanks that can find their own targets and apply violent force without the involvement of meaningful human decisions".<ref>{{cite news|title=Ban on killer robots urgently needed, say scientists|url=https://www.theguardian.com/science/2017/nov/13/ban-on-killer-robots-urgently-needed-say-scientists|access-date=24 December 2017|work=The Guardian|date=13 November 2017 |first=Ian |last=Sample}}</ref><ref>{{cite news|last1=Sharkey|first1=Noel|title=Robot wars are a reality|url=https://www.theguardian.com/commentisfree/2007/aug/18/comment.military|access-date=11 January 2018|work=The Guardian|date=17 August 2007}}</ref>

Miles Brundage of the [[University of Oxford]] has argued an AI arms race might be somewhat mitigated through diplomacy: "We saw in the various historical arms races that collaboration and dialog can pay dividends".<ref name=wired>{{cite news|title=AI Could Revolutionize War as Much as Nukes|url=https://www.wired.com/story/ai-could-revolutionize-war-as-much-as-nukes/|access-date=24 December 2017|magazine=Wired |date=July 19, 2017 |first=Tom |last=Simonite}}</ref> Over a hundred experts signed an open letter in 2017 calling on the UN to address the issue of lethal autonomous weapons;<ref>{{cite news|last1=Gibbs|first1=Samuel|title=Elon Musk leads 116 experts calling for outright ban of killer robots|url=https://www.theguardian.com/technology/2017/aug/20/elon-musk-killer-robots-experts-outright-ban-lethal-autonomous-weapons-war|access-date=11 January 2018|work=The Guardian|date=20 August 2017}}</ref><ref>{{cite web|title=An Open Letter to the United Nations Convention on Certain Conventional Weapons|url=https://futureoflife.org/autonomous-weapons-open-letter-2017/|website=Future of Life Institute|access-date=14 January 2018 |date=August 20, 2017 |first=Ariel |last=Conn}}</ref> however, at a November 2017 session of the UN [[Convention on Certain Conventional Weapons]] (CCW), diplomats could not agree even on how to define such weapons.<ref name=asia>{{cite news|title=Rise of the killer machines|url=https://asiatimes.com/article/rise-killer-machines/|date=24 November 2017|access-date=24 December 2017|work=[[Asia Times]] |first=Alan |last=Boyd}}</ref> The Indian ambassador and chair of the CCW stated that agreement on rules remained a distant prospect.<ref>{{cite news|title='Robots are not taking over,' says head of UN body on autonomous weapons|url=https://www.theguardian.com/science/2017/nov/17/killer-robots-un-convention-on-conventional-weapons|access-date=14 January 2018|work=The Guardian|date=17 November 2017}}</ref> As of 2019, 26 heads of state and 21 Nobel Peace Prize laureates have backed a ban on autonomous weapons.<ref name="g2019">{{cite news |title=Campaign to stop 'killer robots' takes peace mascot to UN |url=https://www.theguardian.com/science/2019/oct/21/campaign-to-stop-killer-robots-takes-peace-mascot-to-un |access-date=27 January 2022 |work=The Guardian |date=21 October 2019 |first=Henry |last=McDonald |language=en}}</ref> However, as of 2022, most major powers continue to oppose a ban on autonomous weapons.<ref>{{cite news |last1=Khan |first1=Jeremy |title=The world just blew a 'historic opportunity' to stop killer robots |url=https://fortune.com/2021/12/22/killer-robots-ban-fails-un-artificial-intelligence-laws/ |access-date=31 December 2021 |work=Fortune |date=2021 |language=en |quote=Several states, including the U.S., Russia, the United Kingdom, India, and Israel, were opposed to any legally binding restrictions... China has supported a binding legal agreement at the CCW, but has also sought to define autonomous weapons so narrowly that much of the A.I.-enabled military equipment it is currently developing would fall outside the scope of such a ban.}}</ref>

Many experts believe attempts to completely ban killer robots are likely to fail,<ref>{{cite news|title=Sorry, Banning 'Killer Robots' Just Isn't Practical|url=https://www.wired.com/story/sorry-banning-killer-robots-just-isnt-practical/|access-date=14 January 2018|magazine=Wired |date=22 August 2017 |first=Tom |last=Simonite}}</ref> in part because detecting treaty violations would be extremely difficult.<ref>Antebi, Liran. "Who Will Stop the Robots?." Military and Strategic Affairs 5.2 (2013).</ref><ref>Shulman, C., & Armstrong, S. (2009, July). Arms control and intelligence explosions. In 7th European Conference on Computing and Philosophy (ECAP), Bellaterra, Spain, July (pp. 2-4).</ref> A 2017 report from [[Harvard University|Harvard's]] [[Belfer Center]] predicts that AI has the potential to be as transformative as nuclear weapons.<ref name=wired/><ref>{{cite news|last1=McFarland|first1=Matt|title='Slaughterbots' film shows potential horrors of killer drones|url=https://money.cnn.com/2017/11/14/technology/autonomous-weapons-ban-ai/index.html|access-date=14 January 2018|work=CNNMoney|date=14 November 2017}}</ref><ref name=belfer>Allen, Greg, and Taniel Chan. "Artificial Intelligence and National Security." Report. Harvard Kennedy School, Harvard University. Boston, MA (2017).</ref> The report further argues that "Preventing expanded military use of AI is likely impossible" and that "the more modest goal of safe and effective technology management must be pursued", such as banning the attaching of an AI [[dead man's switch]] to a nuclear arsenal.<ref name=belfer/>

== Other reactions to autonomous weapons ==
A 2015 open letter by the [[Future of Life Institute]] calling for the prohibition of lethal autonomous weapons systems has been signed by over 26,000 citizens, including physicist [[Stephen Hawking]], [[Tesla, Inc.|Tesla]] magnate [[Elon Musk]], [[Apple Inc.|Apple]]'s [[Steve Wozniak]] and [[Twitter]] co-founder [[Jack Dorsey]], and over 4,600 artificial intelligence researchers, including [[Stuart J. Russell|Stuart Russell]], [[Bart Selman]] and [[Francesca Rossi]].<ref>{{Cite web|date=2016-02-09|title=Autonomous Weapons Open Letter: AI & Robotics Researchers|url=https://futureoflife.org/2016/02/09/open-letter-autonomous-weapons-ai-robotics/|access-date=2022-02-17|website=Future of Life Institute|language=en-US}}</ref><ref name=asia/> The Future of Life Institute has also released two fictional films, ''[[Slaughterbots]]'' (2017) and ''Slaughterbots - if human: kill()'' (2021), which portray threats of autonomous weapons and promote a ban, both of which went viral.

Professor [[Noel Sharkey]] of the [[University of Sheffield]] argues that autonomous weapons will inevitably fall into the hands of terrorist groups such as the [[Islamic State of Iraq and the Levant|Islamic State]].<ref>{{cite news|last1=Wheeler|first1=Brian|title=Terrorists 'certain' to get killer robots|url=https://www.bbc.com/news/uk-politics-42153140|access-date=24 December 2017|work=BBC News|date=30 November 2017}}</ref>

== Disassociation ==
Many Western tech companies avoid being associated too closely with the U.S. military, for fear of losing access to China's market.<ref name=nytimes/> Furthermore, some researchers, such as [[DeepMind]] CEO [[Demis Hassabis]], are ideologically opposed to contributing to military work.<ref>{{cite news|last1=Metz|first1=Cade|title=Pentagon Wants Silicon Valley's Help on A.I.|url=https://www.nytimes.com/2018/03/15/technology/military-artificial-intelligence.html|access-date=19 March 2018|work=The New York Times|date=15 March 2018}}</ref>

For example, in June 2018, company sources at [[Google]] said that top executive [[Diane Greene]] told staff that the company would not follow-up Project Maven after the current contract expired in March 2019.<ref name="bbc1" />

==See also==
* [[AI alignment]]
* ''[[A.I. Rising]]''
* [[Arms race]]
* [[Artificial general intelligence]]
* [[Artificial intelligence]]
* [[Artificial intelligence detection software]]
* [[Artificial Intelligence Cold War]]
* [[Cold War]]
* [[Ethics of artificial intelligence]]
* [[Existential risk from artificial general intelligence]]
* [[Lethal autonomous weapon]]
* [[Military robot]]
* [[Nuclear arms race]]
* [[Post–Cold War era]]
* [[Second Cold War]]
* [[Space Race]]
* [[Unmanned combat aerial vehicle]]
* [[Weak AI]]

==References==
{{Reflist}}

==Further reading==
* Paul Scharre, "Killer Apps: The Real Dangers of an AI Arms Race", ''[[Foreign Affairs]]'', vol. 98, no. 3 (May/June 2019), pp.&nbsp;135–44. "Today's AI technologies are powerful but unreliable.  Rules-based systems cannot deal with circumstances their programmers did not anticipate.  Learning systems are limited by the data on which they were trained. AI failures have already led to tragedy. Advanced autopilot features in cars, although thesddsy perform well in some circumstances, have driven cars without warning into trucks, concrete barriers, and parked cars.  In the wrong situation, AI systems go from supersmart to superdumb in an instant.  When an enemy is trying to manipulate and hack an AI system, the risks are even greater."  (p.&nbsp;140.)
*The National Security Commission on Artificial Intelligence. (2019). ''[https://drive.google.com/a/nscai.org/file/d/153OrxnuGEjsUvlxWsFYauslwNeCEkvUb/view?usp=sharing Interim Report]''. Washington, DC: Author.

[[Category:Artificial intelligence]]
[[Category:Technological races]]
[[Category:Computational neuroscience]]
[[Category:Cybernetics]]