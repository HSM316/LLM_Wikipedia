{{Essay-like|date=February 2017}}
{{Orphan|date=March 2017}}

[[File:Saliencymap example.jpg|thumb|476x476px|A view of the fort of [[Marburg]] (Germany) and the saliency Map of the image using color, intensity and orientation.]]

In [[computer vision]], a '''saliency map''' is an [[image]] that shows each [[pixel]]'s unique quality.<ref>{{cite journal |last1=Kadir |first1=Timor |last2=Brady |first2=Michael |title=Saliency, Scale and Image Description |journal=International Journal of Computer Vision |date=2001 |volume=45 |issue=2 |pages=83–105 |doi=10.1023/A:1012460413855|citeseerx=10.1.1.154.8924}}</ref> The goal of a saliency map is to simplify and/or change the representation of an image into something that is more meaningful and easier to analyze. For example, if a pixel has a high [[grey level]] or other unique color quality in a color image, that pixel's quality will show in the saliency map and in an obvious way. Saliency is a kind of [[image segmentation]].

==Saliency as a segmentation problem==
Saliency estimation may be viewed as an instance of [[image segmentation]]. In [[computer vision]], image segmentation is the process of partitioning a digital image into multiple segments (sets of pixels, also known as [[wiktionary:superpixel|superpixels]]). The goal of segmentation is to simplify and/or change the representation of an image into something that is more meaningful and easier to analyze. Image segmentation is typically used to locate objects and boundaries (lines, curves, etc.) in images. More precisely, image segmentation is the process of assigning a label to every pixel in an image such that pixels with the same label share certain characteristics.<ref>{{cite arXiv |author=A. Maity |title=Improvised Salient Object Detection and Manipulation |year=2015|eprint=1511.02999|class=cs.CV}}</ref>

==Example implementation==
First, we should calculate the distance of each pixel to the rest of pixels in the same frame:
:<math>\mathrm{SALS}(I_k) = \sum_{i=1}^N|I_k - I_i|</math>

<math>I_i</math> is the value of pixel <math>i</math>, in the range of [0,255]. The following equation is the expanded form of this equation. 
: <span class="texhtml"> SALS(''I<sub>k</sub>'') = |''I<sub>k</sub>'' - ''I''<sub>1</sub>| + |''I<sub>k</sub>'' - ''I''<sub>2</sub>| + ... + |''I<sub>k</sub>'' - ''I<sub>N</sub>''| </span>
Where N is the total number of pixels in  the current  frame. Then we can further restructure  our formula. We put the value that has same I together.
: <span class="texhtml"> SALS(''I<sub>k</sub>'') = ∑ ''F<sub>n</sub>'' &times; |''I<sub>k</sub>'' - ''I<sub>n</sub>''| </span>
Where {{mvar|F<sub>n</sub>}} is the frequency of {{mvar|I<sub>n</sub>}}. And the value of n belongs to [0,255]. The frequencies is expressed in the form of histogram, and the computational time of histogram is {{tmath|O(N)}} time complexity.

===Time complexity===
This saliency map algorithm has {{tmath|O(N)}} [[time complexity]]. Since the computational time of histogram is {{tmath|O(N)}} time complexity which N is the number of pixel's number of a frame. Besides, the minus part and multiply part of this equation need 256 times operation. Consequently, the time complexity of this algorithm is {{tmath|O(N+256)}} which equals to {{tmath|O(N)}}.

=== Pseudocode===
All of the following code is [[pseudo]] [[matlab]] code. First, read Data from video sequences.
<div class="mw-highlight">
 <span class="k">for</span> <span class="nb">k</span> = <span class="mi">2</span> : <span class="mi">1</span> : <span class="mi">13</span>  <span class="c">% which means from frame 2 to 13,  and in every loop K's value increase one.</span>
   <span class="nb">I</span> = imread(currentfilename); <span class="c">% read current frame</span>
   <span class="nb">I1</span> = im2single(<span class="nb">I</span>);    <span class="c">% convert double image into single(requirement of command vlslic)</span>
   <span class="nb">l</span> = imread(previousfilename); <span class="c">% read previous frame</span>
   <span class="nb">I2</span> = im2single(<span class="nb">l</span>);
   regionSize = <span class="mi">10</span>; <span class="c">% set the parameter of SLIC this parameter setting are the experimental result. RegionSize means the superpixel size.</span>
   regularizer = <span class="mi">1</span>; <span class="c">% set the parameter of SLIC </span>
   segments1 = vl_slic(<span class="nb">I1</span>, regionSize, regularizer); <span class="c">% get the superpixel of current frame</span>
   segments2 = vl_slic(<span class="nb">I2</span>, regionSize, regularizer); <span class="c">% get superpixel of the previous frame</span>
   numsuppix = max(segments1(:)); <span class="c">% get the number of superpixel all information about superpixel is in [http://www.vlfeat.org/overview/slic.html this link]</span>
   regstats1 = regionprops(segments1, <span class="s">’all’</span>);
   regstats2 = regionprops(segments2, <span class="s">’all’</span>); <span class="c">% get the region characteristic based on segments1</span>
</div>
After we read data, we do superpixel process to each frame.
Spnum1 and Spnum2 represent the pixel number of current frame and previous pixel.

<syntaxhighlight lang="matlab">
% First, we calculate the value distance of each pixel.
% This is our core code
for i=1:1:spnum1   %  From the first pixel to the last one. And in every loop i++
      for j=1:1:spnum2 % From the first pixel to the last one. j++. previous frame
           centredist(i:j) = sum((center(i)-center(j))); % calculate the center distance 
      end
end
</syntaxhighlight>

Then we calculate the color distance of each pixel, this process we call it contract function.
<syntaxhighlight lang="matlab">
for i=1:1:spnum1 % From first pixel of current frame to the last one pixel. I ++
      for j=1:1:spnum2 % From first pixel of previous frame to the last one pixel. J++
           posdiff(i,j) = sum((regstats1(j).Centroid’-mupwtd(:,i))); % Calculate the color distance.
      end
end
</syntaxhighlight>
After this two process, we will get a saliency map, and then store all of these maps into a new FileFolder.

=== Difference in algorithms ===
The major difference between function one and two is the difference of contract function. If spnum1 and spnum2 both represent the current frame's pixel number, then this contract function is for the first saliency function. If spnum1 is the current frame's pixel number and spnum2 represent the previous frame's pixel number, then this contract function is for second saliency function. If we use the second contract function which using the pixel of the same frame to get center distance to get a saliency map, then we apply this saliency function to each frame and use current frame's saliency map minus previous frame's saliency map to get a new image which is the new saliency result of the third saliency function.

[[File:Wiki102.png|thumb|Saliency result]]

==References==
{{reflist}}
==External links==
* {{Cite book|last=Zhai|first=Yun|last2=Shah|first2=Mubarak|date=2006-10-23|title=Visual Attention Detection in Video Sequences Using Spatiotemporal Cues|journal=Proceedings of the 14th ACM International Conference on Multimedia|series=MM '06|location=New York, NY, USA|publisher=ACM|pages=815–824|doi=10.1145/1180639.1180824|isbn=978-1595934475|citeseerx=10.1.1.80.4848}}
* VLfeat: http://www.vlfeat.org/index.html
*[http://www.scholarpedia.org/article/Saliency_map Saliency map] at [[Scholarpedia]]

== See also ==
* [[Image segmentation]]
* [[Salience (neuroscience)]]

[[Category:Computer vision]]
[[Category:Image processing]]