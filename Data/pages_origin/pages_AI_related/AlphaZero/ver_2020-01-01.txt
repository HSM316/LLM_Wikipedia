'''AlphaZero''' is a [[computer program]] developed by [[artificial intelligence]] research company [[DeepMind]] to master the games of [[chess]], [[shogi]] and [[Go (game)|go]].  The [[algorithm]] uses an approach similar to [[AlphaGo Zero]]. On December 5, 2017, the DeepMind team released a [[preprint]] introducing AlphaZero, which within 24 hours achieved a superhuman level of play in these three games by defeating world-champion programs, [[Stockfish (chess)|Stockfish]], [[Elmo (shogi engine)|elmo]], and the 3-day version of AlphaGo Zero. In each case it made use of custom [[tensor processing unit]]s (TPUs) that the Google programs were optimized to use.<ref name=preprint>{{Cite arXiv|author-link1=David Silver (programmer)|first1=David|last1= Silver|first2=Thomas|last2= Hubert|first3= Julian|last3=Schrittwieser|first4= Ioannis|last4=Antonoglou |first5= Matthew|last5= Lai|first6= Arthur|last6= Guez|first7= Marc|last7= Lanctot|first8= Laurent|last8= Sifre|first9= Dharshan|last9= Kumaran|authorlink9=Dharshan Kumaran|first10= Thore|last10= Graepel|first11= Timothy|last11= Lillicrap|first12= Karen|last12= Simonyan|first13=Demis |last13=Hassabis|author-link13=Demis Hassabis |eprint=1712.01815|title=Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm|class=cs.AI|date=5 December 2017}}</ref> AlphaZero was trained solely via "self-play" using 5,000 first-generation TPUs to generate the games and 64 second-generation TPUs to train the [[neural network]]s, all in [[parallel computing|parallel]], with no access to [[Chess opening book|opening books]] or [[Endgame tablebase|endgame tables]].  After four hours of training, DeepMind estimated AlphaZero was playing at a higher [[Elo rating]] than Stockfish 8; after 9 hours of training, the algorithm decisively defeated Stockfish 8 in a time-controlled 100-game tournament (28 wins, 0 losses, and 72 draws).<ref name="preprint"/><ref name=telegraph>{{Cite news|url=https://www.telegraph.co.uk/science/2017/12/06/entire-human-chess-knowledge-learned-surpassed-deepminds-alphazero/|title=Entire human chess knowledge learned and surpassed by DeepMind's AlphaZero in four hours|last=Knapton|first=Sarah|date=6 December 2017|publisher=[[Telegraph.co.uk]]|access-date=6 December 2017|last2=Watson|first2=Leon|language=en-GB}}</ref><ref>{{Cite news|first=James|last= Vincent|url=https://www.theverge.com/2017/12/6/16741106/deepmind-ai-chess-alphazero-shogi-go|title=DeepMind's AI became a superhuman chess player in a few hours, just for fun|publisher=[[The Verge]]|date=6 December 2017|access-date=6 December 2017}}</ref> The trained algorithm played on a single machine with four TPUs. DeepMind's paper on AlphaZero was published in the journal ''[[Science (journal)|Science]]'' on 7 December 2018.<ref name="Science20181207">{{Cite journal|first1 = David|last1 = Silver|author-link1=David Silver (programmer)|first2 =Thomas |last2 = Hubert|author-link2=|first3 = Julian |last3 =Schrittwieser|first4 = Ioannis |last4 = Antonoglou|first5 = Matthew |last5 = Lai|first6 =Arthur |last6 = Guez|first7 = Marc |last7 = Lanctot|first8 =  Laurent |last8 = Sifre|first9 = Dharshan |last9 = Kumaran|first10= Thore |last10= Graepel|first11= Timothy |last11= Lillicrap|first12=Karen |last12= Simonyan|first13= Demis |last13= Hassabis|author-link13=Demis Hassabis|title = A general reinforcement learning algorithm that masters chess, shogi, and go through self-play|journal = [[Science (journal)|Science]]| issn= |pages = 1140–1144|volume = 362|issue = 6419|doi = 10.1126/science.aar6404|pmid = 30523106|date= 7 December 2018|bibcode =}}</ref>

==Relation to AlphaGo Zero==
{{Further|AlphaGo Zero}}

AlphaZero (AZ) is a more generalized variant of the AlphaGo Zero (AGZ) [[algorithm]], and is able to play [[shogi]] and [[chess]] as well as [[Go (game)|Go]]. Differences between AZ and AGZ include:<ref name=preprint/>

* AZ has hard-coded rules for setting search [[Hyperparameter (machine learning)|hyperparameters]].
* The neural network is now updated continually.
* Go (unlike chess) is symmetric under certain reflections and rotations; AlphaGo Zero was programmed to take advantage of these symmetries. AlphaZero is not.
* Chess can end in a [[draw (chess)|draw]] unlike Go; therefore AlphaZero can take into account the possibility of a drawn game.

==AlphaZero vs. Stockfish and elmo==
{{Further|Stockfish (chess)|elmo (shogi engine)}}
Comparing [[Monte Carlo tree search]] searches, AlphaZero searches just 80,000 positions per second in chess and 40,000 in shogi, compared to 70 million for Stockfish and 35 million for elmo. AlphaZero compensates for the lower number of evaluations by using its deep neural network to focus much more selectively on the most promising variation.<ref name=preprint/>

==Training==
AlphaZero was trained solely via self-play, using 5,000 first-generation TPUs to generate the games and 64 second-generation TPUs to train the [[neural network]]s. In parallel, the in-training AlphaZero was periodically matched against its benchmark (Stockfish, elmo, or AlphaGo Zero) in brief one-second-per-move games to determine how well the training was progressing. DeepMind judged that AlphaZero's performance exceeded the benchmark after around four hours of training for Stockfish, two hours for elmo, and eight hours for AlphaGo Zero.<ref name=preprint/>

==Preliminary results==
===Outcome===
====Chess====
In AlphaZero's chess tournament against Stockfish 8 (2016 [[Top Chess Engine Championship|TCEC]] world champion), each program was given one minute's worth of thinking time per move. Stockfish was allocated 64 threads and a [[Hash table|hash]] size of 1 GB,<ref name=preprint/> a setting that Stockfish's Tord Romstad later criticized as suboptimal.<ref name=romstad/>{{refn|group=note|Stockfish developer Tord Romstad responded with <blockquote>The match results by themselves are not particularly meaningful because of the rather strange choice of time controls and Stockfish parameter settings: The games were played at a fixed time of 1 minute/move, which means that Stockfish has no use of its time management heuristics (lot of effort has been put into making Stockfish identify critical points in the game and decide when to spend some extra time on a move; at a fixed time per move, the strength will suffer significantly). The version of Stockfish used is one year old, was playing with far more search threads than has ever received any significant amount of testing, and had way too small hash tables for the number of threads. I believe the percentage of draws would have been much higher in a match with more normal conditions.<ref name=romnak>{{cite web|url=https://www.chess.com/news/view/alphazero-reactions-from-top-gms-stockfish-author|title=AlphaZero: Reactions From Top GMs, Stockfish Author|publisher=[[chess.com]]|date=8 December 2017|accessdate=13 December 2017}}</ref></blockquote>}} AlphaZero was trained on chess for a total of nine hours before the tournament. During the tournament, AlphaZero ran on a single machine with four application-specific [[Tensor processing unit|TPU]]s. In 100 games from the normal starting position, AlphaZero won 25 games as White, won 3 as Black, and drew the remaining 72.<ref name=bbc>{{cite news|title='Superhuman' Google AI claims chess crown|url=https://www.bbc.com/news/technology-42251535|accessdate=7 December 2017|work=BBC News|date=6 December 2017}}</ref> In a series of twelve 100-game matches (of unspecified time or resource constraints) against Stockfish starting from the 12 most popular human openings, AlphaZero won 290, drew 886 and lost 24.<ref name="preprint"/>

====Shogi====
AlphaZero was trained on shogi for a total of two hours before the tournament. In 100 shogi games against elmo (World Computer Shogi Championship 27 summer 2017 tournament version with YaneuraOu 4.73 search), AlphaZero won 90 times, lost 8 times and drew twice.<ref name=bbc/> As in the chess games, each program got one minute per move, and elmo was given 64 threads and a hash size of 1&nbsp;GB.<ref name=preprint/>

====Go====
After 34 hours of self-learning of Go and against AlphaGo Zero, AlphaZero won 60 games and lost 40.<ref name=preprint/><ref name=bbc/>

===Analysis===
DeepMind stated in its preprint that "The game of chess represented the pinnacle of AI research over several decades. State-of-the-art programs are based on powerful engines that search many millions of positions, leveraging handcrafted domain expertise and sophisticated domain adaptations. AlphaZero is a generic [[reinforcement learning]] algorithm{{snd}} originally devised for the game of go{{snd}} that achieved superior results within a few hours, searching a thousand times fewer positions, given no domain knowledge except the rules."<ref name=preprint/> DeepMind's [[Demis Hassabis]], a chess player himself, called AlphaZero's play style "alien": It sometimes wins by offering counterintuitive sacrifices, like offering up a queen and bishop to exploit a positional advantage. "It's like chess from another dimension."<ref>{{cite news|last1=Knight|first1=Will|title=Alpha Zero's "Alien" Chess Shows the Power, and the Peculiarity, of AI|url=https://www.technologyreview.com/s/609736/alpha-zeros-alien-chess-shows-the-power-and-the-peculiarity-of-ai/|accessdate=11 December 2017|work=[[MIT Technology Review]]|date=8 December 2017|language=en}}</ref>

Given the difficulty in chess of [[First-move_advantage_in_chess#Drawn_with_best_play|forcing a win against a strong opponent]], the +28 –0 =72 result is a significant margin of victory. However, some grandmasters, such as [[Hikaru Nakamura]] and [[Komodo (chess)|Komodo]] developer [[Larry Kaufman]], downplayed AlphaZero's victory, arguing that the match would have been closer if the programs had access to an [[Chess opening|opening]] database (since Stockfish was optimized for that scenario).<ref name=chess.com>{{cite news|title=Google's AlphaZero Destroys Stockfish In 100-Game Match|url=https://www.chess.com/news/view/google-s-alphazero-destroys-stockfish-in-100-game-match|accessdate=7 December 2017|work=[[Chess.com]]}}</ref> Romstad additionally pointed out that Stockfish is not optimized for rigidly fixed-time moves and the version used is a year old.<ref name=romstad>{{cite web|url=https://www.chess.com/news/view/alphazero-reactions-from-top-gms-stockfish-author|title=AlphaZero: Reactions From Top GMs, Stockfish Author|publisher=[[chess.com]]|date=8 December 2017|accessdate=9 December 2017}}</ref><ref>Katyanna Quach. [https://www.theregister.co.uk/2017/12/14/deepmind_alphazero_ai_unfair "DeepMind's AlphaZero AI clobbered rival chess app on non-level playing...board"]. The Register (December 14, 2017).</ref>

Similarly, some shogi observers argued that the elmo hash size was too low, that the resignation settings and the "EnteringKingRule" settings (cf. [[Shogi#Entering_King|shogi § Entering King]]) may have been inappropriate, and that elmo is already obsolete compared with newer programs.<ref>{{cite web|title=Some concerns on the matching conditions between AlphaZero and Shogi engine|url=http://www.uuunuuun.com/single-post/2017/12/07/Some-concerns-on-the-matching-conditions-between-AlphaZero-and-Shogi-engine|website=コンピュータ将棋 レーティング|publisher="uuunuuun" (a blogger who rates free shogi engines)|accessdate=9 December 2017}} (via {{cite news|title=瀧澤 誠@elmo (@mktakizawa) {{!}} Twitter|url=https://twitter.com/mktakizawa|accessdate=11 December 2017|work=mktakizawa (elmo developer)|date=9 December 2017|language=en}})</ref><ref>{{cite web|title=DeepMind社がやねうら王に注目し始めたようです|url=http://yaneuraou.yaneu.com/2017/12/07/deepmind%E7%A4%BE%E3%81%8C%E3%82%84%E3%81%AD%E3%81%86%E3%82%89%E7%8E%8B%E3%81%AB%E6%B3%A8%E7%9B%AE%E3%81%97%E5%A7%8B%E3%82%81%E3%81%9F%E3%82%88%E3%81%86%E3%81%A7%E3%81%99/|publisher=The developer of YaneuraOu, a search component used by elmo|accessdate=9 December 2017|date=7 December 2017}}</ref>

===Reaction and criticism===
Papers headlined that the chess training took only four hours: "It was managed in little more than the time between breakfast and lunch."<ref name=telegraph/><ref name=tol>{{cite news|last1=Badshah|first1=Nadeem|title=Google's DeepMind robot becomes world-beating chess grandmaster in four hours|url=https://www.thetimes.co.uk/article/google-s-deepmind-alphazero-becomes-world-beating-chess-grandmaster-in-four-hours-hcppp9vr2|accessdate=7 December 2017|work=[[The Times of London]]|date=7 December 2017}}</ref> ''[[Wired (magazine)|Wired]]'' hyped AlphaZero as "the first multi-skilled AI board-game champ".<ref>{{cite news|title=Alphabet's Latest AI Show Pony Has More Than One Trick|url=https://www.wired.com/story/alphabets-latest-ai-show-pony-has-more-than-one-trick/|accessdate=7 December 2017|date=6 December 2017|work=WIRED}}</ref> AI expert Joanna Bryson noted that Google's "knack for good publicity" was putting it in a strong position against challengers. "It's not only about hiring the best programmers. It's also very political, as it helps make Google as strong as possible when negotiating with governments and regulators looking at the AI sector."<ref name=bbc/>

Human chess grandmasters were very impressed by AlphaZero. Danish grandmaster [[Peter Heine Nielsen]] likened AlphaZero's play to that of a superior alien species.<ref name=bbc/> Norwegian grandmaster [[Jon Ludvig Hammer]] characterized AlphaZero's play as "insane attacking chess" with profound positional understanding.<ref name=telegraph/> Former [[World chess champion|champion]] [[Garry Kasparov]] said "It's a remarkable achievement, even if we should have expected it after AlphaGo."<ref name=chess.com/><ref>{{cite news|last1=Gibbs|first1=Samuel|title=AlphaZero AI beats champion chess program after teaching itself in four hours|url=https://www.theguardian.com/technology/2017/dec/07/alphazero-google-deepmind-ai-beats-champion-program-teaching-itself-to-play-four-hours|accessdate=8 December 2017|work=The Guardian|date=7 December 2017}}</ref>

Grandmaster [[Hikaru Nakamura]] was less impressed, and stated "I don't necessarily put a lot of credibility in the results simply because my understanding is that AlphaZero is basically using the Google supercomputer and Stockfish doesn't run on that hardware; Stockfish was basically running on what would be my laptop. If you wanna have a match that's comparable you have to have Stockfish running on a supercomputer as well."<ref name=romnak/>

Top US correspondence chess player [[Wolff Morrow]] was also unimpressed, claiming that AlphaZero would probably not make the semifinals of a fair competition such as [[TCEC]] where all engines play on equal hardware. Morrow further stated that although he might not be able to beat AlphaZero if AlphaZero played drawish openings such as the [[Petroff Defence]], AlphaZero would not be able to beat him in a [[correspondence chess]] game either.<ref>{{cite web|url=https://en.chessbase.com/post/correspondence-chess-and-correspondence-database-2018|title=Talking modern correspondence chess|publisher=Chessbase|date=26 June 2018|accessdate=11 July 2018}}</ref>

Motohiro Isozaki, the author of YaneuraOu, noted that although AlphaZero did comprehensively beat elmo, the rating of AlphaZero in shogi stopped growing at a point which is at most 100~200 higher than elmo. This gap is not that high, and elmo and other shogi software should be able to catch up in 1–2 years.<ref>[http://yaneuraou.yaneu.com/2017/12/07/deepmind%E7%A4%BE%E3%81%8C%E3%82%84%E3%81%AD%E3%81%86%E3%82%89%E7%8E%8B%E3%81%AB%E6%B3%A8%E7%9B%AE%E3%81%97%E5%A7%8B%E3%82%81%E3%81%9F%E3%82%88%E3%81%86%E3%81%A7%E3%81%99/ DeepMind社がやねうら王に注目し始めたようです | やねうら王 公式サイト], 2017年12月7日</ref>

==Final results==
DeepMind addressed many of the criticisms in their final version of the paper, published in December 2018 in ''[[Science (journal)|Science]]''.<ref name="Science20181207" /> They further clarified that AlphaZero was not running on a supercomputer; it was trained using 5,000 [[tensor processing units]] (TPUs), but only ran on four TPUs and a 44-core CPU in its matches.<ref>As given in the ''Science'' paper, a TPU is "roughly similar in inference speed to a Titan V GPU, although the architectures are not directly comparable" (Ref. 24).</ref>

===Chess===
In the final results, Stockfish ran under the same conditions as in the [[Top Chess Engine Championship|TCEC]] superfinal: 44 CPU cores, Syzygy endgame tablebases, and a 32GB hash size. Instead of a fixed [[time control]] of one move per minute, both engines were given 3 hours plus 15 seconds per move to finish the game. The version of Stockfish used was version 8. In a 1000-game match, AlphaZero won with a score of 155 wins to 6 losses, with the rest drawn. DeepMind also played a series of games using the TCEC opening positions; AlphaZero also won convincingly.

===Shogi===
Similar to Stockfish, Elmo ran under the same conditions as in the 2017 CSA championship. The version of Elmo used was WCSC27 in combination with YaneuraOu 2017 Early KPPT 4.79 64AVX2 TOURNAMENT. Elmo operated on the same hardware as Stockfish: 44 CPU cores and a 32GB hash size. AlphaZero won 98.2% of games when playing black (which plays first in shogi) and 91.2% overall.

===Reactions and criticisms===
Human grandmasters were generally impressed with AlphaZero's games against Stockfish.<ref>{{cite web|url=https://www.chess.com/news/view/updated-alphazero-crushes-stockfish-in-new-1-000-game-match|title=AlphaZero Crushes Stockfish In New 1,000-Game Match|publisher=Chess.com|date=6 December 2018}}</ref> Former world champion [[Garry Kasparov]] said it was a pleasure to watch AlphaZero play, especially since it plays in an open and dynamic style, as he does.<ref>{{cite web|url=https://www.theguardian.com/sport/2018/dec/11/creative-alphazero-leads-way-chess-computers-science|title='Creative' AlphaZero leads way for chess computers and, maybe, science|publisher=The Guardian|date=11 December 2018|author=Sean Ingle}}</ref><ref>{{cite web|url=https://en.chessbase.com/post/the-full-alphazero-paper-is-published-at-long-last|title=Inside the (deep) mind of AlphaZero|author=Albert Silver|publisher=Chessbase|date=7 December 2018}}</ref>

Reactions from the computer chess community were more muted.{{cn|date=February 2019}} [[Komodo (chess)|Komodo]] developer Mark Lefler called it a "pretty amazing achievement", but also pointed out that the data is old, since Stockfish has gained a lot in strength in the months since January 2018 (when Stockfish 8 was released). Fellow developer Larry Kaufman went further and claimed that AlphaZero would probably lose a match against the latest version of Stockfish, Stockfish 10, under TCEC conditions. Kaufman argued that the only advantage of neural network–based engines was that they used a GPU, so if one doesn't care about power consumption (e.g. in an equal-hardware contest where both engines have access to the same CPU and GPU) then anything the GPU achieves is "free". Based on this, he stated that the strongest engine is likely to be a hybrid that uses both neural networks and standard [[alpha–beta search]].<ref>{{cite web|url=http://www.chessdom.com/komodo-mcts-monte-carlo-tree-search-is-the-new-star-of-tcec/|title=Komodo MCTS (Monte Carlo Tree Search) is the new star of TCEC|publisher=Chessdom|date=18 December 2018}}</ref>

Nonetheless, AlphaZero inspired the computer chess community to develop [[Leela Chess Zero]], using the same techniques as AlphaZero. Leela would go on to contest several championships against Stockfish, where it has proven to be of comparable strength.<ref>See [[TCEC]] and [[Leela Chess Zero]].</ref>

==See also==
*[[Leela Chess Zero]]
*[[General game playing]]

==Notes==
{{reflist|group=note}}

==References==
{{Reflist}}

==External links==
* [https://www.chessprogramming.org/AlphaZero Chessprogramming wiki on AlphaZero]
* [https://www.youtube.com/watch?v=akgalUq5vew&list=PL-qLOQ-OEls607FPLAsPZ6De4f1W3ZF-I Chess.com Youtube playlist for AlphaZero vs. Stockfish]

[[Category:2017 software]]
[[Category:Artificial intelligence applications]]
[[Category:2017 in chess]]
[[Category:2017 in go]]
[[Category:Applied machine learning]]
[[Category:AlphaGo]]
[[Category:Shogi software]]
[[Category:Chess engines]]
[[Category:Go software (game)]]
[[Category:Google]]