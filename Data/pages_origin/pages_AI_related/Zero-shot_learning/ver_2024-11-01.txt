{{Short description|Problem setup in machine learning}}

'''Zero-shot learning''' ('''ZSL''') is a problem setup in [[deep learning]] where, at test time, a learner observes samples from classes which were ''not'' observed during [[Machine learning#Training models|training]], and needs to predict the class that they belong to. The name is a play on words based on the earlier concept of [[One-shot learning in computer vision|one-shot learning]], in which classification can be learned from only one, or a few, examples.

Zero-shot methods generally work by associating observed and non-observed classes through some form of auxiliary information, which encodes observable distinguishing properties of objects.<ref>{{cite arXiv|last1=Xian|first1=Yongqin|last2=Lampert|first2=Christoph H.|last3=Schiele|first3=Bernt|last4=Akata|first4=Zeynep|date=2020-09-23|title=Zero-Shot Learning -- A Comprehensive Evaluation of the Good, the Bad and the Ugly|class=cs.CV|eprint=1707.00600}}</ref> For example, given a set of images of animals to be classified, along with auxiliary textual descriptions of what animals look like, an artificial intelligence model which has been trained to recognize horses, but has never been given a zebra, can still recognize a zebra when it also knows that zebras look like striped horses. This problem is widely studied in [[computer vision]], [[natural language processing]], and [[machine perception]].<ref>{{cite journal |last1=Xian |first1=Yongqin |last2=Schiele |first2=Bernt |last3=Akata |first3=Zeynep |title=Zero-shot learning-the good, the bad and the ugly |journal=Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition |date=2017 |pages=4582–4591|bibcode=2017arXiv170304394X |arxiv=1703.04394 }}</ref>

== Background and history ==
The first paper on zero-shot learning in natural language processing appeared in a 2008 paper by Chang, Ratinov, Roth, and Srikumar, at the [[Association for the Advancement of Artificial Intelligence|AAAI’08]], but the name given to the learning paradigm there was ''dataless classification''.<ref name=":0">{{cite journal |last1=Chang |first1=M.W. |date=2008 |title=Importance of Semantic Representation: Dataless Classification |url=https://citeseerx.ist.psu.edu/document?doi=ee0a332b4fc1e82a9999acd6cebceb165dc8645b |journal=AAAI}}</ref> The first paper on zero-shot learning in computer vision appeared at the same conference, under the name ''zero-data learning''.<ref>{{Cite web|last=Larochelle|first=Hugo|date=2008|title=Zero-data Learning of New Tasks|url=https://www.aaai.org/Papers/AAAI/2008/AAAI08-103.pdf}}</ref> The term ''zero-shot learning'' itself first appeared in the literature in a 2009 paper from Palatucci, Hinton, Pomerleau, and Mitchell at [[Neural Information Processing Systems|NIPS’09]].<ref>{{Cite journal|last=Palatucci|first=Mark|date=2009|title=Zero-Shot Learning with Semantic Output Codes|url=https://www.cs.toronto.edu/~hinton/absps/palatucci.pdf|journal=NIPS}}</ref> This terminology was repeated later in another computer vision paper<ref name=":1" /> and the term ''zero-shot learning'' caught on, as a take-off on [[one-shot learning in computer vision|''one-shot learning'' that was introduced in computer vision]] years earlier.<ref>{{Cite journal|last=Miller|first=E. G.|date=2000|title=Learning from One Example Through Shared Densities on Transforms|url=https://people.cs.umass.edu/~elm/papers/cvpr2000.pdf|journal=CVPR}}</ref> 

In computer vision, zero-shot learning models learned parameters for seen classes along with their class representations and rely on representational similarity among class labels so that, during inference, instances can be classified into new classes.

In natural language processing, the key technical direction developed builds on the ability to "understand the labels"—represent the labels in the same semantic space as that of the documents to be classified. This supports the classification of a ''single example'' without observing any annotated data, the purest form of zero-shot classification. The original paper<ref name=":0" /> made use of the [[Explicit semantic analysis|Explicit Semantic Analysis]] (ESA) representation but later papers made use of other representations, including dense representations. This approach was also extended to multilingual domains,<ref>{{Cite journal|last=Song|first=Yangqiu|date=2019|title=Toward any-language zero-shot topic classification of textual documents|journal=Artificial Intelligence|volume=274|pages=133–150|doi=10.1016/j.artint.2019.02.002|doi-access=free}}</ref><ref>{{Cite journal|last=Song|first=Yangqiu|date=2016|title=Cross-Lingual Dataless Classification for Many Languages|url=https://www.ijcai.org/Proceedings/16/Papers/412.pdf|journal=IJCAI}}</ref> fine entity typing<ref name=":2">{{Cite journal|last=Zhou|first=Ben|date=2018|title=Zero-Shot Open Entity Typing as Type-Compatible Grounding|url=https://www.aclweb.org/anthology/D18-1231.pdf|journal=EMNLP|arxiv=1907.03228}}</ref> and other problems. Moreover, beyond relying solely on representations, the computational approach has been extended to depend on transfer from other tasks, such as [[textual entailment]]<ref>{{Cite journal|last=Yin|first=Wenpeng|date=2019|title=Benchmarking Zero-shot Text Classification: Datasets, Evaluation and Entailment Approach|url=https://www.aclweb.org/anthology/D19-1404.pdf|journal=EMNLP|arxiv=1909.00161}}</ref> and question answering.<ref>{{Cite journal|last=Levy|first=Omer|date=2017|title=Zero-Shot Relation Extraction via Reading Comprehension|url=https://www.aclweb.org/anthology/K17-1034.pdf|journal=CoNLL|arxiv=1706.04115}}</ref>

The original paper<ref name=":0" /> also points out that, beyond the ability to classify a single example, when a collection of examples is given, with the assumption that they come from the same distribution, it is possible to bootstrap the performance in a semi-supervised like manner (or [[Transduction (machine learning)|transductive learning]]).  

Unlike standard [[Generalization error|generalization]] in machine learning, where classifiers are expected to correctly classify new samples to classes they have already observed during training, in ZSL, no samples from the classes have been given during training the classifier. It can therefore be viewed as an extreme case of [[domain adaptation]].

== Prerequisite information for zero-shot classes ==
Naturally, some form of auxiliary information has to be given about these zero-shot classes, and this type of information can be of several types. 

* Learning with attributes: classes are accompanied by pre-defined structured description. For example, for bird descriptions, this could include "red head", "long beak".<ref name=":1">{{cite journal |last1=Lampert |first1=C.H. |title=Learning to detect unseen object classes by between-class attribute transfer |journal=IEEE Conference on Computer Vision and Pattern Recognition |date=2009 |pages=951–958|citeseerx=10.1.1.165.9750 |url=http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.165.9750&rep=rep1&type=pdf}}</ref><ref>{{cite journal |last1=Romera-Paredes |first1=Bernardino |last2=Torr |first2=Phillip |title=An embarrassingly simple approach to zero-shot learning |journal=International Conference on Machine Learning |date=2015 |pages=2152–2161|url=http://www.jmlr.org/proceedings/papers/v37/romera-paredes15.pdf}}</ref> These attributes are often organized in a structured compositional way, and taking that structure into account improves learning.<ref>{{cite journal |last1=Atzmon |first1=Yuval |last2=Chechik |first2=Gal |title=Probabilistic AND-OR Attribute Grouping for Zero-Shot Learning |journal=Uncertainty in Artificial Intelligence |date=2018 |url=http://auai.org/uai2018/proceedings/papers/151.pdf|bibcode=2018arXiv180602664A |arxiv=1806.02664 }}</ref> While this approach was used mostly in computer vision, there are some examples for it also in natural language processing.<ref>{{Cite journal|last=Roth|first=Dan|date=2009|title=Aspect Guided Text Categorization with Unobserved Labels|url=http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.148.9946&rep=rep1&type=pdf|journal=ICDM|citeseerx=10.1.1.148.9946}}</ref>
* Learning from textual description. As pointed out above, this has been the key direction pursued in natural language processing. Here class labels are taken to have a meaning and are often augmented with definitions or free-text natural-language description. This could include for example a wikipedia description of the class.<ref name=":2" /><ref>{{cite journal |last1=Hu |first1=R Lily |last2=Xiong |first2=Caiming |last3=Socher |first3=Richard |title=Zero-Shot Image Classification Guided by Natural Language Descriptions of Classes: A Meta-Learning Approach |journal=NeurIPS |date=2018|url=https://nips2018vigil.github.io/static/papers/accepted/28.pdf}}</ref><ref>{{cite book |last1=Srivastava |first1=Shashank |last2=Labutov |first2=Igor |last3=Mitchelle |first3=Tom  |title=Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) |chapter=Zero-shot Learning of Classifiers from Natural Language Quantification |year=2018 |pages=306–316 |doi=10.18653/v1/P18-1029 |doi-access=free }}</ref>
* Class-class similarity. Here, classes are embedded in a continuous space. A zero-shot classifier can predict that a sample corresponds to some position in that space, and the nearest embedded class is used as a predicted class, even if no such samples were observed during training.<ref>{{cite journal |last1=Frome |first1=Andrea |last2=et |first2=al |title=Devise: A deep visual-semantic embedding model |journal=Advances in Neural Information Processing Systems |date=2013 |pages=2121–2129|url=https://papers.nips.cc/paper/5204-devise-a-deep-visual-semantic-embedding-model.pdf}}</ref>

== Generalized zero-shot learning ==
The above ZSL setup assumes that at test time, only zero-shot samples are given, namely, samples from new unseen classes. In generalized zero-shot learning, samples from both new and known classes, may appear at test time. This poses new challenges for classifiers at test time, because it is very challenging to estimate if a given sample is new or known. Some approaches to handle this include: 

* a gating module, which is first trained to decide if a given sample comes from a new class or from an old one, and then, at inference time, outputs either a hard decision,<ref>{{cite journal |last1=Socher |first1=R |last2=Ganjoo |first2=M |last3=Manning |first3=C.D. |last4=Ng |first4=A. |title=Zero-shot learning through cross-modal transfer |journal=Neural Information Processing Systems |date=2013|bibcode=2013arXiv1301.3666S |arxiv=1301.3666 }}</ref> or a soft probabilistic decision<ref>{{cite journal |last1=Atzmon |first1=Yuval |title=Adaptive Confidence Smoothing for Generalized Zero-Shot Learning |journal=The IEEE Conference on Computer Vision and Pattern Recognition|pages=11671–11680 |date=2019|bibcode=2018arXiv181209903A |arxiv=1812.09903 }}</ref>
* a generative module, which is trained to generate feature representation of the unseen classes--a standard classifier can then be trained on samples from all classes, seen and unseen.<ref>{{cite journal |last1=Felix |first1=R |last2=et |first2=al |title=Multi-modal cycle-consistent generalized zero-shot learning |journal=Proceedings of the European Conference on Computer Vision |date=2018 |pages=21–37|bibcode=2018arXiv180800136F |arxiv=1808.00136 }}</ref>

== Domains of application ==
Zero shot learning has been applied to the following fields:
* [[image classification]]
* [[semantic segmentation]]
* [[Artificial intelligence art|image generation]]
* [[object detection]]
* [[natural language processing]]
* [[computational biology]]<ref>{{Cite journal |last1=Wittmann |first1=Bruce J. |last2=Yue |first2=Yisong |last3=Arnold |first3=Frances H. |date=2020-12-04 |title=Machine Learning-Assisted Directed Evolution Navigates a Combinatorial Epistatic Fitness Landscape with Minimal Screening Burden |url=https://www.biorxiv.org/content/10.1101/2020.12.04.408955v1 |language=en |pages=2020.12.04.408955 |doi=10.1101/2020.12.04.408955|s2cid=227914824 }}</ref>

== See also ==
* [[One-shot learning in computer vision]]
* [[Transfer learning]]
* [[Fast mapping]]
* [[Explanation-based learning]]

== References ==
{{reflist}}

[[Category:Machine learning algorithms]]
[[Category:Computer vision]]