{{Use dmy dates|date=August 2012}}
'''Document mosaicing''' is a process that [[image stitching|stitches]] multiple, overlapping [[wikt:snaphot|snapshot]] images of a document together to produce one large, high resolution composite. The document is slid under a stationary, over-the-desk camera by hand until all parts of the document are snapshotted by the camera’s field of view. As the document slid under the camera, all motion of the document is coarsely tracked by the vision system. The document is periodically snapshotted such that the successive snapshots are overlap by about 50%. The system then finds the overlapped pairs and stitches them together repeatedly until all pairs are stitched together as one piece of document.<ref name="MyRef2">{{cite journal |title=Document mosaicing |journal=Image and Vision Computing |year=1999 |doi=10.1016/S0262-8856(98)00178-4 |volume=17 |issue=8 |pages=589–595|last1=Zappalá |first1=Anthony |last2=Gee |first2=Andrew |last3=Taylor |first3=Michael }}</ref>

The document mosaicing can be divided into four main processes.
*Tracking
*[[Feature detection (computer vision)|Feature detecting]]
*Correspondences establishing
*Images mosaicing.

==Tracking (simple correlation process)==
<!-- Deleted image removed: [[File:Document tracking.png|thumb|'''Figure 1''' : The correlation pattern mirrors the text rows. The template is continuously updated so that an incorrect correlation peak results in mild tracking inaccuracy and not total failure.<ref name="MyRef2" />]] -->
In this process, the motion of the document slid under the camera is coarsely tracked by the system. Tracking is performed by a process called simple [[correlation]] process. In the first frame of snapshots, a small patch is extracted from the center of the image as a correlation template as shown in Figure 1. The correlation process is performed in the four times size of the patch area of the next frame. The motion of the paper is indicated by the peak in the correlation function. The peak in the correlation function indicates the motion of the paper. The template is resampled from this frame and the tracking continues until the template reaches the edge of the document. After the template reaches the edge of the document, another snapshot is taken and the tracking process performs repeatedly until the whole document is imaged. The snapshots are stored in an ordered list to facilitate pairing the overlapped images in later processes.

==Feature detecting for efficient matching==
Feature detection is the process of finding the transformation that aligns one image with another. There are two main approaches for feature detection.<ref name="MyRef3">{{cite journal |last=Mann |first=S. |last2=Picard |first2=R. W. |title=Video orbits of the projective group: A new perspective on image mosaicing |journal=Technical Report (Perceptual Computing Section), MIT Media Laboratory |year=1995 |issue=338 |citeseerx=10.1.1.56.6000}}</ref><ref name="MyRef4">{{cite journal |last=Brown |first=L.G. |year=1992 |title=A survey of image registration techniques |journal=ACM Computing Surveys |volume=24 |issue=4 |pages=325–376 |doi=10.1145/146370.146374 |citeseerx=10.1.1.35.2732}}</ref>

{{multiple image
 |direction=vertical
 |width=300
 |image1=
 |caption1='''Figure 2''' : Skew Angle process rotates the text from its original orientation (a) until the variance of the grey levels summed along the image raster lines is maximized (b). (c) shows the results on a real image, where the central portion of text has been de-skewed.<ref name="MyRef2" />
 |image2=
 |caption2='''Figure 3''' : Binary [[Image gradient]] is done to reduce sensitivity to lighting conditions and page coloration, a [[Sobel operator]] is applied to the original images (a). The binary gradient image is produced by thresholding the absolute value of the output (b).<ref name="MyRef2" />
 }}
* '''Feature-based approach''' : Motion parameters are estimated from point correspondences. This approach is suitable for the case that there is plenty supply of stable and detectable features.
* '''Featureless approach''' : When the motion between the two images is small, the motion parameters are estimated using [[optical flow]]. On the other hand, when the motion between the two images is large, the motion parameters are estimated using generalised [[cross-correlation]]. However, this approach requires a computationally expensive resources.

Each image is [[Image segmentation|segmented]] into a hierarchy of columns, lines, and words to match the organised sets of features across images. Skew angle estimation and columns, lines and words finding are the examples of feature detection operations.

===Skew angle estimation===

Firstly, the angle that the rows of text make with the image [[Raster graphics|raster]] lines (skew angle) is estimated. It is assumed to lie in the range of ±20°. A small patch of text in the image is selected randomly and then rotated in the range of ±20° until the variance of the pixel intensities of the patch summed along the raster lines is maximised.<ref name="MyRef5">
{{cite book
 |last1=Bloomberg |first1=Dan S.
 |last2=Kopec |first2=Gary E.
 |last3=Dasari |first3=Lakshmi
 |year=1995
 |chapter=Measuring document image skew and orientation
 |title=Document Recognition II
 |chapter-url=http://www.leptonica.com/papers/skew-measurement.pdf
 |series=Proceedings of the SPIE
 |volume=2422 |pages=302–315
 |bibcode=1995SPIE.2422..302B
 |doi=10.1117/12.205832
|editor1-last=Vincent
 |editor1-first=Luc M
 |editor2-last=Baird
 |editor2-first=Henry S
 }}</ref> See Figure 2.

To ensure that the found skew angle is accurate, the document mosaic system performs calculation at many image patches and derive the final estimation by finding the average of the individual angles weighted by the variance of the pixel intensities of each patch.

===Columns, lines and words finding===

In this operation, the de-skewed document is intuitively segmented into a hierarchy of columns, lines and words. The sensitivity to illumination and page coloration of the de-skewed document can be removed by applying a [[Sobel operator]] to the de-skewed image and thresholding the output to obtain the binary gradient, de-skewed image.<ref name="MyRef6">{{Cite journal |doi=10.1016/S0262-8856(98)00155-3 |title=Documents through cameras |journal=Image and Vision Computing |volume=17 |issue=11 |pages=831–844 |year=1999 |last1=Taylor |first1=M. J. |last2=Zappala |first2=A. |last3=Newman |first3=W. M. |last4=Dance |first4=C. R.}}</ref> See Figure 3.

The operation can be roughly separated into 3 steps: column segmentation, line segmentation and word segmentation.

# Columns are easily segmented from the binary [[gradient]], de-skewed images by summing pixels vertically as shown in Figure 4.
# Baselines of each row are segmented in the same way as the column segmentation process but horizontally.
# Finally, individual words are segmented by applying the vertical process at each segmented row.

These segmentations are important because the document mosaic is created by matching the lower right corners of words in overlapping images pair. Moreover, the segmentation operation can organize the list of images in the context of a hierarchy of rows and column reliably.

The segmentation operation involves a considerable amount of summing in the binary [[gradient]], de-skewed images, which done by construct a matrix of partial sums<ref name="MyRef7">{{cite book |last=Preparata |first=F.P. |last2=Shamos |first2=M. I. |title=Computational Geometry: An Introduction |publisher=Springer–Verlag |series=Monographs in Computer Science |url=https://archive.org/details/computationalgeo0000prep |year=1985 |isbn=9780387961316 |url-access=registration }}</ref> whose elements are given by

<math>p_{iy}=\sum_{u=1}^{i}\sum_{v=1}^{j}b_{uv}</math>
 
The matrix of partial sums is calculated in one pass through the binary [[gradient]], de-skewed image.<ref name="MyRef7" />

<math>\sum_{u=u_{1}}^{u_{2}}\sum_{v=v_{1}}^{v_{2}}b_{uv}=p_{u_{2}v_{2}}+p_{u_{1}v_{1}}-p_{u_{1}v_{2}}-p_{u_{2}v_{1}}</math>

==Correspondences establishing==
The two images are now organized in hierarchy of linked lists in following structure :
* image=list of columns
* row=list of words
* column=list of row
* word=length (in pixels)

At the bottom of the structure, the length of each word is recorded for establishing correspondence between two images to reduce to search only the corresponding structures for the groups of words with the matching lengths.

===Seed match finding===

A seed match finding is done by comparing each row in image1 with each row in image2. The two rows are then compared to each other by every word. If the length (in pixel) of the two words (one from image1 and one from image2) and their immediate neighbours agree with each other within a predefined tolerance threshold (5 pixels, for example), then they are assumed to match. The row of each image is assumed a match if there are three or more word matches between the two rows. The seed match finding operation is terminated when two pairs of consecutive row match are found.

===Match list building===

After finishing a seed match finding operation, the next process is to build the match list to generate the correspondences points of the two images. The process is done by searching the matching pairs of rows away from the seed row.

==Images mosaicing==
[[File:Mosaicing.png|thumb|'''Figure 5''' : Mosaicing of two document images. Blurring is evident in the affine mosaic (b), but not in the mosaic constructed using a plane-to-plane projectivity (a). Close-ups of typical seams of (a) and (b) are shown in (c) and (d) respectively.<ref name="MyRef2" />]]

Given the list of corresponding points of the two images, finding the transformation of the overlapping portion of the images is the next process. Assuming a [[pinhole camera]] model, the transformation between pixels (u,v) of image 1 and pixels (u0, v0) of image 2 is demonstrated by a plane-to-plane projectivity.<ref name="MyRef8">{{cite book |last=Mundy |first=J.L. |last2=Zisserman |first2=A. |chapter=Appendix-Projective geometry for machine vision |title=Geometric Invariance in Computer Vision |chapter-url=https://archive.org/details/GeometricI_00_Mund |chapter-url-access=registration |publisher=MIT Press |location=Cambridge MA |year=1992 |citeseerx=10.1.1.17.1329}}</ref>

<math>
\left[\begin{array}{c}
su'\\
sv'\\
s
\end{array}\right]=\left[\begin{array}{ccc}
p_{11} & p_{12} & p_{13}\\
p_{21} & p_{22} & p_{23}\\
p_{31} & p_{32} & 1
\end{array}\right]\left[\begin{array}{c}
u\\
v\\
1
\end{array}\right]
  \qquad Eq.1
</math>

The parameters of the projectivity is found from four pairs of matching points. RANSAC regression<ref name="MyRef9">{{cite journal |author=Martin A. Fischler |author2=Robert C. Bolles 
|title=Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography |journal=[[Communications of the ACM]] |url=http://www.ai.sri.com/pubs/files/836.pdf |volume=24 |issue=6 |pages=381–395 |year=1981 |doi=10.1145/358669.358692}}</ref> technique is used to reject outlying matches and estimate the projectivity from the remaining good matches.

The projectivity is fine-tuned using correlation at the corners of the overlapping portion to obtain four correspondences to sub-pixel accuracy. Therefore, image1 is then transformed into image2’s coordinate system using Eq.1. The typical result of the process is shown in Figure 5.

===Many images coping===

Finally, the whole page composition is built up by mapping all the images into the coordinate system of an “anchor” image, which is normally the one nearest the page center. The transformations to the anchor frame are calculated by concatenating the pair-wise transformations found earlier. The raw document mosaic is shown in Figure 6.

However, there might be a problem of non-consecutive images that are overlap. This problem can be solved by performing Hierarchical sub-mosaics. As shown in Figure 7, image1 and image2 are registered, as are image3 and image4, creating two sub-mosaics. These two sub-mosaics are later stitched together in another mosaicing process.

==Applied areas==
There are various areas that the technique of document mosaicing can be applied to such as :  
*Text segmentation of images of documents<ref name="MyRef6"/>
*Document Recognition<ref name="MyRef5"/>
*Interaction with paper on the digital desk<ref name="MyRef10">{{cite journal |last=Wellner |first=P. |title=Interacting with paper on the digital desk |journal=Communications of the ACM |volume=36 |issue=7 |pages=87–97 |year=1993 |doi=10.1145/159544.159630 |citeseerx=10.1.1.53.7526}}</ref>
*Video mosaics for virtual environments<ref name="MyRef11">{{cite journal |last=Szeliski |first=R. |title=Video mosaics for virtual environments |journal=IEEE Computer Graphics and Applications |volume=16 |issue=2 |pages=22–306 |year=1996 |doi=10.1109/38.486677}}</ref>
*Image registration techniques<ref name="MyRef4"/>

==Relevant research papers==
*{{cite journal |doi = 10.1109/5.265351|title = Motion and structure from feature correspondences: A review|journal = Proceedings of the IEEE|volume = 82|issue = 2|pages = 252–268|year = 1994|last1 = Huang|first1 = T.S.|last2 = Netravali|first2 = A.N.}}
*D.G. Lowe. [http://dl.acm.org/citation.cfm?id=536946] Perceptual Organization and Visual Recognition. Kluwer Academic Publishers, Boston, 1985.
*{{cite journal |last1=Irani |first1=M. |last2=Peleg |first2=S. |year=1991 |title=Improving resolution by image registration |journal=CVGIP: Graphical Models and Image Processing |volume=53 |issue=3 |pages=231–239 |doi=10.1016/1049-9652(91)90045-L}}
*{{cite journal |last1=Shivakumara |first1=P. |last2=Kumar |first2=G. Hemantha |last3=Guru |first3=D. S. |last4=Nagabhushan |first4=P. |year=2006 |title=Sliding window based approach for document image mosaicing |url=http://dl.acm.org/citation.cfm?id=1709248.1709280 |journal= Image and Vision Computing|volume=24 |issue=1|pages=94–100 |doi=10.1016/j.imavis.2005.09.015}}
*[http://www.cfar.umd.edu/~daniel/daniel_papersfordownload/LiangICPR2006.pdf] Camera-Based Document Image Mosaicing. (n.d.). Image (Rochester, N.Y.), 1.
*{{cite journal |last1=Kumar |first1=G. H. |last2=Shivakumara |first2=P. |last3=Guru |first3=D. S. |last4=Nagabhushan |year=2004 |title=Document image mosaicing : A novel approach |url=http://www.ias.ac.in/sadhana/Pdf2004Jun/Pe1149.pdf |journal=Text |volume=29 |issue=3 |pages=329–341 |doi=10.1007/bf02703782 |citeseerx=10.1.1.107.4304 }}
*Sato, T., Ikeda, S., Kanbara, M., Iketani, A., Nakajima, N., Yokoya, N., & Yamada, K. (n.d.). [http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.1.8169 High-resolution Video Mosaicing for Documents and Photos by Estimating Camera Motion.] ''Mosaic A Journal For The Interdisciplinary Study Of Literature.''

==References==
<references/>

==Bibliography==
*{{cite journal |last=Anthony |first=Zappalá |author2=Andrew Gee|author3=Michael Taylor
|title=Document mosaicing |journal=Image and Vision Computing
|year=1999 |doi=10.1016/S0262-8856(98)00178-4 |volume=17 |issue=8 |pages=589–595}}

==External links==
*[http://www.inf.ed.ac.uk/teaching/courses/av/index.html Advanced Vision homepage]

<!--- Categories --->
[[Category:Computer vision]]
[[Category:Applications of computer vision]]
[[Category:Image processing]]
[[Category:Artificial intelligence]]