{{short description|artificial intelligence-based human image synthesis technique}}
{{Use dmy dates|date=July 2019}}
[[File:Deepfake example.gif|thumb|280px|An example of deepfake technology: actress [[Amy&nbsp;Adams]] in the original (left) is modified to have the face of actor [[Nicolas&nbsp;Cage]] (right)]]
'''Deepfakes''' (a [[portmanteau]] of "[[deep learning]]" and "fake"<ref name="FoxNews2018">{{Cite news |url=http://www.foxnews.com/tech/2018/02/16/terrifying-high-tech-porn-creepy-deepfake-videos-are-on-rise.html | title=Terrifying high-tech porn: Creepy 'deepfake' videos are on the rise | last=Brandon | first=John | date=2018-02-16 | work=Fox News | access-date=2018-02-20 | language=en-US}}</ref>) are media that take a person in an existing image or video and replace them with someone else's likeness using [[Artificial neural network|artificial neural networks]].<ref name=":3" /> They often combine and superimpose existing media onto source media using [[machine learning]] techniques known as [[Autoencoder|autoencoders]] and [[generative adversarial network]]<nowiki/>s (GANs).<ref name="Schwartz">{{cite news | last1=Schwartz |first1=Oscar | title=You thought fake news was bad? Deep fakes are where truth goes to die |url=https://www.theguardian.com/technology/2018/nov/12/deep-fakes-fake-news-truth | accessdate=14 November 2018 | work=The Guardian | date=12 November 2018 |language=en}}</ref><ref name=":14">{{Cite web|url=https://towardsdatascience.com/family-fun-with-deepfakes-or-how-i-got-my-wife-onto-the-tonight-show-a4454775c011|title=Family fun with deepfakes. Or how I got my wife onto the Tonight Show|last=PhD|first=Sven Charleer|date=2019-05-17|website=Medium|language=en|access-date=2019-11-08}}</ref> 

Deepfakes have garnered widespread attention for their uses in [[Celebrity sex tape|celebrity pornographic videos]], [[revenge porn]], [[fake news]], [[Hoax|hoaxes]], and [[Accounting scandals|financial fraud]].<ref name="HighSnobiety2018">{{Cite news |url=https://www.highsnobiety.com/p/what-are-deepfakes-ai-porn/ | title=What Are Deepfakes & Why the Future of Porn is Terrifying | date=2018-02-20 | work=Highsnobiety | access-date=2018-02-20 | language=en-US}}</ref><ref>{{cite web|url=https://theoutline.com/post/3179/deepfake-videos-are-freaking-experts-out|title=Experts fear face swapping tech could start an international showdown|website=The Outline|language=en|access-date=2018-02-28}}</ref><ref>{{Cite news|url=https://www.nytimes.com/2018/03/04/technology/fake-videos-deepfakes.html|title=Here Come the Fake Videos, Too|last=Roose|first=Kevin|date=2018-03-04|work=The New York Times|access-date=2018-03-24|language=en-US|issn=0362-4331}}</ref><ref>{{cite document|title=Adversarial Learning of Deepfakes in Accounting|language=en|arxiv = 1910.03810}}</ref> This has elicited responses from both industry and government to detect and limit their use.<ref name=":21">{{Cite web|url=https://deepfakedetectionchallenge.ai/|title=Join the Deepfake Detection Challenge (DFDC)|website=deepfakedetectionchallenge.ai|access-date=2019-11-08}}</ref><ref name=":5" />

== History ==
The development of deepfakes has taken place to a large extent in two settings: research at academic institutions and development by amateurs in online communities.<ref name=":11">{{Cite web|url=https://www.washingtonpost.com/technology/2019/06/12/top-ai-researchers-race-detect-deepfake-videos-we-are-outgunned/|title=Top AI researchers race to detect 'deepfake' videos: 'We are outgunned'|last=Harwell|first=Drew|date=12 June 2019|website=The Washington Post|language=en|url-status=live|archive-url=|archive-date=|access-date=2019-11-08}}</ref><ref>{{Cite web|url=https://www.nbcnews.com/think/opinion/thanks-ai-future-fake-news-may-be-easily-faked-video-ncna845726|title=Thanks to AI, the future of 'fake news' is being pioneered in homemade porn|last=Sanchez|first=Julian|date=8 February 2018|website=NBC News|language=en|url-status=live|archive-url=|archive-date=|access-date=2019-11-08}}</ref> More recently it has also been adopted by industry.<ref name=":2">{{Cite web|url=https://www.theverge.com/2019/9/2/20844338/zao-deepfake-app-movie-tv-show-face-replace-privacy-policy-concerns|title=Another convincing deepfake app goes viral prompting immediate privacy backlash|last=Porter|first=Jon|date=2019-09-02|website=The Verge|language=en|access-date=2019-11-08}}</ref>

=== Academic research ===
Academic research related to deepfakes lies predominantly within the field of [[computer vision]], a subfield of computer science.<ref name=":11" /> An early landmark project was the Video Rewrite program, published in 1997, which modified existing video footage of a person speaking to depict that person mouthing the words contained in a different audio track.<ref name=":6">{{Cite journal|last=Bregler|first=Christoph|last2=Covell|first2=Michele|last3=Slaney|first3=Malcolm|date=1997|title=Video Rewrite: Driving Visual Speech with Audio|journal=Proceedings of the 24th Annual Conference on Computer Graphics and Interactive Techniques|volume=24|pages=353–360|doi=10.1145/258734.258880}}</ref> It was the first system to fully automate this kind of facial reanimation, and it did so using machine learning techniques to make connections between the sounds produced by a video's subject and the shape of the subject's face.<ref name=":6" />

Contemporary academic projects have focused on creating more realistic videos and on improving techniques.<ref name=":7" /><ref name=":8" /> The “Synthesizing Obama” program, published in 2017, modifies video footage of former president [[Barack Obama]] to depict him mouthing the words contained in a separate audio track.<ref name=":7">{{Cite journal|last=Suwajanakorn|first=Supasorn|last2=Seitz|first2=Steven M.|last3=Kemelmacher-Shlizerman|first3=Ira|date=July 2017|title=Synthesizing Obama: Learning Lip Sync from Audio|journal=ACM Trans. Graph.|volume=36|issue=4|pages=95:1–95:13|doi=10.1145/3072959.3073640}}</ref> The project lists as a main research contribution its photorealistic technique for synthesizing mouth shapes from audio.<ref name=":7" /> The Face2Face program, published in 2016, modifies video footage of a person's face to depict them mimicking the facial expressions of another person in real time.<ref name=":8">{{Cite journal|last=Thies|first=Justus|last2=Zollhöfer|first2=Michael|last3=Stamminger|first3=Marc|last4=Theobalt|first4=Christian|last5=Nießner|first5=Matthias|date=June 2016|title=Face2Face: Real-Time Face Capture and Reenactment of RGB Videos|url=https://ieeexplore.ieee.org/document/7780631/|journal=2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)|location=|publisher=IEEE|volume=|pages=2387–2395|doi=10.1109/CVPR.2016.262|isbn=9781467388511|via=}}</ref> The project lists as a main research contribution the first method for re-enacting facial expressions in real time using a camera that does not capture depth, making it possible for the technique to be performed using common consumer cameras.<ref name=":8" />

In August 2018, researchers at the [[University of California, Berkeley]] published a paper introducing a fake dancing app that can create the impression of masterful dancing ability using AI.<ref name=":9">{{Cite news|url=https://www.businessinsider.com.au/artificial-intelligence-ai-deepfake-dancing-2018-8|title=An AI program will soon be here to help your deepfake dancing – just don't call it deepfake|last=Farquhar|first=Peter|date=2018-08-27|work=Business Insider Australia|access-date=2018-08-27|language=en}}</ref><ref name=":10">{{Cite news|url=https://www.theverge.com/2018/8/26/17778792/deepfakes-video-dancing-ai-synthesis|title=Deepfakes for dancing: you can now use AI to fake those dance moves you always wanted|work=The Verge|access-date=2018-08-27}}</ref> This project expands the application of deepfakes to the entire body; previous works focused on the head or parts of the face.<ref name=":9" />

=== Amateur development ===
The term deepfakes originated around the end of 2017 from a [[Reddit]] user named "deepfakes".<ref name=":3">{{cite web|url=https://www.vice.com/en_us/article/bjye8a/reddit-fake-porn-app-daisy-ridley|title=We Are Truly Fucked: Everyone Is Making AI-Generated Fake Porn Now|last=Cole|first=Samantha|date=24 January 2018|website=Vice|language=|archive-url=|archive-date=|url-status=|access-date=4 May 2019}}</ref> He, as well as others in the Reddit community r/deepfakes, shared deepfakes they created; many videos involved celebrities’ faces swapped onto the bodies of actresses in pornographic videos,<ref name=":3" /> while non-pornographic content included many videos with actor [[Nicolas Cage]]’s face swapped into various movies.<ref>{{cite web|url=https://mashable.com/2018/01/31/nicolas-cage-face-swapping-deepfakes/|title=People Are Using Face-Swapping Tech to Add Nicolas Cage to Random Movies and What Is 2018|last=Haysom|first=Sam|date=31 January 2018|website=Mashable|archive-url=|archive-date=|url-status=|access-date=4 April 2019}}</ref> 

Other online communities remain, including Reddit communities that do not share pornography, such as r/SFWdeepfakes (short for "safe for work deepfakes"), in which community members share deepfakes depicting celebrities, politicians, and others in non-pornographic scenarios.<ref>{{cite web|url=https://www.reddit.com/r/SFWdeepfakes/|title=r/SFWdeepfakes|last=|first=|date=|website=Reddit|language=|archive-url=|archive-date=|url-status=|access-date=12 December 2018}}</ref> Other online communities continue to share pornography on platforms that have not banned deepfake pornography.<ref name=":4">{{cite web|url=https://www.dailydot.com/unclick/deepfake-sites-reddit-ban/|title=Here's where 'deepfakes,' the new fake celebrity porn, went after the Reddit ban|last=Hathaway|first=Jay|date=8 February 2018|website=The Daily Dot|language=|archive-url=|archive-date=|url-status=|access-date=22 December 2018}}</ref>

=== Commercial development ===
In January 2018, a proprietary desktop application called FakeApp was launched.<ref>{{Cite web|url=https://www.online-tech-tips.com/computer-tips/what-is-a-deepfake-and-how-are-they-made/|title=What is a Deepfake and How Are They Made?|date=2019-05-23|website=Online Tech Tips|language=en-US|access-date=2019-11-08}}</ref> This app allows users to easily create and share videos with their faces swapped with each other.<ref>{{Cite web|url=https://www.theverge.com/2018/2/11/16992986/fakeapp-deepfakes-ai-face-swapping|title=I'm using AI to face-swap Elon Musk and Jeff Bezos, and I'm really bad at it|last=Robertson|first=Adi|date=2018-02-11|website=The Verge|language=en|access-date=2019-11-08}}</ref> As of 2019, FakeApp has been superseded by open-source alternatives such as Faceswap and the command line-based DeepFaceLab.<ref name=":12">{{cite web|url=https://faceswap.dev|title=Faceswap is the leading free and Open Source multi-platform Deepfakes software.|date=15 October 2019|publisher=|via=WordPress}}</ref><ref name=":13">{{cite web|url=https://github.com/iperov/DeepFaceLab|title=DeepFaceLab is a tool that utilizes machine learning to replace faces in videos. Includes prebuilt ready to work standalone Windows 7,8,10 binary (look readme.md).: iperov/DeepFaceLab|date=19 June 2019|publisher=|via=GitHub}}</ref>

Larger companies are also starting to use deepfakes.<ref name=":2" /> The mobile app giant [[Momo (software)|Momo]] created the application Zao which allows users to superimpose their face on TV and movie clips with a single picture.<ref name=":2" /> The Japanese AI company DataGrid made a full body deepfake that can create a person from scratch.<ref>{{Cite web|url=https://www.fastcompany.com/90407145/youve-been-warned-full-body-deepfakes-are-the-next-step-in-ai-based-human-mimicry|title=You've been warned: Full body deepfakes are the next step in AI-based human mimicry|last=Pangburn|first=D. J.|date=2019-09-21|website=Fast Company|language=en-US|access-date=2019-11-08}}</ref> They intend to use these for fashion and apparel.

== Techniques ==
Deepfakes rely on a type of [[Artificial neural network|neural network]] called an [[autoencoder]].<ref name=":14" /><ref>{{Cite web|url=https://www.alanzucconi.com/2018/03/14/understanding-the-technology-behind-deepfakes/|title=Understanding the Technology Behind DeepFakes|last=Zucconi|first=Alan|date=2018-03-14|website=Alan Zucconi|language=en-US|access-date=2019-11-08}}</ref> These consist of an encoder, which reduces an image to a lower dimensional latent space, and a decoder, which reconstructs the image from the latent representation. Deepfakes utilize this architecture by having a universal encoder which encodes a person in to the latent space.<ref name=":15">{{Cite web|url=https://towardsdatascience.com/what-the-heck-are-vae-gans-17b86023588a|title=What The Heck Are VAE-GANs?|last=Kan|first=C. E.|date=2018-12-10|website=Medium|language=en|access-date=2019-11-08}}</ref> The latent representation contains key features about their facial features and body posture. This can then be decoded with a model trained specifically for the target.<ref name=":14" /> This means the target's detailed information will be superimposed on the underlying facial and body features of the original video, represented in the latent space.<ref name=":14" />

A popular upgrade to this architecture attaches a [[generative adversarial network]] to the decoder.<ref name=":15" /> A GAN trains a generator, in this case the decoder, and a discriminator in an adversarial relationship.<ref name=":15" /> The generator creates new images from the latent representation of the source material, while the discriminator attempts to determine whether or not the image is generated.<ref name=":15" /> This causes the generator to create images that mimic reality extremely well as any defects would be caught by the discriminator.<ref name=":16">{{Cite news|url=https://www.wired.com/story/these-new-tricks-can-outsmart-deepfake-videosfor-now/|title=These New Tricks Can Outsmart Deepfake Videos—for Now|work=Wired|access-date=2019-11-09|language=en|issn=1059-1028}}</ref> Both algorithms improve constantly in a [[Zero-sum game|zero sum game]].<ref name=":15" /> This makes deepfakes difficult to combat as they are constantly evolving; any time a defect is determined, it can be corrected.<ref name=":16" />

==Applications==

=== Pornography ===
{{main|Deepfake pornography}}
Many deepfakes on the internet feature pornography of people, often female celebrities whose likeness is typically used without their consent.<ref name=":24">{{Cite web|url=https://www.rollingstone.com/culture/culture-news/deepfakes-nonconsensual-porn-study-kpop-895605/|title=Deepfake Porn Is Still a Threat, Particularly for K-Pop Stars|last=Dickson|first=E. J.|last2=Dickson|first2=E. J.|date=2019-10-07|website=Rolling Stone|language=en-US|access-date=2019-11-09}}</ref> Deepfake pornography prominently surfaced on the Internet in 2017, particularly on [[Reddit]].<ref name=":23">{{Cite news|url=https://variety.com/2018/digital/news/deepfakes-porn-adult-industry-1202705749/|title=Porn Producers Offer to Help Hollywood Take Down Deepfake Videos|last=Roettgers|first=Janko|date=2018-02-21|work=Variety|access-date=2018-02-28|language=en-US}}</ref> The first one that captured attention was the [[Daisy Ridley]] deepfake, which was featured in several articles.<ref name=":23" /> Other prominent pornographic deepfakes were of various other celebrities.<ref name=":23" /><ref>{{Cite web|url=https://www.businessinsider.com/deepfakes-explained-the-rise-of-fake-realistic-videos-online-2019-6|title=From porn to 'Game of Thrones': How deepfakes and realistic-looking fake videos hit it big|last=Goggin|first=Benjamin|website=Business Insider|access-date=2019-11-09}}</ref><ref>{{Cite news|url=https://www.bbc.com/news/technology-42912529|title='Fake porn' has serious consequences|last=Lee|first=Dave|date=2018-02-03|access-date=2019-11-09|language=en-GB}}</ref><ref name=":29">{{Cite web|url=https://www.vice.com/en_us/article/ywe4qw/gfycat-spotting-deepfakes-fake-ai-porn|title=Gfycat's AI Solution for Fighting Deepfakes Isn't Working|last=Cole|first=Samantha|date=2018-06-19|website=Vice|language=en|access-date=2019-11-09}}</ref> As of October 2019, most of the deepfake subjects on the internet were British and American Actresses.<ref name=":24" /> However, around a quarter of the subjects are South Korean, the majority of which are K-pop stars.<ref name=":24" /><ref>[https://medium.com/@frenizoe/deepfake-porn-efb80f39bae3 "Deepfake Porn Is Here To Stay", Medium.com]</ref>

{{Anchor|DeepNude}}In June 2019, a downloadable [[Windows]] and [[Linux]] application called DeepNude was released which used neural networks, specifically [[generative adversarial networks]], to remove clothing from images of women. The app had both a paid and unpaid version, the paid version costing $50.<ref name=":30">{{cite web |last1=Cole |first1=Samantha |last2=Maiberg |first2=Emanuel |last3=Koebler |first3=Jason |title=This Horrifying App Undresses a Photo of Any Woman with a Single Click |url=https://www.vice.com/en_us/article/kzm59x/deepnude-app-creates-fake-nudes-of-any-woman |website=Vice |accessdate=2 July 2019 |date=26 June 2019}}</ref><ref>{{cite news |url=https://www.vice.com/en_us/article/8xzjpk/github-removed-open-source-versions-of-deepnude-app-deepfakes |publisher=[[Vice Media]] |title=GitHub Removed Open Source Versions of DeepNude |first=Joseph |last=Cox |date=July 9, 2019}}</ref> On June 27 the creators removed the application and refunded consumers.<ref>{{Cite web|url=https://twitter.com/deepnudeapp/status/1144307316231200768|title=pic.twitter.com/8uJKBQTZ0o|date=27 June 2019}}</ref>

===Politics===
Deepfakes have been used to misrepresent well-known politicians in videos. In separate videos, the face of the Argentine President [[Mauricio Macri]] has been replaced by the face of [[Adolf Hitler]], and [[Angela Merkel]]'s face has been replaced with [[Donald Trump]]'s.<ref name=":0">{{cite web |title=Wenn Merkel plötzlich Trumps Gesicht trägt: die gefährliche Manipulation von Bildern und Videos |publisher=az Aargauer Zeitung |date=2018-02-03 |url=https://www.aargauerzeitung.ch/leben/digital/wenn-merkel-ploetzlich-trumps-gesicht-traegt-die-gefaehrliche-manipulation-von-bildern-und-videos-132155720}}</ref><ref>{{cite web |author=Patrick Gensing|url=http://faktenfinder.tagesschau.de/hintergrund/deep-fakes-101.html |title=Deepfakes: Auf dem Weg in eine alternative Realität? }}</ref> In April 2018, [[Jordan Peele]] collaborated with [[BuzzFeed|Buzzfeed]] to  create a deepfake of [[Barack Obama]] with Peele's voice; it served as a [[public service announcement]] to increase awareness of deepfakes. <ref>{{cite web |last1=Romano |first1=Aja |title=Jordan Peele's simulated Obama PSA is a double-edged warning against fake news |url=https://www.vox.com/2018/4/18/17252410/jordan-peele-obama-deepfake-buzzfeed |website=Vox |accessdate=September 10, 2018 |date=April 18, 2018}}</ref> In January 2019, [[Fox television]] affiliate [[KCPQ]] aired a deepfake of Trump during [[January 2019 Oval Office address|his Oval Office address]], mocking his appearance and skin color.<ref>{{cite web |last1=Swenson |first1=Kyle |title=A Seattle TV station aired doctored footage of Trump's Oval Office speech. The employee has been fired. |url=https://www.washingtonpost.com/nation/2019/01/11/seattle-tv-station-aired-doctored-footage-trumps-oval-office-speech-employee-has-been-fired/ |website=The Washington Post |accessdate=January 11, 2019 |language=en |date=January 11, 2019}}</ref>

In May 2019, [[speaker of the United States House of Representatives]] [[Nancy Pelosi]] was the subject of two [[viral videos]], one of which had the speed slowed down to 75 percent,<ref>{{cite web |title=Faked Pelosi videos, slowed to make her appear drunk, spread across social media |url=https://www.washingtonpost.com/technology/2019/05/23/faked-pelosi-videos-slowed-make-her-appear-drunk-spread-across-social-media |website=Washington Post |accessdate=1 July 2019 |language=en}}</ref> and another which edited together parts of her speech at a news conference for the [[Fox News]] segment ''[[Lou Dobbs Tonight]].'' Both videos were intended to make Pelosi appear as though she was slurring her speech.<ref>{{cite news |last1=Rimer |first1=Sara |title=Q&A: LAW's Danielle Citron Warns That Deepfake Videos Could Undermine the 2020 Election |url=http://www.bu.edu/articles/2019/qa-laws-danielle-citron-warns-that-deepfake-videos-could-undermine-the-2020-election/ |accessdate=11 September 2019 |work=BUToday |publisher=Boston University |date=11 September 2019}}</ref> President [[Donald Trump]] shared the latter video on Twitter, captioning the video "'PELOSI STAMMERS THROUGH NEWS CONFERENCE'".<ref>{{cite web |last1=Novak |first1=Matt |title=Bullshit Viral Videos of Nancy Pelosi Show Fake Content Doesn't Have to Be a Deepfake |url=https://gizmodo.com/bullshit-viral-videos-of-nancy-pelosi-show-fake-content-1835000766 |website=Gizmodo |accessdate=1 July 2019}}</ref> These videos were featured by many major news outlets, which brought deepfakes to the attention of the United States [[House Intelligence Committee]].<ref>{{Cite web|url=https://www.cnn.com/2019/06/04/politics/house-intelligence-committee-deepfakes-threats-hearing/index.html|title=Congress to investigate deepfakes as doctored Pelosi video causes stir|last=CNN|first=Donie O'Sullivan|website=CNN|access-date=2019-11-09}}</ref><ref>{{Cite web|url=https://apnews.com/4b8ec588bf5047a981bb6f7ac4acb5a7|title='Deepfakes' called new election threat, with no easy fix|date=2019-06-13|website=AP NEWS|access-date=2019-11-10}}</ref>

===Acting===

There has been speculation about deepfakes being used for creating digital actors for future films. Digitally constructed/altered humans have already been used in [[Film|films]] before, and deepfakes could contribute new developments in the near future.<ref>{{Cite news|url=https://www.theguardian.com/film/2019/jul/03/in-the-age-of-deepfakes-could-virtual-actors-put-humans-out-of-business|title=In the age of deepfakes, could virtual actors put humans out of business?|last=Kemp|first=Luke|date=2019-07-08|work=The Guardian|access-date=2019-10-20|language=en-GB|issn=0261-3077}}</ref> Amateur deepfake technology has already been used to insert faces into existing films, such as the insertion of [[Harrison Ford]]'s young face onto Han Solo's face in [[Solo: A Star Wars Story|''Solo: A Star Wars Story'']],<ref>{{Cite web|url=https://www.polygon.com/2018/10/17/17989214/harrison-ford-solo-movie-deepfake-technology|title=Harrison Ford is the star of Solo: A Star Wars Story thanks to deepfake technology|last=Radulovic|first=Petrana|date=2018-10-17|website=Polygon|language=en|access-date=2019-10-20}}</ref> and techniques similar to those used by deepfakes were used for the acting of Princess Leia in ''[[Rogue One]].''<ref>{{Cite web|url=https://www.technologyreview.com/s/612241/how-acting-as-carrie-fishers-puppet-made-a-career-for-rogue-ones-princess-leia/|title=How acting as Carrie Fisher's puppet made a career for Rogue One's Princess Leia|last=Winick|first=Erin|website=MIT Technology Review|language=en-US|access-date=2019-10-20}}</ref>

=== Social Media ===
Deepfakes have begun to see use in popular social media platforms, notably through Zao, a Chinese deepfake app that allows users to substitute their own faces onto those of characters in scenes from films and television shows such as [[Romeo + Juliet|Romeo+Juliet]] and [[Game of Thrones]].<ref>{{Cite web|url=https://www.forbes.com/sites/jessedamiani/2019/09/03/chinese-deepfake-app-zao-goes-viral-faces-immediate-criticism-over-user-data-and-security-policy/|title=Chinese Deepfake App Zao Goes Viral, Faces Immediate Criticism Over User Data And Security Policy|last=Damiani|first=Jesse|website=Forbes|language=en|access-date=2019-11-18}}</ref> The app originally faced scrutiny over its invasive user data and privacy policy, after which the company put out a statement claiming it would revise the policy.<ref>{{Cite web|url=https://www.theverge.com/2019/9/2/20844338/zao-deepfake-app-movie-tv-show-face-replace-privacy-policy-concerns|title=Another convincing deepfake app goes viral prompting immediate privacy backlash|last=Porter|first=Jon|date=2019-09-02|website=The Verge|language=en|access-date=2019-11-18}}</ref>

==Concerns==

=== Fraud ===

Audio deepfakes have been used as part of [[Social engineering (security)|social engineering]] scams, fooling people into thinking they are receiving instructions from a trusted individual.<ref name=":20">{{cite news|url=https://www.theverge.com/2019/9/5/20851248/deepfakes-ai-fake-audio-phone-calls-thieves-trick-companies-stealing-money|title=Thieves are now using AI deepfakes to trick companies into sending them money|last=Statt|first=Nick|date=5 Sep 2019|accessdate=13 Sep 2019}}</ref> In 2019, a U.K.-based energy firm’s CEO was scammed over the phone when he was ordered to transfer €220,000 into a Hungarian bank account by an individual who used audio deepfake technology to impersonate the voice of the firm's parent company's chief executive.<ref name=":19">{{Cite web|url=https://www.forbes.com/sites/jessedamiani/2019/09/03/a-voice-deepfake-was-used-to-scam-a-ceo-out-of-243000/|title=A Voice Deepfake Was Used To Scam A CEO Out Of $243,000|last=Damiani|first=Jesse|website=Forbes|language=en|access-date=2019-11-09}}</ref> The perpetrator reportedly called three times and requested a second payment but was turned down when the CEO realized the phone number of the caller was Austrian and that the money was not being reimbursed as he was told it would be.<ref name=":19" />

===Effects on credibility and authenticity===
The presence of deepfakes makes classifying videos as satirical or genuine increasingly difficult.<ref name=":0" /> AI researcher Alex Champandard has said people should know how fast things can be corrupted with deepfake technology, and that the problem is not a technical one, but rather one to be solved by trust in information and journalism.<ref name=":0" /> The primary pitfall is that humanity could fall into an age in which it can no longer be determined whether a medium's content corresponds to the truth.<ref name=":0" />

Similarly, computer science associate professor [[Hao Li]] of the [[University of Southern California]] states that deepfakes created for malicious use, such as fake news, will be even more harmful if nothing is done to spread awareness of deepfake technology.<ref name="Perfect">{{Cite web|url=https://www.wbur.org/hereandnow/2019/10/02/deepfake-technology|title=Perfect Deepfake Tech Could Arrive Sooner Than Expected|website=www.wbur.org|language=en|access-date=2019-11-09}}</ref> Li predicts that genuine videos and deepfakes will become indistinguishable in as soon as half a year, as of October 2019, due to rapid advancement in artificial intelligence and computer graphics.<ref name="Perfect" />

== Responses ==

=== Detection ===
Most of the academic research surrounding Deepfake seeks to detect the videos.<ref name=":18">{{Cite web|url=https://news.berkeley.edu/2019/06/18/researchers-use-facial-quirks-to-unmask-deepfakes/|title=Researchers use facial quirks to unmask 'deepfakes'|last=June 18|first=Kara Manke{{!}}|last2=2019June 20|date=2019-06-18|website=Berkeley News|language=en-US|access-date=2019-11-09|last3=2019}}</ref> The most popular technique is to use algorithms similar to the ones used to build the deepfake to detect them.<ref name=":18" /> By recognizing patterns in how Deepfakes are created the algorithm is able to pick up subtle inconsistencies.<ref name=":18" /> Researchers have developed automatic systems that examine videos for errors such as irregular blinking patterns of lighting.<ref name=":11" /> This technique has also been criticized for creating a "Moving Goal post" where anytime the algorithms for detecting get better, so do the Deepfakes.<ref name=":18" /> The Deepfake Detection Challenge, hosted by a coalition of leading tech companies, hope to accelerate the technology for identifying manipulated content.<ref name=":21" />

Other techniques uses [[Blockchain]] to verify the source of the media.<ref name=":22">{{Cite news|url=https://www.wired.com/story/the-blockchain-solution-to-our-deepfake-problems/|title=The Blockchain Solution to Our Deepfake Problems|work=Wired|access-date=2019-11-09|language=en|issn=1059-1028}}</ref> Videos will have to be verified through the ledger before they are shown on social media platforms.<ref name=":22" /> With this technology only videos from trusted sources would be approved, decreasing the spread of possibly harmful Deepfake media.<ref name=":22" />

===Internet reaction===
Since 2017, Samantha Cole of [[Vice (magazine)|Vice]] published a series of articles covering news surrounding deepfake pornography.<ref name=":31" /><ref name=":26" /><ref name=":32" /><ref name=":30" /><ref name=":29" /><ref name=":1">{{Cite web|url=https://www.vice.com/en_us/article/ywqgab/twitter-bans-deepfakes|title=Twitter Is the Latest Platform to Ban AI-Generated Porn|last=Cole|first=Samantha|date=2018-02-06|website=Vice|language=en|access-date=2019-11-08}}</ref><ref name=":25">{{cite web|url=https://www.vice.com/en_us/article/gydydm/gal-gadot-fake-ai-porn|title=AI-Assisted Fake Porn Is Here and We're All Fucked|last=Cole|first=Samantha|date=11 December 2017|website=Vice|language=|archive-url=|archive-date=|url-status=|access-date=19 December 2018}}</ref><ref name=":3" /> On January 31st, 2018, [[Gfycat]] began removing all deepfakes from its site.<ref name=":32">{{Cite web|url=https://www.vice.com/en_us/article/vby5jx/deepfakes-ai-porn-removed-from-gfycat|title=AI-Generated Fake Porn Makers Have Been Kicked Off Their Favorite Host|last=Cole|first=Samantha|date=2018-01-31|website=Vice|language=en|access-date=2019-11-18}}</ref><ref name=":28">{{Cite web|url=https://thenextweb.com/insider/2018/02/07/twitter-pornhub-and-other-platforms-ban-ai-generated-celebrity-porn/|title=Twitter, Pornhub and other platforms ban AI-generated celebrity porn|last=Ghoshal|first=Abhimanyu|date=2018-02-07|website=The Next Web|language=en-us|access-date=2019-11-09}}</ref> On [[Reddit]], the r/deepfakes subreddit was banned on February 7, 2018, due to the policy violation of "involuntary pornography".<ref>{{Cite news|url=https://www.spiegel.de/netzwelt/web/deepfakes-online-plattformen-wollen-fake-promi-pornos-loeschen-a-1192170.html|title="Deepfakes": Firmen gehen gegen gefälschte Promi-Pornos vor|last=Böhm|first=Markus|date=2018-02-07|work=Spiegel Online|access-date=2019-11-09}}</ref><ref>{{Cite web|url=https://futurezone.at/digital-life/deepfakes-reddit-loescht-forum-fuer-kuenstlich-generierte-fake-pornos/400003061|title=Deepfakes: Reddit löscht Forum für künstlich generierte Fake-Pornos|last=barbara.wimmer|website=futurezone.at|language=de|access-date=2019-11-09}}</ref><ref>{{Cite web|url=https://www.heise.de/newsticker/meldung/Deepfakes-Auch-Reddit-verbannt-Fake-Porn-3962987.html|title=Deepfakes: Auch Reddit verbannt Fake-Porn|last=online|first=heise|website=heise online|language=de|access-date=2019-11-09}}</ref><ref>{{Cite web|url=https://www.derstandard.at/story/2000073855676/reddit-verbannt-deepfake-pornos|title=Reddit verbannt Deepfake-Pornos - derStandard.de|website=DER STANDARD|language=de-AT|access-date=2019-11-09}}</ref><ref>{{Cite web|url=https://www.theverge.com/2018/2/7/16982046/reddit-deepfakes-ai-celebrity-face-swap-porn-community-ban|title=Reddit bans 'deepfakes' AI porn communities|last=Robertson|first=Adi|date=2018-02-07|website=The Verge|language=en|access-date=2019-11-09}}</ref> In the same month, representatives from [[Twitter]] stated that they would suspend accounts suspected of posting non-consensual deepfake content.<ref name=":1" /> Chat site [[Discord (software)|Discord]] has taken action against deepfakes in the past,<ref>{{Cite web|url=https://www.businessinsider.com.au/discord-closes-down-deepfakes-server-ai-celebrity-porn-2018-1|title=Discord just shut down a chat group dedicated to sharing porn videos edited with AI to include celebrities|last=Price|first=Rob|date=2018-01-27|website=Business Insider Australia|language=en|access-date=2019-11-28}}</ref> and has taken a general stance against deepfakes.<ref name=":28" /><ref>{{Cite web|url=https://www.engadget.com/2018/02/07/twitter-joins-those-banning-deepfake-ai-porn/|title=Twitter bans 'deepfake' AI-generated porn|website=Engadget|language=en|access-date=2019-11-28}}</ref>. In September 2018, [[Google]] added "involuntary synthetic pornographic imagery” to its ban list, allowing anyone to request the block of results showing their fake nudes.<ref name="Fake-porn videos are being weaponized to harass and humiliate women: ‘Everybody is a potential target’" />

In February 2018, [[Pornhub]] said that it would ban deepfake videos on its website because it is considered “non consensual content” which violates their terms of service.<ref name=":26">{{Cite web|url=https://www.vice.com/en_us/article/zmwvdw/pornhub-bans-deepfakes|title=Pornhub Is Banning AI-Generated Fake Porn Videos, Says They're Nonconsensual|last=Cole|first=Samantha|date=2018-02-06|website=Vice|language=en|access-date=2019-11-09}}</ref> They also stated previously to Mashable that they will take down content flagged as deepfakes.<ref>{{Cite web|url=https://mashable.com/2018/02/02/what-are-deepfakes/|title=A guide to 'deepfakes,' the internet's latest moral crisis|last=Gilmer|first=Damon Beres and Marcus|website=Mashable|language=en|access-date=2019-11-09}}</ref> Writers from Motherboard from [[BuzzFeed News|Buzzfeed News]] reported that searching “deepfakes” on [[Pornhub]] still returned multiple recent deepfake videos.<ref name=":26" /> 

[[Facebook]] has previously stated that they would not remove deepfakes from their platforms.<ref name=":27">{{Cite web|url=https://www.technologyreview.com/f/613690/facebook-deepfake-zuckerberg-instagram-social-media-election-video/|title=Facebook has promised to leave up a deepfake video of Mark Zuckerberg|website=MIT Technology Review|language=en-US|access-date=2019-11-09}}</ref> The videos will instead be flagged as fake by third-parties and then have a lessened priority in user's feeds.<ref name=":31">{{Cite web|url=https://www.vice.com/en_us/article/ywyxex/deepfake-of-mark-zuckerberg-facebook-fake-video-policy|title=This Deepfake of Mark Zuckerberg Tests Facebook's Fake Video Policies|last=Cole|first=Samantha|date=2019-06-11|website=Vice|language=en|access-date=2019-11-09}}</ref> This response was prompted in June 2019 after a deepfake featuring a 2016 video of [[Mark Zuckerberg]] circulated on Facebook and [[Instagram]].<ref name=":27" />

=== Legal response ===
In the United States, there have been some responses to the problems posed by deepfakes. In 2018, the Malicious Deep Fake Prohibition Act was introduced to the [[United States Senate|US Senate]],<ref>{{Cite web|url=https://www.congress.gov/bill/115th-congress/senate-bill/3805|title=S.3805 - 115th Congress (2017-2018): Malicious Deep Fake Prohibition Act of 2018|last=Sasse|first=Ben|date=2018-12-21|website=www.congress.gov|access-date=2019-10-16}}</ref> and in 2019 the DEEPFAKES Accountability Act was introduced in the [[United States House of Representatives|House of Representatives]].<ref name=":5">{{Cite web|url=https://www.congress.gov/bill/116th-congress/house-bill/3230|title=H.R.3230 - 116th Congress (2019-2020): Defending Each and Every Person from False Appearances by Keeping Exploitation Subject to Accountability Act of 2019|last=Clarke|first=Yvette D.|date=2019-06-28|website=www.congress.gov|access-date=2019-10-16}}</ref> Several states have also introduced legislation regarding deepfakes, including Virginia,<ref>{{Cite web|url=http://social.techcrunch.com/2019/07/01/deepfake-revenge-porn-is-now-illegal-in-virginia/|title='Deepfake' revenge porn is now illegal in Virginia|website=TechCrunch|language=en-US|access-date=2019-10-16}}</ref> Texas, California, and New York.<ref>{{Cite web|url=https://slate.com/technology/2019/07/congress-deepfake-regulation-230-2020.html|title=Congress Wants to Solve Deepfakes by 2020. That Should Worry Us.|last=Brown|first=Nina Iacono|date=2019-07-15|website=Slate Magazine|language=en|access-date=2019-10-16}}</ref> On October 3, 2019, California governor [[Gavin Newsom]] signed into law Assembly Bills No. 602 and No. 730.<ref name="AB602">{{Cite web|url=https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201920200AB602|title=Bill Text - AB-602 Depiction of individual using digital or electronic technology: sexually explicit material: cause of action.|website=leginfo.legislature.ca.gov|access-date=2019-11-09}}</ref><ref name="AB730">{{Cite web|url=https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201920200AB730|title=Bill Text - AB-730 Elections: deceptive audio or visual media.|website=leginfo.legislature.ca.gov|access-date=2019-11-09}}</ref> Assembly Bill No. 602 provides individuals targeted by sexually explicit deepfake content made without their consent with a cause of action against the content’s creator.<ref name="AB602" /> Assembly Bill No. 730 prohibits the distribution of malicious deepfake audio or visual media targeting a candidate running for public office within 60 days of their election.<ref name="AB730" />

In November 2019 China announced that deepfakes and other synthetically faked footage should bear a clear notice about its fakeness starting in 2020. Failure to comply could be considered a [[crime]] the [[Cyberspace Administration of China]] stated on its website.<ref name="Reuters2019">

{{cite web
 | url = https://www.reuters.com/article/us-china-technology/china-seeks-to-root-out-fake-news-and-deepfakes-with-new-online-content-rules-idUSKBN1Y30VU
 | title = China seeks to root out fake news and deepfakes with new online content rules
 | last =
 | first =
 | date = 2019-11-29
 | website = [[Reuters.com]]
 | publisher = [[Reuters]]
 | access-date = 2019-12-17
 | quote = }}

</ref> The Chinese government seems to be reserving the right to prosecute both users and [[online video platform]]s failing to abide by the rules.<ref name="TheVerge2019">

{{cite web
 | url = https://www.theverge.com/2019/11/29/20988363/china-deepfakes-ban-internet-rules-fake-news-disclosure-virtual-reality
 | title = China makes it a criminal offense to publish deepfakes or fake news without disclosure
 | last = Statt
 | first = Nick
 | date = 2019-11-29
 | website = 
 | publisher = [[The Verge]]
 | access-date = 2019-12-17
 | quote = }}

</ref>

In the United Kingdom, producers of deepfake material can be prosecuted for harassment, but there are calls to make deepfake a specific crime;<ref>[https://www.theguardian.com/world/2018/jun/21/call-for-upskirting-bill-to-include-deepfake-pornography-ban Call for upskirting bill to include 'deepfake' pornography ban] ''[[The Guardian]]''</ref> in the United States, where charges as varied as [[identity theft]], [[cyberstalking]], and [[revenge porn]] have been pursued, the notion of a more comprehensive statute has also been discussed.<ref name="Fake-porn videos are being weaponized to harass and humiliate women: ‘Everybody is a potential target’">{{cite web|url=https://www.washingtonpost.com/technology/2018/12/30/fake-porn-videos-are-being-weaponized-harass-humiliate-women-everybody-is-potential-target|title=Fake-porn videos are being weaponized to harass and humiliate women: 'Everybody is a potential target'|last=Harrell|first=Drew|website=The Washington Post|access-date=2019-01-01}}</ref>

==In popular culture==
==="Picaper" by Jack Wodhams===

The 1986 Mid-December issue of ''[[Analog Science Fiction and Fact|Analog]]'' magazine published the novelette "Picaper" by Jack Wodhams. Its plot revolves around digitally enhanced or digitally generated videos produced by skilled hackers serving unscrupulous lawyers and political figures.<ref name="1986-picaper">{{cite web |url=http://www.isfdb.org/cgi-bin/title.cgi?48679 |title=Picaper |publisher=[[Internet Speculative Fiction Database]] |access-date=9 July 2019}}</ref>

Jack Wodhams calls such fabricated videos '''picaper''' or '''mimepic'''—image animation based on "the information from the presented image, and copied through choices from an infinite number of variables that a program might supply".<ref name="1986-picaper"/> To Wodhams, pornography is not the major danger of this technology. 

The sobering conclusion is that "the old idea that pictures do not lie is going to have to undergo drastic revision".<ref name="1986-picaper"/>

===''A Philosophical Investigation''===
{{anchor|"A Philosophical Investigation" by Philip Kerr}}
In the 1992 techno-thriller ''[[A Philosophical Investigation]]'' by [[Philip Kerr]], "Wittgenstein", the main character and a serial killer, makes use of both a software similar to Deepfake and a virtual reality suit for having sex with an avatar of the female police lieutenant Isadora "Jake" Jakowicz assigned to catch him.<ref name="1992-API">{{citation |title=A Philosophical Investigation |author=Philip Kerr | isbn=978-0143117537}}</ref>

===''The Capture''===
Deepfake technology is part of the plot of the 2019 [[BBC One]] drama ''[[The Capture (TV series)|The Capture]]''. The series follows British ex-soldier Shaun Emery, who is accused of assaulting and abducting his barrister. Expertly doctored [[CCTV]] footage is used to set him up and mislead the police investigating him.<ref>{{cite news |last1=Bernal |first1=Natasha |title=The disturbing truth behind The Capture and real life deepfakes |url=https://www.telegraph.co.uk/technology/2019/10/08/truth-behind-deepfake-video-bbc-ones-thriller-capture/ |accessdate=24 October 2019 |work=The Telegraph |date=8 October 2019}}</ref><ref>{{cite news |last1=Crawley |first1=Peter |title=The Capture: A BBC thriller of surveillance, distortion and duplicity |url=https://www.irishtimes.com/culture/tv-radio-web/the-capture-a-bbc-thriller-of-surveillance-distortion-and-duplicity-1.4008823 |accessdate=24 October 2019 |work=The Irish Times |date=5 September 2019 |language=en}}</ref>

== See also ==

* [[Revenge porn|Revenge Porn]]

* [[Deepfake pornography]]

==References==
{{reflist}}

==External links==
* {{Cite news |first=Ben |last=Sasse |date=19 October 2018 |title=This New Technology Could Send American Politics into a Tailspin |url=https://www.washingtonpost.com/opinions/the-real-scary-news-about-deepfakes/2018/10/19/6238c3ce-d176-11e8-83d6-291fcead2ab1_story.html |department=Opinions  |work=[[The Washington Post]] |access-date=10 July 2019}}

[[Category:Applications of computer vision]]
[[Category:Artificial intelligence applications]]
[[Category:Computer graphics]]
[[Category:Deep learning]]
[[Category:Special effects]]
[[Category:Words coined in the 2010s]]