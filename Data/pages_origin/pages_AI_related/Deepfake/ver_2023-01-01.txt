{{Short description|Artificial intelligence-based human image synthesis technique}}
{{Use dmy dates|date=July 2020}}
<!-- Deleted image removed: [[File:Deepfake example.gif|thumb|280px|An example of deepfake technology: in a scene from ''[[Man of Steel (film)|Man of Steel]]'', actress [[Amy&nbsp;Adams]] in the original (left) is modified to have the face of actor [[Nicolas&nbsp;Cage]] (right)]] -->
{{Artificial intelligence}}

'''Deepfakes''' (a [[portmanteau]] of "[[deep learning]]" and "fake"<ref name="FoxNews2018">{{Cite news | url=http://www.foxnews.com/tech/2018/02/16/terrifying-high-tech-porn-creepy-deepfake-videos-are-on-rise.html | title=Terrifying high-tech porn: Creepy 'deepfake' videos are on the rise | last=Brandon | first=John | date=2018-02-16 | work=Fox News | access-date=2018-02-20 | language=en-US | archive-date=15 June 2018 | archive-url=https://web.archive.org/web/20180615160819/http://www.foxnews.com/tech/2018/02/16/terrifying-high-tech-porn-creepy-deepfake-videos-are-on-rise.html | url-status=live }}</ref>) are [[synthetic media]]<ref>{{Cite web|url=https://lab.witness.org/projects/synthetic-media-and-deep-fakes/|title=Prepare, Don't Panic: Synthetic Media and Deepfakes|publisher=witness.org|access-date=25 November 2020|archive-date=2 December 2020|archive-url=https://web.archive.org/web/20201202231744/https://lab.witness.org/projects/synthetic-media-and-deep-fakes/|url-status=live}}</ref> in which a person in an existing image or video is replaced with someone else's likeness. While the act of creating fake content is not new, deepfakes leverage powerful techniques from [[machine learning]] and [[artificial intelligence]] to manipulate or generate visual and audio content that can more easily deceive.<ref name=":17">{{Cite journal|last1=Kietzmann|first1=J.|last2=Lee|first2=L. W.|last3=McCarthy|first3=I. P.|last4=Kietzmann|first4=T. C.|title=Deepfakes: Trick or treat?|journal=Business Horizons|volume=63|issue=2|pages=135–146|doi=10.1016/j.bushor.2019.11.006|year=2020|s2cid=213818098|url=https://irep.ntu.ac.uk/id/eprint/38737/1/1247050_Lee.pdf }}</ref><ref name="Waldrop">{{cite journal |last1=Waldrop |first1=M. Mitchell |title=Synthetic media: The real trouble with deepfakes |journal=Knowable Magazine |publisher= Annual Reviews |date=16 March 2020 |doi=10.1146/knowable-031320-1|doi-access=free |url=https://knowablemagazine.org/article/technology/2020/synthetic-media-real-trouble-deepfakes |access-date=19 December 2022 |language=en}}</ref> The main machine learning methods used to create deepfakes are based on deep learning and involve training generative [[artificial neural network|neural network]] architectures, such as [[autoencoder]]s,<ref name=":17" /> or [[generative adversarial network]]s (GANs).<ref name="Schwartz">{{cite news|url=https://www.theguardian.com/technology/2018/nov/12/deep-fakes-fake-news-truth|title=You thought fake news was bad? Deep fakes are where truth goes to die|last1=Schwartz|first1=Oscar|date=12 November 2018|work=The Guardian|access-date=14 November 2018|language=en|archive-date=16 June 2019|archive-url=https://web.archive.org/web/20190616230351/https://www.theguardian.com/technology/2018/nov/12/deep-fakes-fake-news-truth|url-status=live}}</ref><ref name=":14">{{Cite web|url=https://towardsdatascience.com/family-fun-with-deepfakes-or-how-i-got-my-wife-onto-the-tonight-show-a4454775c011|title=Family fun with deepfakes. Or how I got my wife onto the Tonight Show|first=Sven|last=Charleer|date=2019-05-17|website=Medium|language=en|access-date=2019-11-08|archive-date=11 February 2018|archive-url=https://web.archive.org/web/20180211141135/https://towardsdatascience.com/family-fun-with-deepfakes-or-how-i-got-my-wife-onto-the-tonight-show-a4454775c011|url-status=live}}</ref>

Deepfakes have garnered widespread attention for their potential use in creating [[child sexual abuse]] material, [[Celebrity sex tape|celebrity pornographic videos]], [[revenge porn]], [[fake news]], [[hoax]]es, [[bullying]], and [[Accounting scandals|financial fraud]].<ref name="HighSnobiety2018">{{Cite news | url=https://www.highsnobiety.com/p/what-are-deepfakes-ai-porn/ | title=What Are Deepfakes & Why the Future of Porn is Terrifying | date=2018-02-20 | work=Highsnobiety | access-date=2018-02-20 | language=en-US | archive-date=14 July 2021 | archive-url=https://web.archive.org/web/20210714032914/https://www.highsnobiety.com/p/what-are-deepfakes-ai-porn/ | url-status=live }}</ref><ref>{{cite web|url=https://theoutline.com/post/3179/deepfake-videos-are-freaking-experts-out|title=Experts fear face swapping tech could start an international showdown|website=The Outline|language=en|access-date=2018-02-28|archive-date=16 January 2020|archive-url=https://web.archive.org/web/20200116140157/https://theoutline.com/post/3179/deepfake-videos-are-freaking-experts-out|url-status=live}}</ref><ref>{{Cite news|url=https://www.nytimes.com/2018/03/04/technology/fake-videos-deepfakes.html|title=Here Come the Fake Videos, Too|last=Roose|first=Kevin|date=2018-03-04|work=The New York Times|access-date=2018-03-24|language=en-US|issn=0362-4331|archive-date=18 June 2019|archive-url=https://web.archive.org/web/20190618203019/https://www.nytimes.com/2018/03/04/technology/fake-videos-deepfakes.html|url-status=live}}</ref><ref>{{cite arXiv|title=Adversarial Learning of Deepfakes in Accounting |language=en |eprint = 1910.03810 |last1=Schreyer |first1=Marco |last2=Sattarov |first2=Timur |last3=Reimer |first3=Bernd |last4=Borth |first4=Damian |date=October 2019|class=cs.LG }}</ref> This has elicited responses from both industry and government to detect and limit their use.<ref name=":28" /><ref name=":5" />

From traditional [[entertainment]] to [[Gaming computer|gaming]], deepfake technology has evolved to be increasingly convincing and available to the public, allowing the disruption of the entertainment and [[Media industry|media]] industries.<ref>{{Cite web |title=Artificial Intelligence: Deepfakes in the Entertainment Industry |url=https://www.wipo.int/wipo_magazine/en/2022/02/article_0003.html |access-date=2022-11-08 |website=www.wipo.int |language=en}}</ref>

== History ==
[[Photo manipulation]] was developed in the 19th century and soon applied to [[Film|motion pictures]]. Technology steadily improved during the 20th century, and more quickly with the advent of [[digital video]].

Deepfake technology has been developed by researchers at academic institutions beginning in the 1990s, and later by amateurs in online communities.<ref name=":11">{{Cite news|url=https://www.washingtonpost.com/technology/2019/06/12/top-ai-researchers-race-detect-deepfake-videos-we-are-outgunned/|title=Top AI researchers race to detect 'deepfake' videos: 'We are outgunned'|last=Harwell|first=Drew|date=12 June 2019|newspaper=The Washington Post|language=en|access-date=2019-11-08|archive-date=31 October 2019|archive-url=https://web.archive.org/web/20191031051258/https://www.washingtonpost.com/technology/2019/06/12/top-ai-researchers-race-detect-deepfake-videos-we-are-outgunned/|url-status=live}}</ref><ref>{{Cite web|url=https://www.nbcnews.com/think/opinion/thanks-ai-future-fake-news-may-be-easily-faked-video-ncna845726|title=Thanks to AI, the future of 'fake news' is being pioneered in homemade porn|last=Sanchez|first=Julian|date=8 February 2018|website=NBC News|language=en|access-date=2019-11-08|archive-date=9 November 2019|archive-url=https://web.archive.org/web/20191109084341/https://www.nbcnews.com/think/opinion/thanks-ai-future-fake-news-may-be-easily-faked-video-ncna845726|url-status=live}}</ref> More recently the methods have been adopted by industry.<ref name=":2">{{Cite web|url=https://www.theverge.com/2019/9/2/20844338/zao-deepfake-app-movie-tv-show-face-replace-privacy-policy-concerns|title=Another convincing deepfake app goes viral prompting immediate privacy backlash|last=Porter|first=Jon|date=2019-09-02|website=The Verge|language=en|access-date=2019-11-08|archive-date=3 September 2019|archive-url=https://web.archive.org/web/20190903202859/https://www.theverge.com/2019/9/2/20844338/zao-deepfake-app-movie-tv-show-face-replace-privacy-policy-concerns|url-status=live}}</ref>

=== Academic research ===
Academic research related to deepfakes is split between the field of [[computer vision]], a subfield of computer science,<ref name=":11" /> which develops techniques for creating and identifying deepfakes, and humanities and social science approaches that study the social, ethical and aesthetic implications of deepfakes.

==== Social science and humanities approaches to deepfakes ====
In cinema studies, deepfakes demonstrate how "the human face is emerging as a central object of ambivalence in the digital age".<ref>{{Cite journal|last1=Bode|first1=Lisa|last2=Lees|first2=Dominic|last3=Golding|first3=Dan|date=2021-07-29|title=The Digital Face and Deepfakes on Screen|journal=Convergence: The International Journal of Research into New Media Technologies|volume=27|issue=4|pages=849–854|doi=10.1177/13548565211034044|s2cid=237402465 |issn=1354-8565}}</ref> Video artists have used deepfakes to "playfully rewrite film history by retrofitting canonical cinema with new star performers".<ref name=":36">{{Cite journal|last=Holliday|first=Christopher|date=2021-07-26|title=Rewriting the stars: Surface tensions and gender troubles in the online media production of digital deepfakes|journal=Convergence: The International Journal of Research into New Media Technologies|volume=27|issue=4|pages=899–918|doi=10.1177/13548565211029412|s2cid=237402548 |issn=1354-8565}}</ref> Film scholar Christopher Holliday analyses how the switching out gender and race of performers in familiar movie scenes destabilise gender classifications and categories.<ref name=":36" /> The idea of "[[queering]]" deepfakes is also discussed in Oliver M. Gingrich's discussion of media artworks that use deepfakes to reframe gender,<ref>{{Cite journal|last=Gingrich|first=Oliver M.|date=2021-07-05|title=GENDER*UCK: Reframing gender & media art|url=https://scienceopen.com/hosted-document?doi=10.14236/ewic/EVA2021.25|journal=Proceedings of EVA London 2021 (EVA 2021)|series=Electronic Workshops in Computing |doi=10.14236/ewic/EVA2021.25|s2cid=236918199 }}</ref> including British artist [[Jake Elwes|Jake Elwes']] ''Zizi: Queering the Dataset'', an artwork that uses deepfakes of drag queens to intentionally play with gender. The aesthetic potentials of deepfakes are also beginning to be explored. Theatre historian John Fletcher notes that early demonstrations of deepfakes are presented as performances, and situates these in the context of theatre, discussing "some of the more troubling paradigm shifts" that deepfakes represent as a performance genre.<ref>{{Cite journal|last=Fletcher|first=John|date=2018|title=Deepfakes, Artificial Intelligence, and Some Kind of Dystopia: The New Faces of Online Post-Fact Performance|url=https://muse.jhu.edu/article/715916|journal=Theatre Journal|language=en|volume=70|issue=4|pages=455–471|doi=10.1353/tj.2018.0097|s2cid=191988083 |issn=1086-332X}}</ref>

Philosophers and media scholars have discussed the ethics of deepfakes especially in relation to pornography.<ref>{{Cite journal|last=Öhman|first=Carl|date=2020-06-01|title=Introducing the pervert's dilemma: a contribution to the critique of Deepfake Pornography|journal=Ethics and Information Technology|language=en|volume=22|issue=2|pages=133–140|doi=10.1007/s10676-019-09522-1|s2cid=208145457 |issn=1572-8439}}</ref> Media scholar [[Emily van der Nagel]] draws upon research in photography studies on manipulated images to discuss verification systems that allow women to consent to uses of their images.<ref>{{Cite journal|last=van der Nagel|first=Emily|date=2020-10-01|title=Verifying images: deepfakes, control, and consent|url=https://www.tandfonline.com/doi/full/10.1080/23268743.2020.1741434|journal=Porn Studies|language=en|volume=7|issue=4|pages=424–429|doi=10.1080/23268743.2020.1741434|s2cid=242891792 |issn=2326-8743}}</ref>

Beyond pornography, deepfakes have been framed by philosophers as an "epistemic threat" to knowledge and thus to society.<ref>{{Cite journal|last=Fallis|first=Don|date=2021-12-01|title=The Epistemic Threat of Deepfakes|journal=Philosophy & Technology|language=en|volume=34|issue=4|pages=623–643|doi=10.1007/s13347-020-00419-2|issn=2210-5433|pmc=7406872|pmid=32837868}}</ref> There are several other suggestions for how to deal with the risks deepfakes give rise beyond pornography, but also to corporations, politicians and others, of "exploitation, intimidation, and personal sabotage",<ref>{{Cite journal|last1=Chesney|first1=Robert|last2=Citron|first2=Danielle Keats|date=2018|title=Deep Fakes: A Looming Challenge for Privacy, Democracy, and National Security|url=https://www.ssrn.com/abstract=3213954|journal=SSRN Electronic Journal|language=en|doi=10.2139/ssrn.3213954|issn=1556-5068}}</ref> and there are several scholarly discussions of potential legal and regulatory responses both in legal studies and media studies.<ref>{{Cite journal|last1=Yadlin-Segal|first1=Aya|last2=Oppenheim|first2=Yael|date=February 2021|title=Whose dystopia is it anyway? Deepfakes and social media regulation|url=http://journals.sagepub.com/doi/10.1177/1354856520923963|journal=Convergence: The International Journal of Research into New Media Technologies|language=en|volume=27|issue=1|pages=36–51|doi=10.1177/1354856520923963|s2cid=219438536 |issn=1354-8565}}</ref> In psychology and media studies, scholars discuss the effects of [[disinformation]] that uses deepfakes,<ref>{{Cite journal|last1=Hwang|first1=Yoori|last2=Ryu|first2=Ji Youn|last3=Jeong|first3=Se-Hoon|date=2021-03-01|title=Effects of Disinformation Using Deepfake: The Protective Effect of Media Literacy Education|url=https://www.liebertpub.com/doi/10.1089/cyber.2020.0174|journal=Cyberpsychology, Behavior, and Social Networking|volume=24|issue=3|pages=188–193|doi=10.1089/cyber.2020.0174|pmid=33646021 |s2cid=232078561 |issn=2152-2715}}</ref><ref>{{Cite journal|last=Hight|first=Craig|date=2021-11-12|title=Deepfakes and documentary practice in an age of misinformation|url=https://www.tandfonline.com/doi/full/10.1080/10304312.2021.2003756|journal=Continuum|volume=36 |issue=3 |language=en|pages=393–410|doi=10.1080/10304312.2021.2003756|s2cid=244092288 |issn=1030-4312}}</ref> and the social impact of deepfakes.<ref>{{Cite journal|last1=Hancock|first1=Jeffrey T.|last2=Bailenson|first2=Jeremy N.|date=2021-03-01|title=The Social Impact of Deepfakes|url=https://www.liebertpub.com/doi/10.1089/cyber.2021.29208.jth|journal=Cyberpsychology, Behavior, and Social Networking|language=en|volume=24|issue=3|pages=149–152|doi=10.1089/cyber.2021.29208.jth|pmid=33760669 |s2cid=232356146 |issn=2152-2715}}</ref>

While most English-language academic studies of deepfakes focus on the Western anxieties about disinformation and pornography, digital anthropologist [[Gabriele de Seta]] has analysed the Chinese reception of deepfakes, which are known as ''huanlian'', which translates to "changing faces". The Chinese term does not contain the "fake" of the English deepfake, and de Seta argues that this cultural context may explain why the Chinese response has been more about practical regulatory responses to "fraud risks, image rights, economic profit, and ethical imbalances".<ref>{{Cite journal|last=de Seta|first=Gabriele|date=2021-07-30|title=Huanlian , or changing faces: Deepfakes on Chinese digital media platforms|url=http://journals.sagepub.com/doi/10.1177/13548565211030185|journal=Convergence: The International Journal of Research into New Media Technologies|language=en|volume=27|issue=4|pages=935–953|doi=10.1177/13548565211030185|hdl=11250/2833613 |s2cid=237402447 |issn=1354-8565}}</ref>

==== Computer science research on deepfakes ====
An early landmark project was the Video Rewrite program, published in 1997, which modified existing video footage of a person speaking to depict that person mouthing the words contained in a different audio track.<ref name=":6">{{Cite journal|last1=Bregler|first1=Christoph|last2=Covell|first2=Michele|last3=Slaney|first3=Malcolm|date=1997|title=Video Rewrite: Driving Visual Speech with Audio|journal=Proceedings of the 24th Annual Conference on Computer Graphics and Interactive Techniques|volume=24|pages=353–360|doi=10.1145/258734.258880|s2cid=2341707}}</ref> It was the first system to fully automate this kind of facial reanimation, and it did so using machine learning techniques to make connections between the sounds produced by a video's subject and the shape of the subject's face.<ref name=":6" />

Contemporary academic projects have focused on creating more realistic videos and on improving techniques.<ref name=":7">{{Cite journal|last1=Suwajanakorn|first1=Supasorn|last2=Seitz|first2=Steven M.|last3=Kemelmacher-Shlizerman|first3=Ira|date=July 2017|title=Synthesizing Obama: Learning Lip Sync from Audio|journal=ACM Trans. Graph.|volume=36|issue=4|pages=95:1–95:13|doi=10.1145/3072959.3073640|s2cid=207586187}}</ref><ref name=":8">{{Cite journal|last1=Thies|first1=Justus|last2=Zollhöfer|first2=Michael|last3=Stamminger|first3=Marc|last4=Theobalt|first4=Christian|last5=Nießner|first5=Matthias|date=June 2016|title=Face2Face: Real-Time Face Capture and Reenactment of RGB Videos|journal=2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)|publisher=IEEE|pages=2387–2395|doi=10.1109/CVPR.2016.262|isbn=9781467388511|arxiv=2007.14808|s2cid=206593693}}</ref> The "Synthesizing Obama" program, published in 2017, modifies video footage of former president [[Barack Obama]] to depict him mouthing the words contained in a separate audio track.<ref name=":7" /> The project lists as a main research contribution its [[photorealistic]] technique for synthesizing mouth shapes from audio.<ref name=":7" /> The Face2Face program, published in 2016, modifies video footage of a person's face to depict them mimicking the facial expressions of another person in real time.<ref name=":8" /> The project lists as a main research contribution the first method for re-enacting facial expressions in real time using a camera that does not capture depth, making it possible for the technique to be performed using common consumer cameras.<ref name=":8" />

In August 2018, researchers at the [[University of California, Berkeley]] published a paper introducing a fake dancing app that can create the impression of masterful dancing ability using AI.<ref name=":9">{{Cite news|last=Farquhar|first=Peter|date=2018-08-27|title=An AI program will soon be here to help your deepface dancing – just don't call it deepfake|language=en|work=Business Insider Australia|url=https://www.businessinsider.com.au/artificial-intelligence-ai-deepfake-dancing-2018-8|access-date=2018-08-27|archive-date=10 April 2019|archive-url=https://web.archive.org/web/20190410050633/https://www.businessinsider.com.au/artificial-intelligence-ai-deepfake-dancing-2018-8|url-status=live}}</ref><ref name=":10">{{Cite news|title=Deepfakes for dancing: you can now use AI to fake those dance moves you always wanted|work=The Verge|url=https://www.theverge.com/2018/8/26/17778792/deepfakes-video-dancing-ai-synthesis|access-date=2018-08-27|archive-date=17 May 2019|archive-url=https://web.archive.org/web/20190517055341/https://www.theverge.com/2018/8/26/17778792/deepfakes-video-dancing-ai-synthesis|url-status=live}}</ref> This project expands the application of deepfakes to the entire body; previous works focused on the head or parts of the face.<ref name=":9" />

Researchers have also shown that deepfakes are expanding into other domains such as tampering with medical imagery.<ref>{{Cite book|last1=Mirsky|first1=Yisroel|last2=Mahler|first2=Tom|last3=Shelef|first3=Ilan|last4=Elovici|first4=Yuval|date=2019|title=CT-GAN: Malicious Tampering of 3D Medical Imagery using Deep Learning|url=https://www.usenix.org/conference/usenixsecurity19/presentation/mirsky|language=en|pages=461–478|isbn=978-1-939133-06-9|access-date=18 June 2020|archive-date=20 June 2020|archive-url=https://web.archive.org/web/20200620075305/https://www.usenix.org/conference/usenixsecurity19/presentation/mirsky|url-status=live}}</ref>  In this work, it was shown how an attacker can automatically inject or remove lung cancer in a patient's 3D CT scan. The result was so convincing that it fooled three radiologists and a state-of-the-art lung cancer detection AI. To demonstrate the threat, the authors successfully performed the attack on a hospital in a [[White hat (computer security)|White hat penetration test]].<ref>{{Cite web |date=2019-04-03 |title=Researchers Demonstrate Malware That Can Trick Doctors Into Misdiagnosing Cancer |url=https://gizmodo.com/researchers-demonstrate-malware-that-can-trick-doctors-1833786672 |access-date=2022-06-03 |website=Gizmodo |language=en-us}}</ref>

A survey of deepfakes, published in May 2020, provides a timeline of how the creation and detection deepfakes have advanced over the last few years.<ref>{{cite journal|last1=Mirsky|first1=Yisroel|last2=Lee|first2=Wenke|date=2020-05-12|title=The Creation and Detection of Deepfakes: A Survey|journal=ACM Computing Surveys|doi=10.1145/3425780|arxiv=2004.11138|s2cid=216080410}}</ref> The survey identifies that researchers have been focusing on resolving the following challenges of deepfake creation:

* Generalization.  High-quality deepfakes are often achieved by training on hours of footage of the target. This challenge is to minimize the amount of training data and the time to train the model required to produce quality images and to enable the execution of trained models on ''new'' identities (unseen during training).
* Paired Training. Training a supervised model can produce high-quality results, but requires data pairing. This is the process of finding examples of inputs and their desired outputs for the model to learn from. Data pairing is laborious and impractical when training on multiple identities and facial behaviors. Some solutions include self-supervised training (using frames from the same video), the use of unpaired networks such as Cycle-GAN, or the manipulation of network embeddings.
* Identity leakage.  This is where the identity of the driver (i.e., the actor controlling the face in a reenactment) is partially transferred to the generated face. Some solutions proposed include attention mechanisms, few-shot learning, disentanglement, boundary conversions, and skip connections.
* Occlusions. When part of the face is obstructed with a hand, hair, glasses, or any other item then artifacts can occur. A common occlusion is a closed mouth which hides the inside of the mouth and the teeth. Some solutions include image segmentation during training and in-painting.
* Temporal coherence. In videos containing deepfakes, artifacts such as flickering and jitter can occur because the network has no context of the preceding frames. Some researchers provide this context or use novel temporal coherence losses to help improve realism. As the technology improves, the interference is diminishing.

Overall, deepfakes are expected to have several implications in media and society, media production, media representations, media audiences, gender, law, and regulation, and politics.<ref>{{cite journal |last=Karnouskos |first=Stamatis |title=Artificial Intelligence in Digital Media: The Era of Deepfakes |journal=IEEE Transactions on Technology and Society |date=2020 |volume=1 |issue=3 |page=1 |doi=10.1109/TTS.2020.3001312 |s2cid=221716206 |url=https://papers.duckdns.org/files/2020_Deepfakes.pdf |access-date=9 July 2020 |archive-date=14 July 2021 |archive-url=https://web.archive.org/web/20210714032923/https://papers.duckdns.org/files/2020_Deepfakes.pdf |url-status=live }}</ref>

=== Amateur development ===
The term deepfakes originated around the end of 2017 from a [[Reddit]] user named "deepfakes".<ref name=":3">{{cite web|url=https://www.vice.com/en_us/article/bjye8a/reddit-fake-porn-app-daisy-ridley|title=We Are Truly Fucked: Everyone Is Making AI-Generated Fake Porn Now|last=Cole|first=Samantha|date=24 January 2018|website=Vice|access-date=4 May 2019|archive-date=7 September 2019|archive-url=https://web.archive.org/web/20190907194524/https://www.vice.com/en_us/article/bjye8a/reddit-fake-porn-app-daisy-ridley|url-status=live}}</ref> He, as well as others in the Reddit community r/deepfakes, shared deepfakes they created; many videos involved celebrities' faces swapped onto the bodies of actresses in pornographic videos,<ref name=":3" /> while non-pornographic content included many videos with actor [[Nicolas Cage]]'s face swapped into various movies.<ref>{{cite web|url=https://mashable.com/2018/01/31/nicolas-cage-face-swapping-deepfakes/|title=People Are Using Face-Swapping Tech to Add Nicolas Cage to Random Movies and What Is 2018|last=Haysom|first=Sam|date=31 January 2018|website=Mashable|access-date=4 April 2019|archive-date=24 July 2019|archive-url=https://web.archive.org/web/20190724221500/https://mashable.com/2018/01/31/nicolas-cage-face-swapping-deepfakes/|url-status=live}}</ref>

Other online communities remain, including Reddit communities that do not share pornography, such as r/SFWdeepfakes (short for "safe for work deepfakes"), in which community members share deepfakes depicting celebrities, politicians, and others in non-pornographic scenarios.<ref>{{cite web|url=https://www.reddit.com/r/SFWdeepfakes/|title=r/SFWdeepfakes|website=Reddit|access-date=12 December 2018|archive-date=9 August 2019|archive-url=https://web.archive.org/web/20190809091757/https://www.reddit.com/r/SFWdeepfakes|url-status=live}}</ref> Other online communities continue to share pornography on platforms that have not banned deepfake pornography.<ref name=":4">{{cite web|url=https://www.dailydot.com/unclick/deepfake-sites-reddit-ban/|title=Here's where 'deepfakes,' the new fake celebrity porn, went after the Reddit ban|last=Hathaway|first=Jay|date=8 February 2018|website=The Daily Dot|access-date=22 December 2018|archive-date=6 July 2019|archive-url=https://web.archive.org/web/20190706092234/https://www.dailydot.com/unclick/deepfake-sites-reddit-ban/|url-status=live}}</ref>

=== Commercial development ===
In January 2018, a proprietary desktop application called FakeApp was launched.<ref>{{Cite web|url=https://www.online-tech-tips.com/computer-tips/what-is-a-deepfake-and-how-are-they-made/|title=What is a Deepfake and How Are They Made?|date=2019-05-23|website=Online Tech Tips|language=en-US|access-date=2019-11-08|archive-date=8 November 2019|archive-url=https://web.archive.org/web/20191108161241/https://www.online-tech-tips.com/computer-tips/what-is-a-deepfake-and-how-are-they-made/|url-status=live}}</ref> This app allows users to easily create and share videos with their faces swapped with each other.<ref>{{Cite web|url=https://www.theverge.com/2018/2/11/16992986/fakeapp-deepfakes-ai-face-swapping|title=I'm using AI to face-swap Elon Musk and Jeff Bezos, and I'm really bad at it|last=Robertson|first=Adi|date=2018-02-11|website=The Verge|language=en|access-date=2019-11-08|archive-date=24 March 2018|archive-url=https://web.archive.org/web/20180324223908/https://www.theverge.com/2018/2/11/16992986/fakeapp-deepfakes-ai-face-swapping|url-status=live}}</ref> As of 2019, FakeApp has been superseded by open-source alternatives such as Faceswap, command line-based DeepFaceLab, and web-based apps such as DeepfakesWeb.com <ref>{{Cite web|title=Deepfakes web {{!}} The best online faceswap app|url=https://deepfakesweb.com/|access-date=2021-02-21|website=Deepfakes web|archive-date=14 July 2021|archive-url=https://web.archive.org/web/20210714032902/https://deepfakesweb.com/|url-status=live}}</ref><ref name=":12">{{cite web|url=https://faceswap.dev|title=Faceswap is the leading free and Open Source multi-platform Deepfakes software.|date=15 October 2019|via=WordPress|access-date=14 July 2021|archive-date=31 May 2021|archive-url=https://web.archive.org/web/20210531200049/https://faceswap.dev/|url-status=live}}</ref><ref name=":13">{{cite web|url=https://github.com/iperov/DeepFaceLab|title=DeepFaceLab is a tool that utilizes machine learning to replace faces in videos. Includes prebuilt ready to work standalone Windows 7,8,10 binary (look readme.md).: iperov/DeepFaceLab|date=19 June 2019|via=GitHub|access-date=6 March 2019|archive-date=9 May 2019|archive-url=https://web.archive.org/web/20190509223348/https://github.com/iperov/DeepFaceLab|url-status=live}}</ref>

Larger companies started to use deepfakes.<ref name=":2" /> Corporate training videos can be created using deepfaked avatars and their voices, for example [[Synthesia (software company)|Synthesia]], which uses deepfake technology with avatars to create personalized videos.<ref>{{Cite web|last=Chandler|first=Simon|title=Why Deepfakes Are A Net Positive For Humanity|url=https://www.forbes.com/sites/simonchandler/2020/03/09/why-deepfakes-are-a-net-positive-for-humanity/|access-date=2020-11-03|website=Forbes|language=en|archive-date=16 November 2020|archive-url=https://web.archive.org/web/20201116050152/https://www.forbes.com/sites/simonchandler/2020/03/09/why-deepfakes-are-a-net-positive-for-humanity/|url-status=live}}</ref> The mobile app giant [[Momo (software)|Momo]] created the application Zao which allows users to superimpose their face on television and movie clips with a single picture.<ref name=":2" /> As of 2019 the Japanese AI company DataGrid made a full body deepfake that could create a person from scratch.<ref>{{Cite web|url=https://www.fastcompany.com/90407145/youve-been-warned-full-body-deepfakes-are-the-next-step-in-ai-based-human-mimicry|title=You've been warned: Full body deepfakes are the next step in AI-based human mimicry|last=Pangburn|first=D. J.|date=2019-09-21|website=Fast Company|language=en-US|access-date=2019-11-08|archive-date=8 November 2019|archive-url=https://web.archive.org/web/20191108161240/https://www.fastcompany.com/90407145/youve-been-warned-full-body-deepfakes-are-the-next-step-in-ai-based-human-mimicry|url-status=live}}</ref> They intend to use these for fashion and apparel.

As of 2020 [[audio deepfake]]s, and AI software capable of detecting deepfakes and [[digital cloning|cloning human voices]] after 5 seconds of listening time also exist.<ref>{{Cite web|url=https://www.theverge.com/2020/1/29/21080553/ftc-deepfakes-audio-cloning-joe-rogan-phone-scams|title=FTC says the tech behind audio deepfakes is getting better|first=Kim|last=Lyons|date=29 January 2020|website=The Verge|access-date=8 February 2020|archive-date=30 January 2020|archive-url=https://web.archive.org/web/20200130141130/https://www.theverge.com/2020/1/29/21080553/ftc-deepfakes-audio-cloning-joe-rogan-phone-scams|url-status=live}}</ref><ref>{{Cite web|url=https://google.github.io/tacotron/publications/speaker_adaptation/|title=Audio samples from "Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis"|website=google.github.io|access-date=8 February 2020|archive-date=14 November 2019|archive-url=https://web.archive.org/web/20191114031835/https://google.github.io/tacotron/publications/speaker_adaptation/|url-status=live}}</ref><ref>{{Cite arXiv|title=Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis|first1=Ye|last1=Jia|first2=Yu|last2=Zhang|first3=Ron J.|last3=Weiss|first4=Quan|last4=Wang|first5=Jonathan|last5=Shen|first6=Fei|last6=Ren|first7=Zhifeng|last7=Chen|first8=Patrick|last8=Nguyen|first9=Ruoming|last9=Pang|first10=Ignacio Lopez|last10=Moreno|first11=Yonghui|last11=Wu|date=2 January 2019|class=cs.CL|eprint=1806.04558}}</ref><ref>{{Cite web|url=http://www.niessnerlab.org/projects/roessler2019faceforensicspp.html|title=TUM Visual Computing: Prof. Matthias Nießner|website=www.niessnerlab.org|access-date=8 February 2020|archive-date=21 February 2020|archive-url=https://web.archive.org/web/20200221164942/http://niessnerlab.org/projects/roessler2019faceforensicspp.html|url-status=live}}</ref><ref>{{Cite web|url=https://spectrum.ieee.org/tech-talk/artificial-intelligence/machine-learning/facebook-ai-launches-its-deepfake-detection-challenge|title=Full Page Reload|website=IEEE Spectrum: Technology, Engineering, and Science News|date=11 December 2019|access-date=8 February 2020|archive-date=26 June 2020|archive-url=https://web.archive.org/web/20200626124300/https://spectrum.ieee.org/tech-talk/artificial-intelligence/machine-learning/facebook-ai-launches-its-deepfake-detection-challenge|url-status=live}}</ref><ref>{{Cite web|url=http://ai.googleblog.com/2019/09/contributing-data-to-deepfake-detection.html|title=Contributing Data to Deepfake Detection Research|access-date=8 February 2020|archive-date=5 February 2020|archive-url=https://web.archive.org/web/20200205104836/https://ai.googleblog.com/2019/09/contributing-data-to-deepfake-detection.html|url-status=live}}</ref> A mobile deepfake app, Impressions, was launched in March 2020. It was the first app for the creation of celebrity deepfake videos from mobile phones.<ref>{{Cite web|url=https://www.dailydot.com/debug/impressions-deepfake-app///|title=You can now deepfake yourself into a celebrity with just a few clicks|last=Thalen|first=Mikael|website=daily dot|language=en|access-date=2020-04-03|archive-date=6 April 2020|archive-url=https://web.archive.org/web/20200406221457/https://www.dailydot.com/debug/impressions-deepfake-app/|url-status=live}}</ref><ref>{{Cite web|url=https://kool1079.com/fun-or-fear-deepfake-app-puts-celebrity-faces-in-your-selfies//|title=Fun or Fear: Deepfake App Puts Celebrity Faces In Your Selfies|last=Matthews|first=Zane|website=Kool1079|language=en|access-date=2020-03-06|archive-date=24 March 2020|archive-url=https://web.archive.org/web/20200324141612/https://kool1079.com/fun-or-fear-deepfake-app-puts-celebrity-faces-in-your-selfies/|url-status=live}}</ref>

=== Resurrection ===
Deepfakes technology can not only be used to fabricate messages and actions of others, but it can also be used to revive deceased individuals. On 29 October 2020, Kim Kardashian posted a video of her late father [[Robert Kardashian]]; the face in the video of Robert Kardashian was created with deepfake technology.<ref>{{Cite news|date=2020-10-31|title=Kanye West, Kim Kardashian and her dad: Should we make holograms of the dead?|language=en-GB|work=BBC News|url=https://www.bbc.com/news/entertainment-arts-54753214|access-date=2020-11-11|archive-date=15 November 2020|archive-url=https://web.archive.org/web/20201115150249/https://www.bbc.com/news/entertainment-arts-54753214|url-status=live}}</ref> This hologram was created by the company Kaleida, where they use a combination of performance, motion tracking, SFX, VFX and DeepFake technologies in their [[Holography|hologram]] creation.<ref>{{Cite web|date=2020-10-30|title=Kanye West Gave Kim Kardashian a Hologram of Her Father for Her Birthday|url=https://www.themodems.com/post/kanye-west-gave-kim-kardashian-a-hologram-of-her-father-for-her-birthday|access-date=2020-11-11|website=themodems|language=en|archive-date=11 November 2020|archive-url=https://web.archive.org/web/20201111121855/https://www.themodems.com/post/kanye-west-gave-kim-kardashian-a-hologram-of-her-father-for-her-birthday|url-status=live}}</ref>

In 2020, Joaquin Oliver, victim of the [[Stoneman Douglas High School shooting|Parkland shooting]] was resurrected with deepfake technology. Oliver's parents teamed up on behalf of their organization Nonprofit Change the Ref, with McCann Health to produce this deepfake video advocating for gun-safety voting campaign.<ref>{{Cite web|date=2020-10-02|title=Parkland victim Joaquin Oliver comes back to life in heartbreaking plea to voters|url=https://adage.com/article/advertising/parkland-victim-joaquin-oliver-comes-back-life-heartbreaking-plea-voters/2285166|access-date=2020-11-11|website=adage.com|language=en|archive-date=11 November 2020|archive-url=https://web.archive.org/web/20201111061000/https://adage.com/article/advertising/parkland-victim-joaquin-oliver-comes-back-life-heartbreaking-plea-voters/2285166|url-status=live}}</ref> In this deepfake message, it shows Joaquin encouraging viewers to vote.

In 2022, [[Elvis Presley]] has been resurrected in [[America's Got Talent (season 17)|America's Got Talent 17]] using deepfake technology.<ref>{{Cite magazine |last1=Bowenbank |first1=Starr |date=2022-09-14 |title=Simon Cowell Duets With Elvis in Metaphysic's Latest Deepfake 'AGT' Performance: Watch |url=https://www.billboard.com/culture/tv-film/simon-cowell-duet-elvis-deepfake-agt-performance-1235138799/ |access-date=2022-11-08 |magazine=Billboard |language=en-US}}</ref>

== Techniques ==
Deepfakes rely on a type of [[Artificial neural network|neural network]] called an [[autoencoder]].<ref name=":14" /><ref>{{Cite web|url=https://www.alanzucconi.com/2018/03/14/understanding-the-technology-behind-deepfakes/|title=Understanding the Technology Behind DeepFakes|last=Zucconi|first=Alan|date=2018-03-14|website=Alan Zucconi|language=en-US|access-date=2019-11-08|archive-date=1 November 2019|archive-url=https://web.archive.org/web/20191101164537/https://www.alanzucconi.com/2018/03/14/understanding-the-technology-behind-deepfakes/|url-status=live}}</ref> These consist of an encoder, which reduces an image to a lower dimensional [[latent space]], and a decoder, which reconstructs the image from the latent representation.<ref>{{Cite web |date=2022-05-03 |title=What is a Deepfake? |url=https://blog.synthesys.io/what-is-deepfake/ |access-date=2022-05-17 |website=Blog - Synthesys |language=en-US}}</ref> Deepfakes utilize this architecture by having a universal encoder which encodes a person in to the latent space.<ref name=":15">{{Cite web|url=https://towardsdatascience.com/what-the-heck-are-vae-gans-17b86023588a|title=What The Heck Are VAE-GANs?|last=Kan|first=C. E.|date=2018-12-10|website=Medium|language=en|access-date=2019-11-08|archive-date=14 July 2021|archive-url=https://web.archive.org/web/20210714032915/https://towardsdatascience.com/what-the-heck-are-vae-gans-17b86023588a?gi=aa6ed506d7be|url-status=live}}</ref> The latent representation contains key features about their facial features and body posture. This can then be decoded with a model trained specifically for the target.<ref name=":14" /> This means the target's detailed information will be superimposed on the underlying facial and body features of the original video, represented in the latent space.<ref name=":14" />

A popular upgrade to this architecture attaches a [[generative adversarial network]] to the decoder.<ref name=":15" /> A [[General adversarial network|GAN]] trains a generator, in this case the decoder, and a discriminator in an adversarial relationship.<ref name=":15" /> The generator creates new images from the latent representation of the source material, while the discriminator attempts to determine whether or not the image is generated.<ref name=":15" /> This causes the generator to create images that mimic reality extremely well as any defects would be caught by the discriminator.<ref name=":16">{{Cite magazine|url=https://www.wired.com/story/these-new-tricks-can-outsmart-deepfake-videosfor-now/|title=These New Tricks Can Outsmart Deepfake Videos—for Now|magazine=Wired|access-date=2019-11-09|language=en|issn=1059-1028|archive-date=3 October 2019|archive-url=https://web.archive.org/web/20191003055035/https://www.wired.com/story/these-new-tricks-can-outsmart-deepfake-videosfor-now/|url-status=live}}</ref> Both algorithms improve constantly in a [[Zero-sum game|zero sum game]].<ref name=":15" /> This makes deepfakes difficult to combat as they are constantly evolving; any time a defect is determined, it can be corrected.<ref name=":16" />

==Applications==
=== Blackmail ===
Deepfakes can be used to generate blackmail materials that falsely incriminate a victim. A report by the American [[Congressional Research Service]] warned that deepfakes could be used to blackmail elected officials or those with access to [[classified information]] for [[espionage]] or [[Foreign electoral intervention|influence]] purposes.<ref name=CRS1>{{cite report |author2=Laurie A. Harris |author1=Kelley M. Tayler |date=June 8, 2021 |title=Deep Fakes and National Security |url=https://crsreports.congress.gov/product/pdf/IF/IF11333 |publisher=[[Congressional Research Service]] |page=1 |access-date=July 19, 2021}}</ref>

Alternatively, since the fakes cannot reliably be distinguished from genuine materials, victims of actual blackmail can now claim that the true artifacts are fakes, granting them plausible deniability. The effect is to void credibility of existing blackmail materials, which erases loyalty to blackmailers and destroys the blackmailer's control. This phenomenon can be termed "blackmail inflation", since it "devalues" real blackmail, rendering it worthless.<ref>{{Cite web|url=https://cultstate.com/2020/05/24/Podcast-18--Blackmail-Inflation/|last1=Limberg|first1=Peter|title=Blackmail Inflation|website=CultState|date=2020-05-24|access-date=2021-01-18|archive-date=24 January 2021|archive-url=https://web.archive.org/web/20210124155722/https://cultstate.com/2020/05/24/Podcast-18--Blackmail-Inflation/|url-status=live}}</ref> It is possible to utilize commodity GPU hardware with a small software program to generate this blackmail content for any number of subjects in huge quantities, driving up the supply of fake blackmail content limitlessly and in highly scalable fashion.<ref>{{Cite web|url=https://t.me/forKappy|title=For Kappy|website=Telegraph|date=2020-05-24|access-date=2021-01-18|archive-date=24 January 2021|archive-url=https://web.archive.org/web/20210124155641/https://t.me/forKappy|url-status=live}}</ref>

=== Pornography ===
{{main|Deepfake pornography}}
In 2017, Deepfake pornography prominently surfaced on the Internet, particularly on [[Reddit]].<ref name=":23">{{Cite news|url=https://variety.com/2018/digital/news/deepfakes-porn-adult-industry-1202705749/|title=Porn Producers Offer to Help Hollywood Take Down Deepfake Videos|last=Roettgers|first=Janko|date=2018-02-21|work=Variety|access-date=2018-02-28|language=en-US|archive-date=10 June 2019|archive-url=https://web.archive.org/web/20190610220204/https://variety.com/2018/digital/news/deepfakes-porn-adult-industry-1202705749/|url-status=live}}</ref> As of 2019, many deepfakes on the internet feature pornography of female celebrities whose likeness is typically used without their consent.<ref name=":24">{{Cite magazine|url=https://www.rollingstone.com/culture/culture-news/deepfakes-nonconsensual-porn-study-kpop-895605/|title=Deepfake Porn Is Still a Threat, Particularly for K-Pop Stars|last1=Dickson|first1=E. J.|date=2019-10-07|magazine=Rolling Stone|language=en-US|access-date=2019-11-09|archive-date=30 October 2019|archive-url=https://web.archive.org/web/20191030165258/https://www.rollingstone.com/culture/culture-news/deepfakes-nonconsensual-porn-study-kpop-895605/|url-status=live}}</ref>  A report published in October 2019 by Dutch cybersecurity startup Deeptrace estimated that 96% of all deepfakes online were pornographic.<ref name=":105">{{Cite web|url=https://regmedia.co.uk/2019/10/08/deepfake_report.pdf|title=The State of Deepfake - Landscape, Threats, and Impact|date=2019-10-01|work=Deeptrace|access-date=2020-07-07|language=en-US|archive-date=9 August 2020|archive-url=https://web.archive.org/web/20200809043229/https://regmedia.co.uk/2019/10/08/deepfake_report.pdf|url-status=live}}</ref> 
As of 2018, a [[Daisy Ridley]] deepfake first captured attention,<ref name=":23" /> among others.<ref>{{Cite web|url=https://www.businessinsider.com/deepfakes-explained-the-rise-of-fake-realistic-videos-online-2019-6|title=From porn to 'Game of Thrones': How deepfakes and realistic-looking fake videos hit it big|last=Goggin|first=Benjamin|website=Business Insider|access-date=2019-11-09|archive-date=8 November 2019|archive-url=https://web.archive.org/web/20191108193123/https://www.businessinsider.com/deepfakes-explained-the-rise-of-fake-realistic-videos-online-2019-6|url-status=live}}</ref><ref>{{Cite news|url=https://www.bbc.com/news/technology-42912529|title='Fake porn' has serious consequences|last=Lee|first=Dave|date=2018-02-03|access-date=2019-11-09|language=en-GB|archive-date=1 December 2019|archive-url=https://web.archive.org/web/20191201134131/https://www.bbc.com/news/technology-42912529|url-status=live}}</ref><ref name=":29">{{Cite web|url=https://www.vice.com/en_us/article/ywe4qw/gfycat-spotting-deepfakes-fake-ai-porn|title=Gfycat's AI Solution for Fighting Deepfakes Isn't Working|last=Cole|first=Samantha|date=2018-06-19|website=Vice|language=en|access-date=2019-11-09|archive-date=8 November 2019|archive-url=https://web.archive.org/web/20191108193129/https://www.vice.com/en_us/article/ywe4qw/gfycat-spotting-deepfakes-fake-ai-porn|url-status=live}}</ref> As of October 2019, most of the deepfake subjects on the internet were British and American actresses.<ref name=":24" /> However, around a quarter of the subjects are South Korean, the majority of which are K-pop stars.<ref name=":24" /><ref>{{Cite web|url=https://medium.com/@frenizoe/deepfake-porn-efb80f39bae3|title=Deepfake Porn Is Here To Stay|first=Freni|last=Zoe|date=24 November 2019|website=Medium|access-date=10 December 2019|archive-date=10 December 2019|archive-url=https://web.archive.org/web/20191210192315/https://medium.com/@frenizoe/deepfake-porn-efb80f39bae3|url-status=live}}</ref>

{{Anchor|DeepNude}}In June 2019, a downloadable [[Windows]] and [[Linux]] application called DeepNude was released that used neural networks, specifically [[generative adversarial networks]], to remove clothing from images of women. The app had both a paid and unpaid version, the paid version costing $50.<ref name=":30">{{cite web |last1=Cole |first1=Samantha |last2=Maiberg |first2=Emanuel |last3=Koebler |first3=Jason |title=This Horrifying App Undresses a Photo of Any Woman with a Single Click |url=https://www.vice.com/en_us/article/kzm59x/deepnude-app-creates-fake-nudes-of-any-woman |website=Vice |access-date=2 July 2019 |date=26 June 2019 |archive-date=2 July 2019 |archive-url=https://web.archive.org/web/20190702011315/https://www.vice.com/en_us/article/kzm59x/deepnude-app-creates-fake-nudes-of-any-woman |url-status=live }}</ref><ref>{{cite news |url=https://www.vice.com/en_us/article/8xzjpk/github-removed-open-source-versions-of-deepnude-app-deepfakes |publisher=[[Vice Media]] |title=GitHub Removed Open Source Versions of DeepNude |first=Joseph |last=Cox |date=9 July 2019 |access-date=14 July 2019 |archive-date=24 September 2020 |archive-url=https://web.archive.org/web/20200924083833/https://www.vice.com/en_us/article/8xzjpk/github-removed-open-source-versions-of-deepnude-app-deepfakes |url-status=live }}</ref> On 27 June the creators removed the application and refunded consumers.<ref>{{Cite web|url=https://twitter.com/deepnudeapp/status/1144307316231200768|title=pic.twitter.com/8uJKBQTZ0o|date=27 June 2019|access-date=3 August 2019|archive-date=6 April 2021|archive-url=https://web.archive.org/web/20210406183900/https://twitter.com/deepnudeapp/status/1144307316231200768|url-status=live}}</ref>

=== Politics ===
Deepfakes have been used to misrepresent well-known politicians in videos.

* In April 2018, [[Jordan Peele]] collaborated with [[BuzzFeed|Buzzfeed]] to create a deepfake of [[Barack Obama]] with Peele's voice; it served as a [[public service announcement]] to increase awareness of deepfakes.<ref>{{cite web |last1=Romano |first1=Aja |date=18 April 2018 |title=Jordan Peele's simulated Obama PSA is a double-edged warning against fake news |url=https://www.vox.com/2018/4/18/17252410/jordan-peele-obama-deepfake-buzzfeed |url-status=live |archive-url=https://web.archive.org/web/20190611142158/https://www.vox.com/2018/4/18/17252410/jordan-peele-obama-deepfake-buzzfeed |archive-date=11 June 2019 |access-date=10 September 2018 |website=Vox}}</ref>
* In 2018, in separate videos, the face of the Argentine President [[Mauricio Macri]] had been replaced by the face of [[Adolf Hitler]], and [[Angela Merkel]]'s face has been replaced with [[Donald Trump]]'s.<ref name=":0">{{cite web|url=https://www.aargauerzeitung.ch/leben/digital/wenn-merkel-ploetzlich-trumps-gesicht-traegt-die-gefaehrliche-manipulation-von-bildern-und-videos-132155720|title=Wenn Merkel plötzlich Trumps Gesicht trägt: die gefährliche Manipulation von Bildern und Videos|date=2018-02-03|publisher=az Aargauer Zeitung|access-date=9 April 2018|archive-date=13 April 2019|archive-url=https://web.archive.org/web/20190413014251/https://www.aargauerzeitung.ch/leben/digital/wenn-merkel-ploetzlich-trumps-gesicht-traegt-die-gefaehrliche-manipulation-von-bildern-und-videos-132155720|url-status=live}}</ref><ref>{{cite web|url=http://faktenfinder.tagesschau.de/hintergrund/deep-fakes-101.html|title=Deepfakes: Auf dem Weg in eine alternative Realität?|author=Patrick Gensing|access-date=9 April 2018|archive-date=11 October 2018|archive-url=https://web.archive.org/web/20181011182211/http://faktenfinder.tagesschau.de/hintergrund/deep-fakes-101.html|url-status=live}}</ref>
* In January 2019, [[Fox Broadcasting Company|Fox]] affiliate [[KCPQ]] aired a deepfake of Trump during [[January 2019 Oval Office address|his Oval Office address]], mocking his appearance and skin color. The employee found responsible for the video was subsequently fired.<ref>{{cite news |last1=Swenson |first1=Kyle |date=11 January 2019 |title=A Seattle TV station aired doctored footage of Trump's Oval Office speech. The employee has been fired. |language=en |newspaper=The Washington Post |url=https://www.washingtonpost.com/nation/2019/01/11/seattle-tv-station-aired-doctored-footage-trumps-oval-office-speech-employee-has-been-fired/ |url-status=live |access-date=11 January 2019 |archive-url=https://web.archive.org/web/20190415011409/https://www.washingtonpost.com/nation/2019/01/11/seattle-tv-station-aired-doctored-footage-trumps-oval-office-speech-employee-has-been-fired/ |archive-date=15 April 2019}}</ref>
* In June 2019, the United States [[House Intelligence Committee]] held hearings on the potential malicious use of deepfakes to sway elections.<ref>{{Cite web |last=O'Sullivan |first=Donie |date=4 June 2019 |title=Congress to investigate deepfakes as doctored Pelosi video causes stir |url=https://www.cnn.com/2019/06/04/politics/house-intelligence-committee-deepfakes-threats-hearing/index.html |url-status=live |archive-url=https://web.archive.org/web/20190629081003/https://www.cnn.com/2019/06/04/politics/house-intelligence-committee-deepfakes-threats-hearing/index.html |archive-date=29 June 2019 |access-date=2019-11-09 |website=CNN}}</ref>
* In April 2020, the Belgian branch of [[Extinction Rebellion]] published a deepfake video of Belgian Prime Minister Sophie Wilmès on Facebook.<ref>{{Cite web |title=#TellTheTruthBelgium |url=https://www.extinctionrebellion.be/en/ |url-status=live |archive-url=https://web.archive.org/web/20200425000040/https://www.extinctionrebellion.be/en |archive-date=25 April 2020 |access-date=2020-04-21 |website=Extinction Rebellion Belgium |language=en}}</ref> The video promoted a possible link between [[deforestation]] and [[COVID-19]]. It had more than 100,000 views within 24 hours and received many comments. On the Facebook page where the video appeared, many users interpreted the deepfake video as genuine.<ref>{{Cite web |last=Holubowicz |first=Gerald |date=2020-04-15 |title=Extinction Rebellion s'empare des deepfakes |url=https://journalism.design/les-deepfakes/extinction-rebellion-sempare-des-deepfakes/ |url-status=live |archive-url=https://web.archive.org/web/20200729050900/https://journalism.design/les-deepfakes/extinction-rebellion-sempare-des-deepfakes/ |archive-date=29 July 2020 |access-date=2020-04-21 |website=Journalism.design |language=fr}}</ref>
* During the [[2020 United States presidential election|2020 US Presidential campaign]], many deep fakes surfaced purporting [[Joe Biden]] in cognitive decline—falling asleep during an interview, getting lost, and misspeaking—all bolstering rumors of his decline.<ref name="Carnahan 2020">{{cite web |last=Carnahan |first=Dustin |title=Faked videos shore up false beliefs about Biden's mental health |website=The Conversation |date=2020-09-16 |url=http://theconversation.com/faked-videos-shore-up-false-beliefs-about-bidens-mental-health-145975 |access-date=2022-04-09}}</ref><ref name="Parker 2020">{{cite web |last=Parker |first=Ashley |title=Trump and allies ramp up efforts to spread disinformation and fake news |website=The Independent |date=2020-09-07 |url=https://www.independent.co.uk/news/world/americas/us-election-2020/trump-us-election-fake-news-biden-twitter-deep-fake-videos-b404815.html |url-access=registration |access-date=2022-04-09}}</ref>
* During the [[2020 Delhi Legislative Assembly election]] campaign, the Delhi Bharatiya Janata Party used similar technology to distribute a version of an English-language campaign advertisement by its leader, [[Manoj Tiwari (politician)|Manoj Tiwari]], translated into [[Haryanvi language|Haryanvi]] to target [[Haryana]] voters. A voiceover was provided by an actor, and AI trained using video of Tiwari speeches was used to lip-sync the video to the new voiceover. A party staff member described it as a "positive" use of deepfake technology, which allowed them to "convincingly approach the target audience even if the candidate didn't speak the language of the voter."<ref>{{Cite web|url=https://www.vice.com/en_in/article/jgedjb/the-first-use-of-deepfakes-in-indian-election-by-bjp|title=We've Just Seen the First Use of Deepfakes in an Indian Election Campaign|last=Christopher|first=Nilesh|date=2020-02-18|website=Vice|language=en|access-date=2020-02-19|archive-date=19 February 2020|archive-url=https://web.archive.org/web/20200219153000/https://www.vice.com/en_in/article/jgedjb/the-first-use-of-deepfakes-in-indian-election-by-bjp|url-status=live}}</ref>
*In 2020, [[Bruno Sartori]] produced deepfakes parodying politicians like [[Jair Bolsonaro]] and [[Donald Trump]].<ref>{{Cite news |url=https://www.economist.com/1843/2020/04/28/amabie-the-mythical-creature-making-a-coronavirus-comeback |title=Amabie: the mythical creature making a coronavirus comeback |date=2020-04-28 |access-date=2021-06-03 |newspaper=The Economist |issn=0013-0613 |archive-date=20 May 2021 |archive-url=https://web.archive.org/web/20210520200202/https://www.economist.com/1843/2020/04/28/amabie-the-mythical-creature-making-a-coronavirus-comeback |url-status=live }}</ref>
* In April 2021, politicians in a number of European countries were approached by pranksters [[Vovan and Lexus]], who are accused by critics of working for the [[Russia]]n state. They impersonated [[Leonid Volkov (politician)|Leonid Volkov]], a Russian opposition politician and chief of staff of the Russian opposition leader [[Alexei Navalny]]'s campaign, allegedly through deepfake technology.<ref>{{cite news |last1=Roth |first1=Andrew |title=European MPs targeted by deepfake video calls imitating Russian opposition |url=https://www.theguardian.com/world/2021/apr/22/european-mps-targeted-by-deepfake-video-calls-imitating-russian-opposition |access-date=29 March 2022 |work=[[The Guardian]] |date=22 April 2021}}</ref><ref>{{cite news |last1=Ivanov |first1=Maxim |last2=Rothrock |first2=Kevin |title=Hello, this is Leonid Volkov* Using deepfake video and posing as Navalny's right-hand man, Russian pranksters fool Latvian politicians and journalists into invitation and TV interview |url=https://meduza.io/en/feature/2021/04/22/hello-this-is-leonid-volkov |access-date=29 March 2022 |work=[[Meduza]] |date=22 April 2021}}</ref><ref>{{cite news |title=Dutch MPs in video conference with deep fake imitation of Navalny's Chief of Staff |url=https://nltimes.nl/2021/04/24/dutch-mps-video-conference-deep-fake-imitation-navalnys-chief-staff |access-date=29 March 2022 |work=[[NL Times]] |date=24 April 2021}}</ref><ref>{{cite news |title='Deepfake' Navalny Aide Targets European Lawmakers |url=https://www.themoscowtimes.com/2021/04/23/deepfake-navalny-aide-targets-european-lawmakers-a73717 |access-date=29 March 2022 |work=[[The Moscow Times]] |date=23 April 2021}}</ref> However, the pair told ''[[The Verge]]'' that they did not use deepfakes, and just used a [[look-alike]].<ref>{{cite news |last1=Vincent |first1=James |title='Deepfake' that supposedly fooled European politicians was just a look-alike, say pranksters |url=https://www.theverge.com/2021/4/30/22407264/deepfake-european-polticians-leonid-volkov-vovan-lexus |work=[[The Verge]] |date=30 April 2021}}</ref>

===Art===
In March 2018 the multidisciplinary artist Joseph Ayerle published the [[video art]]work ''Un'emozione per sempre 2.0'' (English title: ''The Italian Game''). The artist worked with Deepfake technology to create an ''AI actress'', a synthetic version of 80s movie star [[Ornella Muti]], traveling in time from 1978 to 2018. The [[Massachusetts Institute of Technology]] referred this artwork in the study "Collective Wisdom".<ref>Katerina Cizek, William Uricchio, and Sarah Wolozin: Collective Wisdom | Massachusetts Institute of Technology [https://wip.mitpress.mit.edu/pub/collective-wisdom-part-6] {{Webarchive|url=https://web.archive.org/web/20200304015015/https://wip.mitpress.mit.edu/pub/collective-wisdom-part-6|date=4 March 2020}}</ref> The artist used Ornella Muti's [[time travel]] to explore generational reflections, while also investigating questions about the role of provocation in the world of art.<ref>{{Cite web |url=http://www.ansa.it/toscana/notizie/2017/11/03/ornella-muti-in-cortometraggio-a-firenze_36349008-ce7b-4c7e-8742-43e28f7225f4.html |title=ANSA {{!}} Ornella Muti in cortometraggio a Firenze |date=3 November 2017 |access-date=27 February 2020 |archive-date=27 February 2020 |archive-url=https://web.archive.org/web/20200227220711/http://www.ansa.it/toscana/notizie/2017/11/03/ornella-muti-in-cortometraggio-a-firenze_36349008-ce7b-4c7e-8742-43e28f7225f4.html |url-status=live }}</ref> For the technical realization Ayerle used scenes of photo model [[Kendall Jenner]]. The program replaced Jenner's face by an AI calculated face of Ornella Muti. As a result, the AI actress has the face of the Italian actress Ornella Muti and the body of Kendall Jenner.

Deepfakes have been widely used in [[satire]] or to parody celebrities and politicians. The 2020 webseries ''[[Sassy Justice]]'', created by [[Trey Parker]] and [[Matt Stone]], heavily features the use of deepfaked public figures to satirize current events and raise awareness of deepfake technology.<ref>{{Cite web |date=2020-10-27 |title='South Park' creators launch new deepfake satire series 'Sassy Justice' |url=https://www.nme.com/news/tv/south-park-creators-launch-new-deepfake-satire-series-sassy-justice-2800657 |access-date=2022-06-07 |website=NME |language=en-GB}}</ref>

===Acting===
There has been speculation about deepfakes being used for creating digital actors for future films. Digitally constructed/altered humans have already been used in [[film]]s before, and deepfakes could contribute new developments in the near future.<ref>{{Cite news|url=https://www.theguardian.com/film/2019/jul/03/in-the-age-of-deepfakes-could-virtual-actors-put-humans-out-of-business|title=In the age of deepfakes, could virtual actors put humans out of business?|last=Kemp|first=Luke|date=2019-07-08|work=The Guardian|access-date=2019-10-20|language=en-GB|issn=0261-3077|archive-date=20 October 2019|archive-url=https://web.archive.org/web/20191020223601/https://www.theguardian.com/film/2019/jul/03/in-the-age-of-deepfakes-could-virtual-actors-put-humans-out-of-business|url-status=live}}</ref> Deepfake technology has already been used by fans to insert faces into existing films, such as the insertion of [[Harrison Ford]]'s young face onto Han Solo's face in ''[[Solo: A Star Wars Story]]'',<ref>{{Cite web|url=https://www.polygon.com/2018/10/17/17989214/harrison-ford-solo-movie-deepfake-technology|title=Harrison Ford is the star of Solo: A Star Wars Story thanks to deepfake technology|last=Radulovic|first=Petrana|date=2018-10-17|website=Polygon|language=en|access-date=2019-10-20|archive-date=20 October 2019|archive-url=https://web.archive.org/web/20191020223601/https://www.polygon.com/2018/10/17/17989214/harrison-ford-solo-movie-deepfake-technology|url-status=live}}</ref> and techniques similar to those used by deepfakes were used for the acting of Princess Leia and [[Grand Moff Tarkin]] in ''[[Rogue One]].''<ref>{{Cite web|url=https://www.technologyreview.com/s/612241/how-acting-as-carrie-fishers-puppet-made-a-career-for-rogue-ones-princess-leia/|title=How acting as Carrie Fisher's puppet made a career for Rogue One's Princess Leia|last=Winick|first=Erin|website=MIT Technology Review|language=en-US|access-date=2019-10-20|archive-date=23 October 2019|archive-url=https://web.archive.org/web/20191023063609/https://www.technologyreview.com/s/612241/how-acting-as-carrie-fishers-puppet-made-a-career-for-rogue-ones-princess-leia/|url-status=live}}</ref><ref>{{Cite web |date=2022-02-10 |title=Deepfake Luke Skywalker is another step down a ghoulish CGI path |url=https://www.gq-magazine.co.uk/culture/article/boba-fett-luke-skywalker |access-date=2022-06-03 |website=British GQ |language=en-GB}}</ref>

As deepfake technology increasingly advances, [[Disney]] has improved their visual effects using high-resolution deepfake face swapping technology.<ref name=":52">{{Cite web|title=High-Resolution Neural Face Swapping for Visual Effects {{!}} Disney Research Studios|url=https://studios.disneyresearch.com/2020/06/29/high-resolution-neural-face-swapping-for-visual-effects/|access-date=2020-10-07|language=en-US|archive-date=27 November 2020|archive-url=https://web.archive.org/web/20201127101746/https://studios.disneyresearch.com/2020/06/29/high-resolution-neural-face-swapping-for-visual-effects/|url-status=live}}</ref> Disney improved their technology through progressive training programmed to identify facial expressions, implementing a face-swapping feature, and iterating in order to stabilize and refine the output.<ref name=":52" /> This high-resolution deepfake technology saves significant operational and production costs.<ref name=":62">{{Cite web|title=Disney's deepfake technology could be used in film and TV|url=https://blooloop.com/news/disney-deepfake-face-swap-technology/|access-date=2020-10-07|website=Blooloop|date=21 July 2020|archive-date=12 November 2020|archive-url=https://web.archive.org/web/20201112044743/https://blooloop.com/news/disney-deepfake-face-swap-technology/|url-status=live}}</ref> Disney's deepfake generation model can produce AI-generated media at a 1024 x 1024 resolution, as opposed to common models that produce media at a 256 x 256 resolution.<ref name=":62" /> The technology allows Disney to {{nowrap|[[De-aging in film|de-age]]}} characters or revive deceased actors.<ref>{{Cite web|first=Jon A.|last=Lindley|date=2020-07-02|title=Disney Ventures Into Bringing Back 'Dead Actors' Through Facial Recognition|url=https://www.techtimes.com/articles/250776/20200702/disney-is-using-deepfakes-and-facial-recognition-to-bring-back-dead-actors.htm|access-date=2020-10-07|website=Tech Times|language=en|archive-date=14 July 2021|archive-url=https://web.archive.org/web/20210714032907/https://www.techtimes.com/articles/250776/20200702/disney-is-using-deepfakes-and-facial-recognition-to-bring-back-dead-actors.htm|url-status=live}}</ref>

The 2020 documentary ''[[Welcome to Chechnya]]'' used deepfake technology to obscure the identity of the people interviewed, so as to protect them from retaliation.<ref>{{Cite web |last=Dazed |date=2022-02-10 |title=Will deepfakes rewrite history as we know it? |url=https://www.dazeddigital.com/science-tech/article/55429/1/deepfake-museum-of-moving-image-media-unstable-evidence-on-screen |access-date=2022-06-03 |website=Dazed |language=en}}</ref>

=== Entertainment ===
On June 8, 2022,<ref>{{Cite web |date=2022-06-08 |title=The AGT Judges Had Priceless Reactions to That Simon Cowell Singing Audition |url=https://www.nbc.com/nbc-insider/agt-2022-see-the-judges-reactions-to-simon-cowell-singing |access-date=2022-08-29 |website=NBC Insider Official Site |language=en-US}}</ref> Daniel Emmet, a former [[America's Got Talent|AGT]] contestant, teamed up with the [[Artificial intelligence|AI]] [[Startup company|startup]]<ref>{{Cite web |last=Marr |first=Bernard |title=Can A Metaverse AI Win America's Got Talent? (And What That Means For The Industry) |url=https://www.forbes.com/sites/bernardmarr/2022/08/30/can-a-metaverse-ai-win-americas-got-talent-and-what-that-means-for-the-industry/ |access-date=2022-08-30 |website=Forbes |language=en}}</ref><ref>{{Cite web |last=Morales |first=Jowi |date=2022-06-10 |title=Deepfakes Go Mainstream: How Metaphysic's AGT Entry Will Impact Entertainment |url=https://www.makeuseof.com/deepfakes-mainstream-agt-entry/ |access-date=2022-08-29 |website=MUO |language=en-US}}</ref> Metaphysic AI, to create a hyperrealistic deepfake to make it appear as [[Simon Cowell]]. Cowell, notoriously known for severely critiquing contestants,<ref>{{Cite web |last=Carter |first=Rebecca |date=2019-06-01 |title=BGT viewers slam Simon Cowell for 'rude' and 'nasty' remark to contestant |url=https://www.entertainmentdaily.co.uk/tv/bgt-viewers-slam-simon-cowell-for-rude-and-nasty-remark-to-contestant/ |access-date=2022-08-31 |website=Entertainment Daily |language=en-GB}}</ref> was on stage interpreting "[[You're the Inspiration|You're The Inspiration]]" by [[Chicago (band)|Chicago]]. Emmet sang on stage as an image of Simon Cowell emerged on the screen behind him in flawless synchronicity.<ref>{{Citation |title=Simon Cowell Sings on Stage?! Metaphysic Will Leave You Speechless {{!}} AGT 2022 |url=https://www.youtube.com/watch?v=mPU0WNUzsBo&ab_channel=America'sGotTalent |language=en |access-date=2022-08-29}}</ref>

On August 30, 2022, [[Metaphysic AI]] had 'deep-fake' [[Simon Cowell]], [[Howie Mandel]] and [[Terry Crews]] singing [[opera]] on stage.<ref>{{Cite web |last=Segarra |first=Edward |title='AGT' judges Simon Cowell, Howie Mandel get 'deepfake' treatment by AI act Metaphysic: Watch here |url=https://www.usatoday.com/story/entertainment/tv/2022/08/30/agt-simon-cowell-calls-ai-opera-best-act-metaphysic/7947094001/ |access-date=2022-08-31 |website=USA TODAY |language=en-US}}</ref>

On September 13, 2022, Metaphysic AI performed with a [[Synthetic media|synthetic]] version of [[Elvis Presley]] for the finals of ''America's Got Talent''.<ref>{{Cite magazine |last=Bowenbank |first=Starr |date=2022-09-14 |title=Simon Cowell Duets With Elvis in Metaphysic's Latest Deepfake 'AGT' Performance: Watch |url=https://www.billboard.com/culture/tv-film/simon-cowell-duet-elvis-deepfake-agt-performance-1235138799/ |access-date=2022-09-15 |magazine=Billboard |language=en-US}}</ref>

===Internet meme===
In 2020, an [[internet meme]] emerged utilizing deepfakes to generate videos of people singing the chorus of {{nihongo|"Baka Mitai"|ばかみたい}}, a song from the game ''[[Yakuza 0]]'' in the video game series ''[[Yakuza (series)|Yakuza]]''. In the series, the melancholic song is sung by the player in a [[karaoke]] [[minigame]]. Most iterations of this meme use a 2017 video uploaded by user Dobbsyrules, who [[lip sync]]s the song, as a template.<ref>{{cite web |last1=C |first1=Kim |title=Coffin Dance and More: The Music Memes of 2020 So Far |url=https://www.musictimes.com/articles/82157/20200822/coffin-dance-and-more-the-music-memes-of-2020-so-far.htm |website=Music Times |access-date=26 August 2020 |date=22 August 2020 |archive-date=26 June 2021 |archive-url=https://web.archive.org/web/20210626152114/https://www.musictimes.com/articles/82157/20200822/coffin-dance-and-more-the-music-memes-of-2020-so-far.htm |url-status=live }}</ref><ref>{{cite news |last1=Sholihyn |first1=Ilyas |title=Someone deepfaked Singapore's politicians to lip-sync that Japanese meme song |url=https://www.asiaone.com/digital/someone-deepfaked-singapores-politicians-lip-sync-japanese-meme-song |access-date=26 August 2020 |agency=[[AsiaOne]] |date=7 August 2020 |archive-date=3 September 2020 |archive-url=https://web.archive.org/web/20200903160218/https://www.asiaone.com/digital/someone-deepfaked-singapores-politicians-lip-sync-japanese-meme-song |url-status=live }}</ref>

=== Social media ===
Deepfakes have begun to see use in popular social media platforms, notably through Zao, a Chinese deepfake app that allows users to substitute their own faces onto those of characters in scenes from films and television shows such as ''[[Romeo + Juliet]]'' and ''[[Game of Thrones]]''.<ref>{{Cite web|url=https://www.forbes.com/sites/jessedamiani/2019/09/03/chinese-deepfake-app-zao-goes-viral-faces-immediate-criticism-over-user-data-and-security-policy/|title=Chinese Deepfake App Zao Goes Viral, Faces Immediate Criticism Over User Data And Security Policy|last=Damiani|first=Jesse|website=Forbes|language=en|access-date=2019-11-18|archive-date=14 September 2019|archive-url=https://web.archive.org/web/20190914182816/https://www.forbes.com/sites/jessedamiani/2019/09/03/chinese-deepfake-app-zao-goes-viral-faces-immediate-criticism-over-user-data-and-security-policy/|url-status=live}}</ref> The app originally faced scrutiny over its invasive user data and privacy policy, after which the company put out a statement claiming it would revise the policy.<ref name=":2" /> In January 2020 Facebook announced that it was introducing new measures to counter this on its platforms.<ref>{{Cite web|url=https://www.independent.ie/business/technology/ahead-of-irish-and-us-elections-facebook-announces-new-measures-against-deepfake-videos-38840513.html|title=Ahead of Irish and US elections, Facebook announces new measures against 'deepfake' videos|website=Independent.ie|language=en|access-date=2020-01-07|archive-date=8 January 2020|archive-url=https://web.archive.org/web/20200108144047/https://www.independent.ie/business/technology/ahead-of-irish-and-us-elections-facebook-announces-new-measures-against-deepfake-videos-38840513.html|url-status=live}}</ref>

The [[Congressional Research Service]] cited unspecified evidence as showing that foreign [[Intelligence officer|intelligence operatives]] used deepfakes to create social media accounts with the purposes of [[Recruitment of spies|recruiting]] individuals with access to [[classified information]].<ref name=CRS1/>

In 2021, realistic deepfake videos of actor [[Tom Cruise]] were released on [[TikTok]], which went viral and garnered more than tens of millions of views. The deepfake videos featured an "artificial intelligence-generated doppelganger" of Cruise doing various activities such as teeing off at the golf course, showing off a coin trick, and biting into a lollipop. The creator of the clips, [[Belgium|Belgian]] [[Visual effects|VFX]] Artist Chris Umé,<ref>{{Cite web |date=2021-03-06 |title=How Belgian visual expert Chris Ume masterminded Tom Cruise's deepfakes |url=https://www.thestatesman.com/technology/science/belgian-visual-expert-chris-ume-masterminded-tom-cruises-deepfakes-1502955882.html |access-date=2022-08-24 |website=The Statesman |language=en-US}}</ref> said he first got interested in deepfakes in 2018 and saw the "creative potential" of them.<ref>{{cite news |author=Rachel Metz |title=How a deepfake Tom Cruise on TikTok turned into a very real AI company |work=CNN |url=https://edition.cnn.com/2021/08/06/tech/tom-cruise-deepfake-tiktok-company/index.html}}</ref><ref>{{cite web |last1=Corcoran |first1=Mark |last2=Henry |first2=Matt |date=23 June 2021 |title=This is not Tom Cruise. That's what has security experts so worried |url=https://www.abc.net.au/news/2021-06-24/tom-cruise-deepfake-chris-ume-security-washington-dc/100234772 |access-date=28 March 2022 |website=ABC News |language=en-AU}}</ref>

===Sockpuppets===
Deepfake photographs can be used to create [[sockpuppet (internet)|sockpuppets]], non-existent people, who are active both online and in traditional media. A deepfake photograph appears to have been generated together with a legend for an apparently non-existent person named Oliver Taylor, whose identity was described as a university student in the United Kingdom. The Oliver Taylor persona submitted opinion pieces in several newspapers and was active in online media attacking a British legal academic and his wife, as "terrorist sympathizers." The academic had drawn international attention in 2018 when he commenced a lawsuit in Israel against NSO, a surveillance company, on behalf of people in Mexico who alleged they were victims of NSO's [[phone hacking]] technology. ''Reuters'' could find only scant records for Oliver Taylor and "his" university had no records for him. Many experts agreed that the profile photo is a deepfake. Several newspapers have not retracted articles attributed to him or removed them from their websites. It is feared that such techniques are a new battleground in [[disinformation]].<ref>Reuters, 15 July 2020, [https://www.reuters.com/article/us-cyber-deepfake-activist-idUSKCN24G15E Deepfake Used to Attack Activist Couple Shows New Disinformation Frontier] {{Webarchive|url=https://web.archive.org/web/20200926073638/https://www.reuters.com/article/us-cyber-deepfake-activist-idUSKCN24G15E |date=26 September 2020 }}</ref>

Collections of deepfake photographs of non-existent people on [[social networks]] have also been deployed as part of Israeli [[partisan (politics)|partisan]] propaganda. The [[Facebook]] page "Zionist Spring" featured photos of non-existent persons along with their "testimonies" purporting to explain why they have abandoned their left-leaning politics to embrace the [[Right-wing politics|right-wing]], and the page also contained large numbers of posts from [[Prime Minister of Israel]] [[Benjamin Netanyahu]] and his son and from other Israeli right wing sources. The photographs appear to have been generated by "[[human image synthesis]]" technology, computer software that takes data from photos of real people to produce a realistic composite image of a non-existent person. In much of the "testimony," the reason given for embracing the political right was the shock of learning of alleged [[incitement]] to violence against the prime minister. Right wing Israeli television broadcasters then broadcast the "testimony" of these non-existent person based on the fact that they were being "shared" online. The broadcasters aired the story, even though the broadcasters could not find such people, explaining "Why does the origin matter?" Other Facebook fake profiles—profiles of fictitious individuals—contained material that allegedly contained such incitement against the right wing prime minister, in response to which the prime minister complained that there was a plot to murder him.<ref>972 Magazine, 12 August 2020, [https://www.972mag.com/leftists-for-bibi-deepfake-pro-netanyahu-propaganda-exposed/ "'Leftists for Bibi'? Deepfake Pro-Netanyahu Propaganda Exposed: According to a Series of Facebook Posts, the Israeli Prime Minister is Winning over Left-Wing Followers--Except that None of the People in Question Exist"] {{Webarchive|url=https://web.archive.org/web/20200814013617/https://www.972mag.com/leftists-for-bibi-deepfake-pro-netanyahu-propaganda-exposed/ |date=14 August 2020 }}</ref><ref>The Seventh Eye, 9 June 2020, [https://www.the7eye.org.il/375768 הפורנוגרפיה של ההסתהתומכי נתניהו ממשיכים להפיץ פוסטים מזויפים בקבוצות במדיה החברתית • לצד הטרלות מעלות גיחוך מופצות תמונות שקריות על מנת להגביר את השנאה והפילוג בחברה הישראלית] {{Webarchive|url=https://web.archive.org/web/20200818080717/https://www.the7eye.org.il/375768 |date=18 August 2020 }}</ref>

==Concerns==
===Fraud===
[[Audio deepfake]]s have been used as part of [[Social engineering (security)|social engineering]] scams, fooling people into thinking they are receiving instructions from a trusted individual.<ref name=":20">{{cite news|url=https://www.theverge.com/2019/9/5/20851248/deepfakes-ai-fake-audio-phone-calls-thieves-trick-companies-stealing-money|title=Thieves are now using AI deepfakes to trick companies into sending them money|last=Statt|first=Nick|date=5 Sep 2019|access-date=13 Sep 2019|archive-date=15 September 2019|archive-url=https://web.archive.org/web/20190915151504/https://www.theverge.com/2019/9/5/20851248/deepfakes-ai-fake-audio-phone-calls-thieves-trick-companies-stealing-money|url-status=live}}</ref> In 2019, a U.K.-based energy firm's CEO was scammed over the phone when he was ordered to transfer €220,000 into a Hungarian bank account by an individual who used audio deepfake technology to impersonate the voice of the firm's parent company's chief executive.<ref name=":19">{{Cite web|url=https://www.forbes.com/sites/jessedamiani/2019/09/03/a-voice-deepfake-was-used-to-scam-a-ceo-out-of-243000/|title=A Voice Deepfake Was Used To Scam A CEO Out Of $243,000|last=Damiani|first=Jesse|website=Forbes|language=en|access-date=2019-11-09|archive-date=14 September 2019|archive-url=https://web.archive.org/web/20190914192455/https://www.forbes.com/sites/jessedamiani/2019/09/03/a-voice-deepfake-was-used-to-scam-a-ceo-out-of-243000/|url-status=live}}</ref>

=== Credibility and authenticity ===
Though fake photos have long been plentiful, faking motion pictures has been more difficult, and the presence of deepfakes increases the difficulty of classifying videos as genuine or not.<ref name=":0" /> AI researcher Alex Champandard has said people should know how fast things can be corrupted with deepfake technology, and that the problem is not a technical one, but rather one to be solved by trust in information and journalism.<ref name=":0" /> Deepfakes can be leveraged to defame, impersonate, and spread disinformation.<ref>{{Cite web|title=Weaponised deep fakes: National security and democracy on JSTOR|url=https://www.jstor.org/stable/resrep25129|access-date=2020-10-21|website=www.jstor.org|language=en|archive-date=22 October 2020|archive-url=https://web.archive.org/web/20201022150916/https://www.jstor.org/stable/resrep25129|url-status=live}}</ref> The primary pitfall is that humanity could fall into an age in which it can no longer be determined whether a medium's content corresponds to the truth.<ref name=":0" />

Similarly, computer science associate professor [[Hao Li]] of the [[University of Southern California]] states that deepfakes created for malicious use, such as fake news, will be even more harmful if nothing is done to spread awareness of deepfake technology.<ref name="Perfect">{{Cite web|url=https://www.wbur.org/hereandnow/2019/10/02/deepfake-technology|title=Perfect Deepfake Tech Could Arrive Sooner Than Expected|website=www.wbur.org|language=en|access-date=2019-11-09|archive-date=30 October 2019|archive-url=https://web.archive.org/web/20191030164611/https://www.wbur.org/hereandnow/2019/10/02/deepfake-technology|url-status=live}}</ref> Li predicted that genuine videos and deepfakes would become indistinguishable in as soon as half a year, as of October 2019, due to rapid advancement in [[artificial intelligence]] and computer graphics.<ref name="Perfect" />

Former [[Google]] fraud czar [[Shuman Ghosemajumder]] has called deepfakes an area of "societal concern" and said that they will inevitably evolve to a point at which they can be generated automatically, and an individual could use that technology to produce millions of deepfake videos.<ref>{{Cite web|last=Sonnemaker|first=Tyler|title=As social media platforms brace for the incoming wave of deepfakes, Google's former 'fraud czar' predicts the biggest danger is that deepfakes will eventually become boring|url=https://www.businessinsider.com/google-ex-fraud-czar-danger-of-deepfakes-is-becoming-boring-2020-1|access-date=2021-04-14|website=Business Insider|archive-date=14 April 2021|archive-url=https://web.archive.org/web/20210414002924/https://www.businessinsider.com/google-ex-fraud-czar-danger-of-deepfakes-is-becoming-boring-2020-1|url-status=live}}</ref>

The consequences of a deepfake are not significant enough to destabilize the entire government system; however, deepfakes possess the ability to damage individual entities tremendously.<ref name=":72">{{Cite journal|last=Bateman|first=Jon|date=2020|title=Summary|journal=Deepfakes and Synthetic Media in the Financial System|url=https://www.jstor.org/stable/resrep25783.6|pages=1–2|access-date=28 October 2020|archive-date=20 April 2021|archive-url=https://web.archive.org/web/20210420005800/https://www.jstor.org/stable/resrep25783.6|url-status=live}}</ref> This is because deepfakes are often targeted at one individual, and/or their relations to others in hopes to create a narrative powerful enough to influence public opinion or beliefs. This can be done through deepfake voice phishing, which manipulates audio to create fake phone calls or conversations.<ref name=":72" /> Another method of deepfake use is fabricated private remarks, which manipulate media to convey individuals voicing damaging comments.<ref name=":72" />

In September 2020 Microsoft made public that they are developing a Deepfake detection software tool.<ref>{{cite news |last1=Kelion |first1=Leo |title=Deepfake detection tool unveiled by Microsoft |work=BBC News |date=September 2020 |url=https://www.bbc.com/news/technology-53984114 |access-date=15 April 2021 |archive-date=14 April 2021 |archive-url=https://web.archive.org/web/20210414182803/https://www.bbc.com/news/technology-53984114 |url-status=live }}</ref>

=== Example events ===
==== Barack Obama ====
On April 17, 2018, American actor [[Jordan Peele]], [[BuzzFeed]], and [[Monkeypaw Productions]] posted a deepfake of Barack Obama to YouTube, which depicted Barack Obama cursing and calling Donald Trump names.<ref>{{Cite web |last=Fagan |first=Kaylee |title=A viral video that appeared to show Obama calling Trump a 'dips---' shows a disturbing new trend called 'deepfakes' |url=https://www.businessinsider.com/obama-deepfake-video-insulting-trump-2018-4 |url-status=live |archive-url=https://web.archive.org/web/20200922174210/https://www.businessinsider.com/obama-deepfake-video-insulting-trump-2018-4 |archive-date=22 September 2020 |access-date=2020-11-03 |website=Business Insider}}</ref> In this deepfake Peele's voice and face were transformed and manipulated into those of Obama. The intent of this video was to portray the dangerous consequences and power of deepfakes, and how deepfakes can make anyone say anything.

==== Donald Trump ====
On May 5, 2019, Derpfakes posted a deepfake of [[Donald Trump]] to YouTube, based on a skit [[Jimmy Fallon]] performed on [[The Tonight Show Starring Jimmy Fallon|NBC's The Tonight Show]].<ref name=":34" /> In the original skit (aired May 4, 2016), Jimmy Fallon dressed as Donald Trump and pretended to participate in a phone call with Barack Obama, conversing in a manner that presented him to be bragging about his primary win in Indiana.<ref name=":34">{{Cite web|title=The rise of the deepfake and the threat to democracy|url=http://www.theguardian.com/technology/ng-interactive/2019/jun/22/the-rise-of-the-deepfake-and-the-threat-to-democracy|access-date=2020-11-03|website=The Guardian|language=en|archive-date=1 November 2020|archive-url=https://web.archive.org/web/20201101063543/https://www.theguardian.com/technology/ng-interactive/2019/jun/22/the-rise-of-the-deepfake-and-the-threat-to-democracy|url-status=live}}</ref> In the deepfake, Jimmy Fallon's face was transformed into Donald Trump's face, with the audio remaining the same. This deepfake video was produced by Derpfakes with a comedic intent.

'''Nancy Pelosi'''

In 2019, a clip from [[Nancy Pelosi]]'s speech at the [[Center for American Progress]] (given on May 22, 2019) in which the video was slowed down, in addition to the pitch of the audio being altered, to make it seem as if she were drunk, was widely distributed on social media. Critics argue that this was not a deepfake, but a shallowfake; a less sophisticated form of video manipulation.<ref>{{Cite web |last=Towers-Clark |first=Charles |title=Mona Lisa And Nancy Pelosi: The Implications Of Deepfakes |url=https://www.forbes.com/sites/charlestowersclark/2019/05/31/mona-lisa-and-nancy-pelosi-the-implications-of-deepfakes/ |url-status=live |archive-url=https://web.archive.org/web/20201123002751/https://www.forbes.com/sites/charlestowersclark/2019/05/31/mona-lisa-and-nancy-pelosi-the-implications-of-deepfakes/ |archive-date=23 November 2020 |access-date=2020-10-07 |website=Forbes |language=en}}</ref><ref>{{Cite web |date=21 April 2020 |title=What Is The Difference Between A Deepfake And Shallowfake? |url=https://deepfakenow.com/what-is-the-difference-between-a-deepfake-and-shallowfake/}}</ref>

==== Kim Jong-un and Vladimir Putin ====
[[File:Dictators - Kim Jong-Un by RepresentUs.webm|thumb|"Kim Jong-Un"]]

On September 29, 2020, deepfakes of [[North Korea]]n leader [[Kim Jong-un]] and [[Russia]]n President [[Vladimir Putin]] were uploaded to YouTube, created by a nonpartisan advocacy group [[RepresentUs]].<ref name=":82">{{Cite web |title=Deepfake Putin is here to warn Americans about their self-inflicted doom |url=https://www.technologyreview.com/2020/09/29/1009098/ai-deepfake-putin-kim-jong-un-us-election/ |url-status=live |archive-url=https://web.archive.org/web/20201030140905/https://www.technologyreview.com/2020/09/29/1009098/ai-deepfake-putin-kim-jong-un-us-election/ |archive-date=30 October 2020 |access-date=2020-10-07 |website=MIT Technology Review |language=en}}</ref>

[[File:Vladimir Putin warning Americans on election interference and increasing political divide.webm|thumb|Deepfake video: Vladimir Putin warning Americans on election interference and increasing political divide]]

The deepfakes of Kim and Putin were meant to air publicly as commercials to relay the notion that interference by these leaders in US elections would be detrimental to the United States' democracy. The commercials also aimed to shock Americans to realize how fragile democracy is, and how media and news can significantly influence the country's path regardless of credibility.<ref name=":82" /> However, while the commercials included an ending comment detailing that the footage was not real, they ultimately did not air due to fears and sensitivity regarding how Americans may react.<ref name=":82" />

====Volodymyr Zelenskyy====

On March 16, 2022, a one-minute long deepfake video depicting Ukraine's president [[Volodymyr Zelenskyy]] seemingly telling his soldiers to lay down their arms and surrender during the [[2022 Russian invasion of Ukraine]] was circulated on social media. Russian social media boosted it, but after it was debunked, Facebook and YouTube removed it. Twitter allowed the video in tweets where it was exposed as a fake, but said it would be taken down if posted to deceive people. Hackers inserted the disinformation into a live scrolling-text news crawl on TV station Ukraine 24, and the video appeared briefly on the station's website in addition to false claims that Zelenskyy had fled his country's capital, [[Kyiv]]. It was not immediately clear who created the deepfake, to which Zelenskyy responded with his own video, saying, "We don't plan to lay down any arms. Until our victory."<ref>{{cite web | url=https://www.npr.org/2022/03/16/1087062648/deepfake-video-zelenskyy-experts-war-manipulation-ukraine-russia | title=Deepfake video of Zelenskyy could be 'tip of the iceberg' in info war, experts warn | publisher=[[NPR]] | date=March 16, 2022 | access-date=March 17, 2022 | author=Allyn, Bobby}}</ref>

== Responses ==

=== Social media platforms ===

==== Twitter ====
[[Twitter]] is taking active measures to handle synthetic and manipulated media on their platform. In order to prevent disinformation from spreading, Twitter is placing a notice on tweets that contain manipulated media and/or deepfakes that signal to viewers that the media is manipulated.<ref name=":02">{{Cite web|title=Help us shape our approach to synthetic and manipulated media|url=https://blog.twitter.com/en_us/topics/company/2019/synthetic_manipulated_media_policy_feedback.html|access-date=2020-10-07|website=blog.twitter.com|language=en-us|archive-date=28 October 2020|archive-url=https://web.archive.org/web/20201028211949/https://blog.twitter.com/en_us/topics/company/2019/synthetic_manipulated_media_policy_feedback.html|url-status=live}}</ref> There will also be a warning that appears to users who plan on retweeting, liking, or engaging with the tweet.<ref name=":02" /> Twitter will also work to provide users a link next to the tweet containing manipulated or synthetic media that links to a Twitter Moment or credible news article on the related topic—as a debunking action.<ref name=":02" /> Twitter also has the ability to remove any tweets containing deepfakes or manipulated media that may pose a harm to users' safety.<ref name=":02" /> In order to better improve Twitter's detection of deepfakes and manipulated media, Twitter has asked users who are interested in partnering with them to work on deepfake detection solutions to fill out a form (that is due 27 November 2020).<ref>{{Cite web|title=TechCrunch|url=https://social.techcrunch.com/2019/11/11/twitter-drafts-a-deepfake-policy-that-would-label-and-warn-but-not-remove-manipulated-media/|access-date=2020-10-07|website=TechCrunch|date=11 November 2019 |language=en-US|archive-date=14 July 2021|archive-url=https://web.archive.org/web/20210714032908/https://techcrunch.com/2019/11/11/twitter-drafts-a-deepfake-policy-that-would-label-and-warn-but-not-remove-manipulated-media/|url-status=live}}</ref>

==== Facebook ====
[[Facebook]] has taken efforts towards encouraging the creation of deepfakes in order to develop state of the art deepfake detection software. Facebook was the prominent partner in hosting the Deepfake Detection Challenge (DFDC), held December 2019, to 2114 participants who generated more than 35,000 models.<ref name=":110">{{Cite web|title=Deepfake Detection Challenge Results: An open initiative to advance AI|url=https://ai.facebook.com/blog/deepfake-detection-challenge-results-an-open-initiative-to-advance-ai/|access-date=2020-10-07|website=ai.facebook.com|language=en|archive-date=29 October 2020|archive-url=https://web.archive.org/web/20201029023928/https://ai.facebook.com/blog/deepfake-detection-challenge-results-an-open-initiative-to-advance-ai|url-status=live}}</ref> The top performing models with the highest detection accuracy were analyzed for similarities and differences; these findings are areas of interest in further research to improve and refine  deepfake detection models .<ref name=":110" /> Facebook has also detailed that the platform will be taking down  media generated with artificial intelligence used to alter an individual's speech.<ref name=":210">{{Cite news|last=Paul|first=Katie|date=2020-02-04|title=Twitter to label deepfakes and other deceptive media|language=en|work=Reuters|url=https://www.reuters.com/article/us-twitter-security-idUSKBN1ZY2OV|access-date=2020-10-07|archive-date=10 October 2020|archive-url=https://web.archive.org/web/20201010081053/https://www.reuters.com/article/us-twitter-security-idUSKBN1ZY2OV|url-status=live}}</ref> However, media that has been edited to alter the order or context of words in one's message would remain on the site but be labeled as false, since it was not generated by artificial intelligence.<ref name=":210" />

=== Detection ===
Most of the academic research surrounding deepfakes focuses on the detection deepfake videos.<ref name=":18">{{Cite web |url=https://news.berkeley.edu/2019/06/18/researchers-use-facial-quirks-to-unmask-deepfakes/ |title=Researchers use facial quirks to unmask 'deepfakes' |first=Kara |last=Manke |date=2019-06-18 |website=Berkeley News |language=en-US|access-date=2019-11-09|archive-date=9 November 2019|archive-url=https://web.archive.org/web/20191109021126/https://news.berkeley.edu/2019/06/18/researchers-use-facial-quirks-to-unmask-deepfakes/|url-status=live}}</ref> One approach to deepfake detection is to use algorithms to recognize patterns and pick up subtle inconsistencies that arise in deepfake videos.<ref name=":18" /> For example, researchers have developed automatic systems that examine videos for errors such as irregular blinking patterns of lighting.<ref name=":11" /> This approach has been criticized because deepfake detection is characterized by a "[[Zero-sum game|moving goal post]]" where the production of deepfakes continues to change and improve as algorithms to detect deepfakes improve.<ref name=":18" /> In order to assess the most effective algorithms for detecting deepfakes, a coalition of leading technology companies hosted the Deepfake Detection Challenge to accelerate the technology for identifying manipulated content.<ref name=":21">{{Cite web |url=https://deepfakedetectionchallenge.ai/ |title=Join the Deepfake Detection Challenge (DFDC) |publisher=deepfakedetectionchallenge.ai |access-date=2019-11-08 |archive-date=12 January 2020 |archive-url=https://web.archive.org/web/20200112102819/https://deepfakedetectionchallenge.ai/ |url-status=live}}</ref> The winning model of the Deepfake Detection Challenge was 65% accurate on the holdout set of 4,000 videos.<ref>{{Cite web |title=Deepfake Detection Challenge Results: An open initiative to advance AI |url=https://ai.facebook.com/blog/deepfake-detection-challenge-results-an-open-initiative-to-advance-ai/ |access-date=2022-09-30 |website=ai.facebook.com |language=en}}</ref> A team at Massachusetts Institute of Technology published a paper in December 2021 demonstrating that ordinary humans are 69-72% accurate at identifying a random sample of 50 of these videos.<ref>{{Cite journal |last1=Groh |first1=Matthew |last2=Epstein |first2=Ziv |last3=Firestone |first3=Chaz |last4=Picard |first4=Rosalind |title=Deepfake detection by human crowds, machines, and machine-informed crowds |journal=Proceedings of the National Academy of Sciences|year=2022 |volume=119 |issue=1 |doi=10.1073/pnas.2110013119 |pmid=34969837 |pmc=8740705 |arxiv=2105.06496 |bibcode=2022PNAS..11910013G }}</ref>

A team at the University of Buffalo published a paper in October 2020 outlining their technique of using reflections of light in the eyes of 
those depicted to spot deepfakes with a high rate of success, even without the use of an AI detection tool, at least for the time being.<ref>{{Cite arXiv |last1=Hu |first1=Shu |last2=Li |first2=Yuezun |last3=Lyu |first3=Siwei |date=12 October 2020 |title=Exposing GAN-Generated Faces Using Inconsistent Corneal Specular Highlights |eprint=2009.11924 |class=cs.CV}}</ref>

Another team led by Wael AbdAlmageed with Visual Intelligence and Multimedia Analytics Laboratory (VIMAL) of the [[Information Sciences Institute]] at the [[University of Southern California|University Of Southern California]] developed two generations <ref name=":37">{{Cite web |title=Google Scholar |url=https://scholar.google.com/scholar?hl=en&as_sdt=0,39&q=Recurrent+Convolutional+Strategies+for+Face+Manipulation+Detection+in+Videos&btnG= |access-date=2022-04-30 |website=scholar.google.com}}</ref><ref name=":38">{{Cite web |title=Two-branch recurrent network for isolating deepfakes in videos |url=https://scholar.google.com/citations?view_op=view_citation&hl=en&user=tRGH8FkAAAAJ&citation_for_view=tRGH8FkAAAAJ:nb7KW1ujOQ8C |access-date=2022-04-30 |website=scholar.google.com}}</ref> of deepfake detectors based on [[convolutional neural network]]s. The first generation <ref name=":37" /> used [[recurrent neural network]]s to spot spatio-temporal inconsistencies to identify visual artifacts left by the deepfake generation process. The algorithm archived 96% accuracy on FaceForensics++; the only large-scale deepfake benchmark available at that time. The second generation <ref name=":38" /> used end-to-end deep networks to differentiate between artifacts and high-level semantic facial information using two-branch networks. The first branch propagates color information while the other branch suppresses facial content and amplifies low-level frequencies using [[Blob detection#The Laplacian of Gaussian|Laplacian of Gaussian (LoG)]]. Further, they included a new loss function that learns a compact representation of bona fide faces, while dispersing the representations (i.e. features) of deepfakes. VIMAL's approach showed state-of-the-art performance on FaceForensics++ and Celeb-DF benchmarks, and on [[#Volodymyr Zelenskyy|March 16th, 2022]] (the same day of the release), was used to identify the deepfake of Volodymyr Zelensky out-of-the-box without any retraining or knowledge of the algorithm with which the deepfake was created.

Other techniques use [[blockchain]] to verify the source of the media.<ref name=":22">{{Cite magazine |url=https://www.wired.com/story/the-blockchain-solution-to-our-deepfake-problems/ |title=The Blockchain Solution to Our Deepfake Problems |magazine=Wired |access-date=2019-11-09 |language=en |issn=1059-1028 |archive-date=7 November 2019 |archive-url=https://web.archive.org/web/20191107164023/https://www.wired.com/story/the-blockchain-solution-to-our-deepfake-problems/|url-status=live}}</ref> Videos will have to be verified through the ledger before they are shown on social media platforms.<ref name=":22" /> With this technology, only videos from trusted sources would be approved, decreasing the spread of possibly harmful deepfake media.<ref name=":22" />

Digitally signing of all video and imagery by cameras and video cameras, including smartphone cameras, was suggested to fight deepfakes.<ref name=":35">{{Cite web|last=Leetaru|first=Kalev|title=Why Digital Signatures Won't Prevent Deep Fakes But Will Help Repressive Governments|url=https://www.forbes.com/sites/kalevleetaru/2018/09/09/why-digital-signatures-wont-prevent-deep-fakes-but-will-help-repressive-governments/|access-date=2021-02-17|website=Forbes|language=en|archive-date=14 April 2021|archive-url=https://web.archive.org/web/20210414234733/https://www.forbes.com/sites/kalevleetaru/2018/09/09/why-digital-signatures-wont-prevent-deep-fakes-but-will-help-repressive-governments/|url-status=live}}</ref> That allows tracing every photograph or video back to its original owner that can be used to pursue dissidents.<ref name=":35" />

One easy way to uncover deepfake video calls consists in asking the caller to turn sideways.<ref>{{Cite web |date=2022-08-08 |title=To Uncover a Deepfake Video Call, Ask the Caller to Turn Sideways |url=https://metaphysic.ai/to-uncover-a-deepfake-video-call-ask-the-caller-to-turn-sideways/,%20https://metaphysic.ai/to-uncover-a-deepfake-video-call-ask-the-caller-to-turn-sideways/ |access-date=2022-08-24 |website=Metaphysic |language=en-US}}{{dead link|date=August 2022}}</ref>

===Internet reaction===
Since 2017, Samantha Cole of [[Vice (magazine)|Vice]] published a series of articles covering news surrounding deepfake pornography.<ref name=":31" /><ref name=":26" /><ref name=":32" /><ref name=":30" /><ref name=":29" /><ref name=":1">{{Cite web|url=https://www.vice.com/en_us/article/ywqgab/twitter-bans-deepfakes|title=Twitter Is the Latest Platform to Ban AI-Generated Porn|last=Cole|first=Samantha|date=2018-02-06|website=Vice|language=en|access-date=2019-11-08|archive-date=1 November 2019|archive-url=https://web.archive.org/web/20191101165115/https://www.vice.com/en_us/article/ywqgab/twitter-bans-deepfakes|url-status=live}}</ref><ref name=":25">{{cite web|url=https://www.vice.com/en_us/article/gydydm/gal-gadot-fake-ai-porn|title=AI-Assisted Fake Porn Is Here and We're All Fucked|last=Cole|first=Samantha|date=11 December 2017|website=Vice|access-date=19 December 2018|archive-date=7 September 2019|archive-url=https://web.archive.org/web/20190907212225/https://www.vice.com/en_us/article/gydydm/gal-gadot-fake-ai-porn|url-status=live}}</ref><ref name=":3" /> On 31 January 2018, [[Gfycat]] began removing all deepfakes from its site.<ref name=":32">{{Cite web|url=https://www.vice.com/en_us/article/vby5jx/deepfakes-ai-porn-removed-from-gfycat|title=AI-Generated Fake Porn Makers Have Been Kicked Off Their Favorite Host|last=Cole|first=Samantha|date=2018-01-31|website=Vice|language=en|access-date=2019-11-18|archive-date=1 November 2019|archive-url=https://web.archive.org/web/20191101165130/https://www.vice.com/en_us/article/vby5jx/deepfakes-ai-porn-removed-from-gfycat|url-status=live}}</ref><ref name=":28">{{Cite web|url=https://thenextweb.com/insider/2018/02/07/twitter-pornhub-and-other-platforms-ban-ai-generated-celebrity-porn/|title=Twitter, Pornhub and other platforms ban AI-generated celebrity porn|last=Ghoshal|first=Abhimanyu|date=2018-02-07|website=The Next Web|language=en-us|access-date=2019-11-09|archive-date=20 December 2019|archive-url=https://web.archive.org/web/20191220061859/https://thenextweb.com/insider/2018/02/07/twitter-pornhub-and-other-platforms-ban-ai-generated-celebrity-porn/|url-status=live}}</ref> On [[Reddit]], the r/deepfakes subreddit was banned on 7 February 2018, due to the policy violation of "involuntary pornography".<ref>{{Cite news|url=https://www.spiegel.de/netzwelt/web/deepfakes-online-plattformen-wollen-fake-promi-pornos-loeschen-a-1192170.html|title="Deepfakes": Firmen gehen gegen gefälschte Promi-Pornos vor|last=Böhm|first=Markus|date=2018-02-07|work=Spiegel Online|access-date=2019-11-09|archive-date=23 September 2019|archive-url=https://web.archive.org/web/20190923002744/https://www.spiegel.de/netzwelt/web/deepfakes-online-plattformen-wollen-fake-promi-pornos-loeschen-a-1192170.html|url-status=live}}</ref><ref>{{Cite web|url=https://futurezone.at/digital-life/deepfakes-reddit-loescht-forum-fuer-kuenstlich-generierte-fake-pornos/400003061|title=Deepfakes: Reddit löscht Forum für künstlich generierte Fake-Pornos|last=barbara.wimmer|website=futurezone.at|date=8 February 2018|language=de|access-date=2019-11-09|archive-date=8 February 2018|archive-url=https://web.archive.org/web/20180208194840/https://futurezone.at/digital-life/deepfakes-reddit-loescht-forum-fuer-kuenstlich-generierte-fake-pornos|url-status=live}}</ref><ref>{{Cite web|url=https://www.heise.de/newsticker/meldung/Deepfakes-Auch-Reddit-verbannt-Fake-Porn-3962987.html|title=Deepfakes: Auch Reddit verbannt Fake-Porn|website=heise online|language=de|access-date=2019-11-09|archive-date=10 April 2019|archive-url=https://web.archive.org/web/20190410050632/https://www.heise.de/newsticker/meldung/Deepfakes-Auch-Reddit-verbannt-Fake-Porn-3962987.html|url-status=live}}</ref><ref>{{Cite web|url=https://www.derstandard.at/story/2000073855676/reddit-verbannt-deepfake-pornos|title=Reddit verbannt Deepfake-Pornos - derStandard.de|website=DER STANDARD|language=de-AT|access-date=2019-11-09|archive-date=9 November 2019|archive-url=https://web.archive.org/web/20191109005835/https://www.derstandard.at/story/2000073855676/reddit-verbannt-deepfake-pornos|url-status=live}}</ref><ref>{{Cite web|url=https://www.theverge.com/2018/2/7/16982046/reddit-deepfakes-ai-celebrity-face-swap-porn-community-ban|title=Reddit bans 'deepfakes' AI porn communities|last=Robertson|first=Adi|date=2018-02-07|website=The Verge|language=en|access-date=2019-11-09|archive-date=24 September 2019|archive-url=https://web.archive.org/web/20190924035821/https://www.theverge.com/2018/2/7/16982046/reddit-deepfakes-ai-celebrity-face-swap-porn-community-ban|url-status=live}}</ref> In the same month, representatives from [[Twitter]] stated that they would suspend accounts suspected of posting non-consensual deepfake content.<ref name=":1" /> Chat site [[Discord (software)|Discord]] has taken action against deepfakes in the past,<ref>{{Cite web|url=https://www.businessinsider.com.au/discord-closes-down-deepfakes-server-ai-celebrity-porn-2018-1|title=Discord just shut down a chat group dedicated to sharing porn videos edited with AI to include celebrities|last=Price|first=Rob|date=2018-01-27|website=Business Insider Australia|language=en|access-date=2019-11-28|archive-date=15 December 2019|archive-url=https://web.archive.org/web/20191215182904/https://www.businessinsider.com.au/discord-closes-down-deepfakes-server-ai-celebrity-porn-2018-1|url-status=live}}</ref> and has taken a general stance against deepfakes.<ref name=":28" /><ref>{{Cite web|url=https://www.engadget.com/2018/02/07/twitter-joins-those-banning-deepfake-ai-porn/|title=Twitter bans 'deepfake' AI-generated porn|website=Engadget|language=en|access-date=2019-11-28|archive-date=15 December 2019|archive-url=https://web.archive.org/web/20191215182857/https://www.engadget.com/2018/02/07/twitter-joins-those-banning-deepfake-ai-porn/|url-status=live}}</ref> In September 2018, [[Google]] added "involuntary synthetic pornographic imagery" to its ban list, allowing anyone to request the block of results showing their fake nudes.<ref name="Fake-porn videos are being weaponized to harass and humiliate women: 'Everybody is a potential target'" />
{{check quotation}}
In February 2018, [[Pornhub]] said that it would ban deepfake videos on its website because it is considered "non consensual content" which violates their terms of service.<ref name=":26">{{Cite web|url=https://www.vice.com/en_us/article/zmwvdw/pornhub-bans-deepfakes|title=Pornhub Is Banning AI-Generated Fake Porn Videos, Says They're Nonconsensual|last=Cole|first=Samantha|date=2018-02-06|website=Vice|language=en|access-date=2019-11-09|archive-date=1 November 2019|archive-url=https://web.archive.org/web/20191101165117/https://www.vice.com/en_us/article/zmwvdw/pornhub-bans-deepfakes|url-status=live}}</ref> They also stated previously to Mashable that they will take down content flagged as deepfakes.<ref>{{Cite web|url=https://mashable.com/2018/02/02/what-are-deepfakes/|title=A guide to 'deepfakes,' the internet's latest moral crisis|first1=Damon|last1=Beres|first2=Marcus|last2=Gilmer|website=Mashable|date=2 February 2018|language=en|access-date=2019-11-09|archive-date=9 December 2019|archive-url=https://web.archive.org/web/20191209201826/https://mashable.com/2018/02/02/what-are-deepfakes/|url-status=live}}</ref> Writers from Motherboard from [[BuzzFeed News|Buzzfeed News]] reported that searching "deepfakes" on [[Pornhub]] still returned multiple recent deepfake videos.<ref name=":26" />

[[Facebook]] has previously stated that they would not remove deepfakes from their platforms.<ref name=":27">{{Cite web|url=https://www.technologyreview.com/f/613690/facebook-deepfake-zuckerberg-instagram-social-media-election-video/|title=Facebook has promised to leave up a deepfake video of Mark Zuckerberg|website=MIT Technology Review|language=en-US|access-date=2019-11-09|archive-date=16 October 2019|archive-url=https://web.archive.org/web/20191016060800/https://www.technologyreview.com/f/613690/facebook-deepfake-zuckerberg-instagram-social-media-election-video/|url-status=live}}</ref> The videos will instead be flagged as fake by third-parties and then have a lessened priority in user's feeds.<ref name=":31">{{Cite web|url=https://www.vice.com/en_us/article/ywyxex/deepfake-of-mark-zuckerberg-facebook-fake-video-policy|title=This Deepfake of Mark Zuckerberg Tests Facebook's Fake Video Policies|last=Cole|first=Samantha|date=2019-06-11|website=Vice|language=en|access-date=2019-11-09|archive-date=12 October 2019|archive-url=https://web.archive.org/web/20191012160019/https://www.vice.com/en_us/article/ywyxex/deepfake-of-mark-zuckerberg-facebook-fake-video-policy|url-status=live}}</ref> This response was prompted in June 2019 after a deepfake featuring a 2016 video of [[Mark Zuckerberg]] circulated on Facebook and [[Instagram]].<ref name=":27" />

In May 2022, [[Google]] officially changed the terms of service for their [[Project Jupyter#Industry adoption|Jupyter Notebook colabs]], banning the use of their colab service for the purpose of creating deepfakes.<ref>Anderson, Martin (2022). [https://www.unite.ai/google-has-banned-the-training-of-deepfakes-in-colab/ ''Google Has Banned the Training of Deepfakes in Colab''] {{Webarchive|url=https://web.archive.org/web/20220530122326/https://www.unite.ai/google-has-banned-the-training-of-deepfakes-in-colab/ |date=30 May 2022 }}, Unite.ai, May 28, 2022</ref> This came a few days after a VICE article had been published, claiming that "most deepfakes are non-consensual porn" and that the main use of popular deepfake software DeepFaceLab (DFL), "the most important technology powering the vast majority of this generation of deepfakes" which often was used in combination with Google colabs, would be to create non-consensual pornography, by pointing to the fact that among many other well-known examples of third-party DFL implementations such as deepfakes commissioned by [[The Walt Disney Company]], official music videos, and web series ''[[Sassy Justice]]'' by the creators of ''[[South Park]]'', DFL's [[GitHub]] page also links to deepfake porn website ''Mr. Deepfake'' and participants of the DFL Discord server also participate on ''Mr. Deepfakes''.<ref>Maiberg, Emanuel (2022). [https://www.vice.com/en/article/qjb7b7/ethical-deepfakes-deep-tom-cruise-ai-generated-porn ''It Takes 2 Clicks to Get From 'Deep Tom Cruise' to Vile Deepfake Porn''] {{Webarchive|url=https://web.archive.org/web/20220530140832/https://www.vice.com/en/article/qjb7b7/ethical-deepfakes-deep-tom-cruise-ai-generated-porn |date=30 May 2022 }}, VICE, May 17, 2022</ref>

=== Legal response ===
{{Globalize |section|date=November 2021}}
In the United States, there have been some responses to the problems posed by deepfakes. In 2018, the Malicious Deep Fake Prohibition Act was introduced to the [[United States Senate|US Senate]],<ref>{{Cite web|url=https://www.congress.gov/bill/115th-congress/senate-bill/3805|title=S.3805 - 115th Congress (2017-2018): Malicious Deep Fake Prohibition Act of 2018|last=Sasse|first=Ben|date=2018-12-21|website=www.congress.gov|access-date=2019-10-16|archive-date=16 October 2019|archive-url=https://web.archive.org/web/20191016053649/https://www.congress.gov/bill/115th-congress/senate-bill/3805|url-status=live}}</ref> and in 2019 the DEEPFAKES Accountability Act was introduced in the [[United States House of Representatives|House of Representatives]].<ref name=":5">{{Cite web|url=https://www.congress.gov/bill/116th-congress/house-bill/3230|title=H.R.3230 - 116th Congress (2019-2020): Defending Each and Every Person from False Appearances by Keeping Exploitation Subject to Accountability Act of 2019|last=Clarke|first=Yvette D.|date=2019-06-28|website=www.congress.gov|access-date=2019-10-16|archive-date=17 December 2019|archive-url=https://web.archive.org/web/20191217110329/https://www.congress.gov/bill/116th-congress/house-bill/3230|url-status=live}}</ref> Several states have also introduced legislation regarding deepfakes, including Virginia,<ref>{{Cite web|url=http://social.techcrunch.com/2019/07/01/deepfake-revenge-porn-is-now-illegal-in-virginia/|title='Deepfake' revenge porn is now illegal in Virginia|website=TechCrunch|date=July 2019 |language=en-US|access-date=2019-10-16|archive-date=14 July 2021|archive-url=https://web.archive.org/web/20210714032913/https://techcrunch.com/2019/07/01/deepfake-revenge-porn-is-now-illegal-in-virginia/|url-status=live}}</ref> Texas, California, and New York.<ref>{{Cite web|url=https://slate.com/technology/2019/07/congress-deepfake-regulation-230-2020.html|title=Congress Wants to Solve Deepfakes by 2020. That Should Worry Us.|last=Iacono Brown|first=Nina|date=2019-07-15|website=Slate Magazine|language=en|access-date=2019-10-16|archive-date=16 October 2019|archive-url=https://web.archive.org/web/20191016053644/https://slate.com/technology/2019/07/congress-deepfake-regulation-230-2020.html|url-status=live}}</ref> On 3 October 2019, California governor [[Gavin Newsom]] signed into law Assembly Bills No. 602 and No. 730.<ref name="AB602">{{Cite web|url=https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201920200AB602|title=Bill Text - AB-602 Depiction of individual using digital or electronic technology: sexually explicit material: cause of action.|website=leginfo.legislature.ca.gov|access-date=2019-11-09|archive-date=17 November 2019|archive-url=https://web.archive.org/web/20191117091545/https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201920200AB602|url-status=live}}</ref><ref name="AB730">{{Cite web|url=https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201920200AB730|title=Bill Text - AB-730 Elections: deceptive audio or visual media.|website=leginfo.legislature.ca.gov|access-date=2019-11-09|archive-date=31 October 2019|archive-url=https://web.archive.org/web/20191031021726/https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201920200AB730|url-status=live}}</ref> Assembly Bill No. 602 provides individuals targeted by sexually explicit deepfake content made without their consent with a cause of action against the content's creator.<ref name="AB602" /> Assembly Bill No. 730 prohibits the distribution of malicious deepfake audio or visual media targeting a candidate running for public office within 60 days of their election.<ref name="AB730" />

In November 2019 China announced that deepfakes and other synthetically faked footage should bear a clear notice about their fakeness starting in 2020. Failure to comply could be considered a [[crime]] the [[Cyberspace Administration of China]] stated on its website.<ref name="Reuters2019">{{cite web
 | url = https://www.reuters.com/article/us-china-technology/china-seeks-to-root-out-fake-news-and-deepfakes-with-new-online-content-rules-idUSKBN1Y30VU
 | title = China seeks to root out fake news and deepfakes with new online content rules
 | date = 2019-11-29
 | website = [[Reuters.com]]
 | publisher = [[Reuters]]
 | access-date = 2019-12-17
 | archive-date = 17 December 2019
 | archive-url = https://web.archive.org/web/20191217111759/https://www.reuters.com/article/us-china-technology/china-seeks-to-root-out-fake-news-and-deepfakes-with-new-online-content-rules-idUSKBN1Y30VU
 | url-status = live
 }}</ref> The Chinese government seems to be reserving the right to prosecute both users and [[online video platform]]s failing to abide by the rules.<ref name="TheVerge2019">{{cite web
 | url = https://www.theverge.com/2019/11/29/20988363/china-deepfakes-ban-internet-rules-fake-news-disclosure-virtual-reality
 | title = China makes it a criminal offense to publish deepfakes or fake news without disclosure
 | last = Statt
 | first = Nick
 | date = 2019-11-29
 | website = [[The Verge]]
 | access-date = 2019-12-17
 | archive-date = 22 December 2019
 | archive-url = https://web.archive.org/web/20191222164345/https://www.theverge.com/2019/11/29/20988363/china-deepfakes-ban-internet-rules-fake-news-disclosure-virtual-reality
 | url-status = live
 }}</ref>

In the United Kingdom, producers of deepfake material can be prosecuted for harassment, but there are calls to make deepfake a specific crime;<ref>[https://www.theguardian.com/world/2018/jun/21/call-for-upskirting-bill-to-include-deepfake-pornography-ban Call for upskirting bill to include 'deepfake' pornography ban] {{Webarchive|url=https://web.archive.org/web/20180621090804/https://www.theguardian.com/world/2018/jun/21/call-for-upskirting-bill-to-include-deepfake-pornography-ban |date=21 June 2018 }} ''[[The Guardian]]''</ref> in the United States, where charges as varied as [[identity theft]], [[cyberstalking]], and [[revenge porn]] have been pursued, the notion of a more comprehensive statute has also been discussed.<ref name="Fake-porn videos are being weaponized to harass and humiliate women: 'Everybody is a potential target'">{{cite news|url=https://www.washingtonpost.com/technology/2018/12/30/fake-porn-videos-are-being-weaponized-harass-humiliate-women-everybody-is-potential-target|title=Fake-porn videos are being weaponized to harass and humiliate women: 'Everybody is a potential target'|last=Harrell|first=Drew|newspaper=The Washington Post|access-date=2019-01-01|archive-date=2 January 2019|archive-url=https://web.archive.org/web/20190102031512/https://www.washingtonpost.com/technology/2018/12/30/fake-porn-videos-are-being-weaponized-harass-humiliate-women-everybody-is-potential-target/|url-status=live}}</ref>

In Canada, the [[Communications Security Establishment]] released a report which said that deepfakes could be used to interfere in Canadian politics, particularly to discredit politicians and influence voters.<ref>[https://cyber.gc.ca/sites/default/files/publications/tdp-2019-report_e.pdf] {{Webarchive|url=https://web.archive.org/web/20191122155500/https://cyber.gc.ca/sites/default/files/publications/tdp-2019-report_e.pdf|date=22 November 2019}} see page 18</ref><ref>{{Cite web|url=https://election.ctvnews.ca/how-deepfakes-could-impact-the-2019-canadian-election-1.4586847|title=How deepfakes could impact the 2019 Canadian election|last=Bogart|first=Nicole|date=2019-09-10|website=Federal Election 2019|language=en|access-date=2020-01-28|archive-date=27 January 2020|archive-url=https://web.archive.org/web/20200127163749/https://election.ctvnews.ca/how-deepfakes-could-impact-the-2019-canadian-election-1.4586847|url-status=live}}</ref> As a result, there are multiple ways for citizens in Canada to deal with deepfakes if they are targeted by them.<ref>{{Cite web|url=https://mcmillan.ca/What-Can-The-Law-Do-About-Deepfake|title=What Can The Law Do About Deepfake|website=mcmillan.ca|language=en|access-date=2020-01-28|archive-date=7 December 2019|archive-url=https://web.archive.org/web/20191207025712/https://mcmillan.ca/What-Can-The-Law-Do-About-Deepfake|url-status=live}}</ref>

==== Response from DARPA ====
In 2018, the [[Defense Advanced Research Projects Agency]] (DARPA) funded a project where individuals will compete to create AI-generated videos, audio, and images as well as automated tools to detect these deepfakes.<ref>{{Cite web|title=The US military is funding an effort to catch deepfakes and other AI trickery|url=https://www.technologyreview.com/2018/05/23/142770/the-us-military-is-funding-an-effort-to-catch-deepfakes-and-other-ai-trickery/|access-date=2020-10-07|website=MIT Technology Review|language=en|archive-date=1 November 2020|archive-url=https://web.archive.org/web/20201101063502/https://www.technologyreview.com/2018/05/23/142770/the-us-military-is-funding-an-effort-to-catch-deepfakes-and-other-ai-trickery/|url-status=live}}</ref> In 2019, DARPA hosted a "proposers day" for a project affiliated with the Semantic Forensics Program where researchers were driven to prevent viral spread of AI-manipulated media.<ref name=":33">{{Cite web|title=DARPA Is Taking On the Deepfake Problem|url=https://www.nextgov.com/emerging-tech/2019/08/darpa-taking-deepfake-problem/158980/|access-date=2020-10-07|website=Nextgov.com|language=en|archive-date=28 October 2020|archive-url=https://web.archive.org/web/20201028083255/https://www.nextgov.com/emerging-tech/2019/08/darpa-taking-deepfake-problem/158980/|url-status=live}}</ref> DARPA and the Semantic Forensics Program were also working together to detect AI-manipulated media through efforts in training computers to utilize common sense, logical reasoning.<ref name=":33" /> In 2020 DARPA created a Media Forensics (MediFor) program, to detect and mitigate the increasing harm that deepfakes and AI-generated media posed, to provide information regarding how the media was created and to address and emphasize the consequential role of deepfakes and their influence upon decision making.<ref name=":42">{{Cite web|title=Media Forensics|url=https://www.darpa.mil/program/media-forensics|access-date=2020-10-07|website=www.darpa.mil|archive-date=29 October 2020|archive-url=https://web.archive.org/web/20201029173807/https://www.darpa.mil/program/media-forensics|url-status=live}}</ref>

==In popular culture==
* The 1986 Mid-December issue of ''[[Analog Science Fiction and Fact|Analog]]'' magazine published the novelette "Picaper" by Jack Wodhams. Its plot revolves around digitally enhanced or digitally generated videos produced by skilled hackers serving unscrupulous lawyers and political figures.<ref name="1986-picaper">{{cite web |url=http://www.isfdb.org/cgi-bin/title.cgi?48679 |title=Picaper |publisher=[[Internet Speculative Fiction Database]] |access-date=9 July 2019 |archive-date=29 July 2020 |archive-url=https://web.archive.org/web/20200729073914/http://www.isfdb.org/cgi-bin/title.cgi?48679 |url-status=live }}</ref>
* The 1987 film ''[[The Running Man (1987 film)|The Running Man]]'' starring Arnold Schwarzenegger depicts an autocratic government using computers to digitally replace the faces of actors with those of wanted fugitives to make it appear the fugitives had been neutralized.
* In the 1992 techno-thriller ''[[A Philosophical Investigation]]'' by [[Philip Kerr]], "Wittgenstein", the main character and a serial killer, makes use of both a software similar to deepfake and a virtual reality suit for having sex with an avatar of Isadora "Jake" Jakowicz, the female police lieutenant assigned to catch him.<ref name="1992-API">{{Cite book |title=A Philosophical Investigation |author=Philip Kerr |year=2010 | isbn=978-0143117537}}</ref>
* The 1993 film ''[[Rising Sun (film)|Rising Sun]]'' starring Sean Connery and Wesley Snipes depicts another character, Jingo Asakuma, who reveals that a computer disc has digitally altered personal identities to implicate a competitor.
*  Deepfake technology is part of the plot of the 2019 [[BBC One]] drama ''[[The Capture (TV series)|The Capture]]''. The series follows British ex-soldier Shaun Emery, who is accused of assaulting and abducting his barrister. Expertly doctored [[CCTV]] footage is used to set him up and mislead the police investigating him.<ref>{{Cite news |last1=Bernal |first1=Natasha |title=The disturbing truth behind The Capture and real life deepfakes |url=https://www.telegraph.co.uk/technology/2019/10/08/truth-behind-deepfake-video-bbc-ones-thriller-capture/ |access-date=24 October 2019 |work=The Telegraph |date=8 October 2019 |archive-date=14 October 2019 |archive-url=https://web.archive.org/web/20191014090045/https://www.telegraph.co.uk/technology/2019/10/08/truth-behind-deepfake-video-bbc-ones-thriller-capture/ |url-status=live }}</ref><ref>{{cite news |last1=Crawley |first1=Peter |title=The Capture: A BBC thriller of surveillance, distortion and duplicity |url=https://www.irishtimes.com/culture/tv-radio-web/the-capture-a-bbc-thriller-of-surveillance-distortion-and-duplicity-1.4008823 |access-date=24 October 2019 |newspaper=The Irish Times |date=5 September 2019 |language=en |archive-date=9 September 2019 |archive-url=https://web.archive.org/web/20190909044130/https://www.irishtimes.com/culture/tv-radio-web/the-capture-a-bbc-thriller-of-surveillance-distortion-and-duplicity-1.4008823 |url-status=live }}</ref>
* ''Al Davis vs. the NFL'': The narrative structure of this 2021 documentary, part of [[ESPN]]'s ''[[30 for 30]]'' documentary series, uses deepfake versions of the film's two central characters, both deceased—[[Al Davis]], who owned the [[Las Vegas Raiders]] during the team's tenure in [[History of the Oakland Raiders|Oakland]] and [[History of the Los Angeles Raiders|Los Angeles]], and [[Pete Rozelle]], the [[National Football League|NFL]] commissioner who frequently clashed with Davis.<ref>{{Cite press release |url=https://espnpressroom.com/us/press-releases/2021/01/espn-films-latest-30-for-30-documentary-al-davis-vs-the-nfl-to-premiere-february-4/ |title=ESPN Films Latest 30 for 30 Documentary ''Al Davis vs. The NFL'' to Premiere February 4 |publisher=ESPN |date=January 15, 2021 |access-date=February 5, 2021 |archive-date=6 February 2021 |archive-url=https://web.archive.org/web/20210206211440/https://espnpressroom.com/us/press-releases/2021/01/espn-films-latest-30-for-30-documentary-al-davis-vs-the-nfl-to-premiere-february-4/ |url-status=live}}</ref><ref>{{Cite web |url=https://www.forbes.com/sites/shlomosprung/2021/02/02/al-davis-vs-the-nfl-uses-deepfake-technology-to-bring-late-raiders-owner-pete-rozelle-back-to-life/ |title=ESPN Documentary 'Al Davis Vs The NFL' Uses Deepfake Technology To Bring Late Raiders Owner Back To Life |first=Shlomo |last=Sprung |work=Forbes |date=February 1, 2021 |access-date=February 4, 2021 |archive-date=14 April 2021 |archive-url=https://web.archive.org/web/20210414230505/https://www.forbes.com/sites/shlomosprung/2021/02/02/al-davis-vs-the-nfl-uses-deepfake-technology-to-bring-late-raiders-owner-pete-rozelle-back-to-life/ |url-status=live }}</ref>
* Deepfake technology is featured in "Impawster Syndrome", the 57th episode of the Canadian police series ''[[Hudson & Rex]]'', first broadcast on 6 January 2022, in which a member of the St. John's police team is investigated on suspicion of robbery and assault due to doctored CCTV footage using his likeness.<ref>{{Cite web |url=https://www.citytv.com/show/hudson-rex/ |title=Hudson and Rex}}</ref>
* Using deepfake technology in his music video for his 2022 single, "[[The Heart Part 5]]", musician [[Kendrick Lamar]] transformed into figures resembling [[Nipsey Hussle]], [[O. J. Simpson|O.J. Simpson]], and [[Kanye West]], among others.<ref name=":39">{{Cite web |last=Wood |first=Mikael |date=2022-05-09 |title=Watch Kendrick Lamar morph into O.J., Kanye, Kobe, Nipsey Hussle in new video |url=https://www.latimes.com/entertainment-arts/music/story/2022-05-09/kendrick-lamar-new-video-the-heart-part-5-deepfake |access-date=2022-05-10 |website=Los Angeles Times |language=en-US}}</ref> The deepfake technology in the video was created by Deep Voodoo, a studio led by [[Trey Parker]] and [[Matt Stone]], who created ''[[South Park]]''.<ref name=":39" />
* [[Aloe Blacc]] honored his long-time collaborator [[Avicii]] four years after his death by performing their song "[[Wake Me Up (Avicii song)|Wake Me Up]]"<ref>{{Citation |title=Aloe Blacc - Wake Me Up (Universal Language Mix) |url=https://www.youtube.com/watch?v=TzofRTcoPsU |language=en |access-date=2022-08-24}}</ref> in [[English language|English]], [[Spanish language|Spanish]], and [[Mandarin Chinese|Mandarin]], using deepfake technologies.<ref>{{Cite web |date=2022-05-05 |title=Watch Aloe Blacc Perform "Wake Me Up" in 3 Languages to Honor Avicii Using Respeecher AI Translation |url=https://voicebot.ai/2022/05/05/watch-aloe-blacc-perform-wake-me-up-in-3-languages-to-honor-avicii-using-respeecher-ai-translation/ |access-date=2022-08-24 |website=Voicebot.ai |language=en-US}}</ref>

==See also==
* [[15.ai]]
* [[Computer facial animation]]
* [[Digital cloning]]
* [[Facial motion capture]]
* [[Hyperreality]]
* [[Identity replacement technology]]
* [[Interactive online characters]]
* [[Regulation of artificial intelligence]]
* [[StyleGAN]]
* [[Synthetic media]]
* [[Uncanny valley]]
* [[Virtual actor]]

==References==
{{reflist}}

==External links==
{{Commons category}}
*{{Cite news |first=Ben |last=Sasse |date=19 October 2018 |title=This New Technology Could Send American Politics into a Tailspin |url=https://www.washingtonpost.com/opinions/the-real-scary-news-about-deepfakes/2018/10/19/6238c3ce-d176-11e8-83d6-291fcead2ab1_story.html |department=Opinions  |newspaper=[[The Washington Post]] |access-date=10 July 2019}}
*[https://www.asvspoof.org/ Fake/Spoof Audio Detection Challenge (ASVspoof)]
*[https://deepfakedetectionchallenge.ai/ Deepfake Detection Challenge (DFDC)]
*[https://deepfakes.virtuality.mit.edu/wp-content/uploads/2021/08/Media-Literacy-Bibliography.pdf Bibliography: Media Literacy in the Age of Deepfakes]. Curated by Dr Joshua Glick.

{{Differentiable computing}}
{{Media manipulation}}

[[Category:Applications of computer vision]]
[[Category:Applications of artificial intelligence]]
[[Category:Computer graphics]]
[[Category:Deep learning]]
[[Category:Identity theft]]
[[Category:Special effects]]
[[Category:2010s neologisms]]
[[Category:Internet memes introduced in 2020]]
[[Category:Articles containing video clips]]
[[Category:Deepfakes| ]]
[[Category:Media studies]]
[[Category:2018 neologisms]]