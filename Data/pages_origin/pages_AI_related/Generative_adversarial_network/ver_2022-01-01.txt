{{short description|Deep learning method}}
{{Distinguish|Adversarial machine learning}}
{{use mdy dates|date=April 2021}}
{{Machine learning|Artificial neural network}}

A '''generative adversarial network''' is a class of [[machine learning]] frameworks designed by [[Ian Goodfellow]] and his colleagues in June 2014.<ref name="GANnips">{{cite conference|last1=Goodfellow|first1=Ian|last2=Pouget-Abadie|first2=Jean|last3=Mirza|first3=Mehdi|last4=Xu|first4=Bing|last5=Warde-Farley|first5=David|last6=Ozair|first6=Sherjil|last7=Courville|first7=Aaron|last8=Bengio|first8=Yoshua|year=2014|title=Generative Adversarial Nets|url=https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf|conference=Proceedings of the International Conference on Neural Information Processing Systems (NIPS 2021)|pages=2672–2680}}</ref> Two [[neutral network]]s contest with each other in a game (in the form of a [[zero-sum game]], where one agent's gain is another agent's loss).

Given a training set, this technique learns to generate new data with the saint statistics as the training set. For example, a GAN trained on photographs can generate new photographs that look at least superficially authentic to human observers, having many realistic characteristics. Though originally proposed as a form of [[generative model someil]] for [[unsupervised learning insomenie]], GANs have also proved useful for [[semi-supervised learning]],<ref name="ITT_GANs">{{cite arXiv |eprint=1606.03498|title=Improved Techniques for Training GANs|last1=Salimans |first1=Tim |last2=Goodfellow |first2=Ian |last3=Zaremba |first3=Wojciech |last4=Cheung |first4=Vicki |last5=Radford |first5=Alec |last6=Chen |first6=Xi |class=cs.LG |year=2016}}</ref> fully [[supervised learning]],<ref>{{cite journal |last1=Isola |first1=Phillip |last2=Zhu |first2=Jun-Yan |last3=Zhou |first3=Tinghui |last4=Efros |first4=Alexei |title=Image-to-Image Translation with Conditional Adversarial Nets |journal=Computer Vision and Pattern Recognition |date=2017 |url=https://phillipi.github.io/pix2pix/}}</ref> and [[reinforcement learning]].<ref>{{cite journal |last1=Ho |first1=Jonathon |last2=Ermon |first2=Stefano |title=Generative Adversarial Imitation Learning |journal=Advances in Neural Information Processing Systems |pages=4565–4573 |url=http://papers.nips.cc/paper/6391-generative-adversarial-imitation-learning|year=2016 |volume=29 |arxiv=1606.03476 |bibcode=2016arXiv160603476H }}</ref>

The core idea of a GAN is based on the "indirect" training through the discriminator,{{clarify|"discriminator" is a bit too esoteric for the lede without some prose that explicates it better to the global wikipedia reader; especially so for the first use of the term|date=March 2021}} which itself is also being updated dynamically.<ref>{{cite web |title=Vanilla GAN (GANs in computer vision: Introduction to generative learning) |url=https://theaisummer.com/gan-computer-vision/#vanilla-gan-generative-adversarial-networks-2014 |website=theaisummer.com |date=April 10, 2020 |publisher=AI Summer |access-date=20 September 2020 |url-status=live |archive-url=https://web.archive.org/web/20200603130655/https://theaisummer.com/gan-computer-vision/ |archive-date=2020-06-03}}</ref> This basically means that the generator is not trained to minimize the distance to a specific image, but rather to fool the discriminator. This enables the model to learn in an unsupervised manner.

==Method==
The [[generative model|''generative'' network]] generates candidates while the [[discriminative model|''discriminative'' network]] evaluates them.<ref name="GANnips"/> The contest operates in terms of data distributions. Typically, the generative network learns to map from a [[latent space]] to a data distribution of interest, while the discriminative network distinguishes candidates produced by the generator from the true data distribution. The generative network's training objective is to increase the error rate of the discriminative network (i.e., "fool" the discriminator network by producing novel candidates that the discriminator thinks are not synthesized (are part of the true data distribution)).<ref name="GANnips"/><ref>{{cite journal|last1=Luc|first1=Pauline|last2=Couprie|first2=Camille|last3=Chintala|first3=Soumith|last4=Verbeek|first4=Jakob|date=2016-11-25|title=Semantic Segmentation using Adversarial Networks|journal=NIPS Workshop on Adversarial Training, Dec, Barcelona, Spain|volume=2016|arxiv=1611.08408|bibcode=2016arXiv161108408L}}</ref>

A known dataset serves as the initial training data for the discriminator. Training it involves presenting it with samples from the training dataset, until it achieves acceptable accuracy. The generator trains based on whether it succeeds in fooling the discriminator. Typically the generator is seeded with randomized input that is sampled from a predefined [[latent space]] (e.g. a [[multivariate normal distribution]]). Thereafter, candidates synthesized by the generator are evaluated by the discriminator. Independent [[backpropagation]] procedures are applied to both networks so that the generator produces better samples, while the discriminator becomes more skilled at flagging synthetic samples.<ref name="OpenAI_com">{{citation |url=https://openai.com/blog/generative-models/ |title=Generative Models |publisher=[[OpenAI]] |author1=Andrej Karpathy |author-link1=Andrej Karpathy |author2=Pieter Abbeel|author-link2=Pieter Abbeel |author3=Greg Brockman |author4=Peter Chen |author5=Vicki Cheung |author6=Rocky Duan |author7=Ian Goodfellow |author8=Durk Kingma |author9=Jonathan Ho |author10=Rein Houthooft |author11=Tim Salimans |author12=John Schulman |author13=Ilya Sutskever |author14=Wojciech Zaremba|access-date= April 7, 2016}}</ref> When used for image generation, the generator is typically a deconvolutional neural network, and the discriminator is a [[convolutional neural network]].

GANs often suffer from a "mode collapse" where they fail to generalize properly, missing entire modes from the input data. For example, a GAN trained on the [[MNIST]] dataset containing many samples of each digit, might nevertheless timidly omit a subset of the digits from its output. Some researchers perceive the root problem to be a weak discriminative network that fails to notice the pattern of omission, while others assign blame to a bad choice of [[objective function]]. Many solutions have been proposed.<ref>{{cite journal |last1=Lin |first1=Zinan |last2=Khetan |first2=Ashish |last3=Fanti |first3=Giulia |last4=Oh |first4=Sewoong |display-authors=1 |title=PacGAN: the power of two samples in generative adversarial networks |series=<!---->|url=https://dl.acm.org/doi/10.5555/3326943.3327081 |publisher=NIPS'18: Proceedings of the 32nd International Conference on Neural Information Processing Systems |pages=1505–1514 |date=December 2018|arxiv=1712.04086 }} {{open access}} (also available {{arxiv|1712.04086}} {{open access}})</ref>
Convergence of GANs is an open problem.<ref>{{cite arxiv|last1=Mescheder|first1=Lars|last2=Geiger|first2=Andreas|last3=Nowozin|first3=Sebastian|date=2018-07-31|title=Which Training Methods for GANs do actually Converge?|class=cs.LG|eprint=1801.04406}}</ref>

GANs are '''implicit generative models''',<ref>{{cite arXiv | eprint=1610.03483| last1=Mohamed| first1=Shakir| last2=Lakshminarayanan| first2=Balaji| title=Learning in Implicit Generative Models| year=2016| class=stat.ML}}</ref> which means that they do not explicitly model the likelihood function nor provide means for finding the latent variable corresponding to a given sample, unlike alternatives such as [[Flow-based generative model]].

==Applications==
GAN applications have increased rapidly.<ref>{{Citation|last=Caesar|first=Holger|title=A list of papers on Generative Adversarial (Neural) Networks: nightrome/really-awesome-gan|date=2019-03-01|url=https://github.com/nightrome/really-awesome-gan|access-date=2019-03-02}}</ref>

===Fashion, art and advertising===
GANs can be used to generate art; ''[[The Verge]]'' wrote in March 2019 that "The images created by GANs have become the defining look of contemporary AI art."<ref>{{cite news |last1=Vincent |first1=James |title=A never-ending stream of AI art goes up for auction |url=https://www.theverge.com/2019/3/5/18251267/ai-art-gans-mario-klingemann-auction-sothebys-technology |access-date=13 June 2020 |work=The Verge |date=5 March 2019 |language=en}}</ref> GANs can also be used to [[inpainting|inpaint]] photographs<ref>Yu, Jiahui, et al. "[http://openaccess.thecvf.com/content_cvpr_2018/papers/Yu_Generative_Image_Inpainting_CVPR_2018_paper.pdf Generative image inpainting with contextual attention]." Proceedings of the IEEE conference on computer vision and pattern recognition. 2018.</ref> or create photos of imaginary fashion models, with no need to hire a model, photographer or makeup artist, or pay for a studio and transportation.<ref>{{cite web |last1=Wong |first1=Ceecee |title=The Rise of AI Supermodels |url=https://www.cdotrends.com/story/14300/rise-ai-supermodels |website=CDO Trends}}</ref>

===Science===
GANs can [[image restoration|improve]] [[astrophotography|astronomical images]]<ref>{{cite journal|last1=Schawinski|first1=Kevin|last2=Zhang|first2=Ce|last3=Zhang|first3=Hantian|last4=Fowler|first4=Lucas|last5=Santhanam|first5=Gokula Krishnan|s2cid=7213940|date=2017-02-01|title=Generative Adversarial Networks recover features in astrophysical images of galaxies beyond the deconvolution limit|journal=Monthly Notices of the Royal Astronomical Society: Letters|volume=467|issue=1|pages=L110–L114|arxiv=1702.00403|doi=10.1093/mnrasl/slx008|bibcode=2017MNRAS.467L.110S}}</ref> and simulate [[Gravitational lens|gravitational lensing]] for dark matter research.<ref>{{cite news |last1=Kincade |first1=Kathy |title=Researchers Train a Neural Network to Study Dark Matter |url=https://www.rdmag.com/news/2019/05/researchers-train-neural-network-study-dark-matter |publisher=R&D Magazine}}</ref><ref>{{cite news |last1=Kincade |first1=Kathy |title=CosmoGAN: Training a neural network to study dark matter |url=https://phys.org/news/2019-05-cosmogan-neural-network-dark.html |work=Phys.org |date=May 16, 2019}}</ref><ref>{{cite web |title=Training a neural network to study dark matter |url=https://www.sciencedaily.com/releases/2019/05/190516145206.htm |website=Science Daily |date=May 16, 2019}}</ref> They were used in 2019 to successfully model the distribution of [[dark matter]] in a particular direction in space and to predict the gravitational lensing that will occur.<ref>{{Cite web|url=https://www.theregister.co.uk/2019/05/20/neural_networks_dark_matter/|title=Cosmoboffins use neural networks to build dark matter maps the easy way|last=at 06:13|first=Katyanna Quach 20 May 2019|website=www.theregister.co.uk|language=en|access-date=2019-05-20}}</ref><ref>{{Cite journal|last1=Mustafa|first1=Mustafa|last2=Bard|first2=Deborah|last3=Bhimji|first3=Wahid|last4=Lukić|first4=Zarija|last5=Al-Rfou|first5=Rami|last6=Kratochvil|first6=Jan M.|s2cid=126034204|date=2019-05-06|title=CosmoGAN: creating high-fidelity weak lensing convergence maps using Generative Adversarial Networks|journal=Computational Astrophysics and Cosmology|volume=6|issue=1|pages=1|doi=10.1186/s40668-019-0029-9|issn=2197-7909|bibcode=2019ComAC...6....1M|arxiv=1706.02390}}</ref>

GANs have been proposed as a fast and accurate way of modeling high energy jet formation<ref>{{cite journal|first1=Michela|last1=Paganini|first2=Luke|last2=de Oliveira|first3=Benjamin|last3=Nachman|s2cid=88514467|title=Learning Particle Physics by Example: Location-Aware Generative Adversarial Networks for Physics Synthesis|journal=Computing and Software for Big Science|doi= 	  10.1007/s41781-017-0004-6|year=2017|volume=1|page=4|arxiv=1701.05927|bibcode=2017arXiv170105927D}}</ref> and modeling [[Particle shower|showers]] through [[Calorimeter (particle physics)|calorimeters]] of [[particle physics|high-energy physics]] experiments.<ref>{{cite journal|first1=Michela|last1=Paganini|first2=Luke|last2=de Oliveira|first3=Benjamin|last3=Nachman|s2cid=3330974|title=Accelerating Science with Generative Adversarial Networks: An Application to 3D Particle Showers in Multi-Layer Calorimeters|journal= Physical Review Letters|doi= 	10.1103/PhysRevLett.120.042003|pmid=29437460|year=2018|volume=120|issue=4|page=042003|arxiv=1705.02355|bibcode=2018PhRvL.120d2003P}}</ref><ref>{{cite journal|first1=Michela|last1=Paganini|first2=Luke|last2=de Oliveira|first3=Benjamin|last3=Nachman|s2cid=41265836|title=CaloGAN: Simulating 3D High Energy Particle Showers in Multi-Layer Electromagnetic Calorimeters with Generative Adversarial Networks|journal=Phys. Rev. D|doi=10.1103/PhysRevD.97.014021|year=2018|volume=97|issue=1|page=014021|arxiv=1712.10321|bibcode=2018PhRvD..97a4021P}}</ref><ref>{{cite journal|first1=Martin|last1=Erdmann|first2=Jonas|last2=Glombitza|first3=Thorben|last3=Quast|s2cid=54216502|title=Precise Simulation of Electromagnetic Calorimeter Showers Using a Wasserstein Generative Adversarial Network|journal=Computing and Software for Big Science|doi=10.1007/s41781-018-0019-7|year=2019|volume=3|page=4|arxiv=1807.01954}}</ref><ref>{{cite journal|title=Fast and Accurate Simulation of Particle Detectors Using Generative Adversarial Networks|first1=Pasquale|last1=Musella|first2=Francesco|last2=Pandolfi|s2cid=119474793|year=2018|journal=Computing and Software for Big Science|doi=10.1007/s41781-018-0015-y|volume=2|page=8|arxiv=1805.00850|bibcode=2018arXiv180500850M}}</ref> GANs have also been trained to accurately approximate bottlenecks in computationally expensive simulations of particle physics experiments. Applications in the context of present and proposed [[CERN]] experiments have demonstrated the potential of these methods for accelerating simulation and/or improving simulation fidelity.<ref>{{cite web|title=Deep generative models for fast shower simulation in ATLAS|first=Collaboration|last=ATLAS|year=2018|url=https://atlas.web.cern.ch/Atlas/GROUPS/PHYSICS/PUBNOTES/ATL-SOFT-PUB-2018-001/}}</ref><ref>{{cite journal|title=Fast simulation of muons produced at the SHiP experiment using Generative Adversarial Networks|journal=Journal of Instrumentation|volume=14|issue=11|pages=P11028|first=Collaboration|last=SHiP|s2cid=202542604|year=2019|arxiv=1909.04451|doi=10.1088/1748-0221/14/11/P11028|bibcode=2019JInst..14P1028A}}</ref>

===Video games===
In 2018, GANs reached the [[mod (video gaming)|video game modding]] community, as a method of [[image scaling|up-scaling]] low-resolution 2D textures in old video games by recreating them in [[4K resolution|4k]] or higher resolutions via image training, and then down-sampling them to fit the game's native resolution (with results resembling the [[supersampling]] method of [[spatial anti-aliasing|anti-aliasing]]).<ref>{{cite news|last1=Tang|first1=Xiaoou|last2=Qiao|first2=Yu|last3=Loy|first3=Chen Change|last4=Dong|first4=Chao|last5=Liu|first5=Yihao|last6=Gu|first6=Jinjin|last7=Wu|first7=Shixiang|last8=Yu|first8=Ke|last9=Wang|first9=Xintao|date=2018-09-01|title=ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks|language=en|arxiv=1809.00219|bibcode=2018arXiv180900219W}}</ref> With proper training, GANs provide a clearer and sharper 2D texture image magnitudes higher in quality than the original, while fully retaining the original's level of details, colors, etc. Known examples of extensive GAN usage include ''[[Final Fantasy VIII]]'', ''[[Final Fantasy IX]]'', ''[[Resident Evil (2002 video game)|Resident Evil REmake]]'' HD Remaster, and ''[[Max Payne]]''.{{Citation needed|date=January 2020}}

===Concerns about malicious applications===
{{Main|Deepfake}}
[[File:Woman 1.jpg|thumb|An image generated by a [[StyleGAN]] that looks deceptively like a photograph of a real person. This image was generated by a StyleGAN based on an analysis of portraits.]]
[[image:GAN deepfake white girl.jpg|thumb|Another GAN deepfake deep learning example]]
Concerns have been raised about the potential use of GAN-based [[human image synthesis]] for sinister purposes, e.g., to produce fake, possibly incriminating, photographs and videos.<ref name=TPDNEwuaitcryhf|>{{cite web|url=https://tech.slashdot.org/story/19/02/14/199200/this-person-does-not-exist-website-uses-ai-to-create-realistic-yet-horrifying-faces|title='This Person Does Not Exist' Website Uses AI To Create Realistic Yet Horrifying Faces|author=msmash|date=2019-02-14|website=Slashdot|access-date=2019-02-16}}</ref>
GANs can be used to generate unique, realistic profile photos of people who do not exist, in order to automate creation of fake social media profiles.<ref>{{cite news |last1=Doyle |first1=Michael |title=John Beasley lives on Saddlehorse Drive in Evansville. Or does he? |url=https://www.courierpress.com/story/news/crime/2019/05/16/john-beasley-lives-saddlehorse-drive-evansville-does-he/3700111002/ |publisher=Courier and Press |date=May 16, 2019}}</ref>

In 2019 the state of California considered<ref>{{cite news |last1=Targett |first1=Ed |title=California moves closer to making deepfake pornography illegal |publisher=Computer Business Review |date=May 16, 2019}}</ref> and passed on October 3, 2019, the [https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201920200AB602 bill AB-602], which bans the use of human image synthesis technologies to make fake pornography without the consent of the people depicted, and [https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201920200AB730 bill AB-730], which prohibits distribution of manipulated videos of a political candidate within 60 days of an election. Both bills were authored by Assembly member [[Marc Berman]] and signed by Governor [[Gavin Newsom]]. The laws went into effect in 2020.<ref name="CNET2019">

{{cite web
 | last = Mihalcik
 | first = Carrie
 | title = California laws seek to crack down on deepfakes in politics and porn
 | website = [[cnet.com]]
 | publisher = [[CNET]]
 | date = 2019-10-04
 | url = https://www.cnet.com/news/california-laws-seek-to-crack-down-on-deepfakes-in-politics-and-porn/
 | access-date = 2019-10-13 }}

</ref>

DARPA's Media Forensics program studies ways to counteract fake media, including fake media produced using GANs.<ref>{{cite magazine |last1=Knight |first1=Will |title=The Defense Department has produced the first tools for catching deepfakes |url=https://www.technologyreview.com/s/611726/the-defense-department-has-produced-the-first-tools-for-catching-deepfakes/ |magazine=MIT Technology Review |date=Aug 7, 2018}}</ref>

===Transfer learning===
State-of-art [[transfer learning]] research use GANs to enforce the alignment of the latent feature space, such as in deep reinforcement learning.<ref>{{cite arxiv|last1=Li|first1=Bonnie|last2=François-Lavet|first2=Vincent|last3=Doan|first3=Thang|last4=Pineau|first4=Joelle|date=2021-02-14|title=Domain Adversarial Reinforcement Learning|class=cs.LG|eprint=2102.07097}}</ref> This works by feeding the embeddings of the source and target task to the discriminator which tries to guess the context. The resulting loss is then (inversely) backpropagated through the encoder.

===Miscellaneous applications===
GAN can be used to detect glaucomatous images helping the early diagnosis which is essential to avoid partial or total loss
of vision.<ref>{{cite journal |last1=Bisneto |first1=Tomaz Ribeiro Viana |last2=de Carvalho Filho |first2=Antonio Oseas |last3=Magalhães |first3=Deborah Maria Vieira |title=Generative adversarial network and texture features applied to automatic glaucoma detection |journal=Applied Soft Computing |volume=90 |date=February 2020 |pages=106165 |doi=10.1016/j.asoc.2020.106165}}</ref>

GANs that produce [[photorealistic rendering|photorealistic]] images can be used to visualize [[interior design]], [[industrial design]], shoes,<ref>{{Cite web|url=https://towardsdatascience.com/generating-shoe-designs-with-deep-learning-5dde432a23b8|title=Generating Shoe Designs with Machine Learning|last=Wei|first=Jerry|date=2019-07-03|website=Medium|language=en|access-date=2019-11-06}}</ref> bags, and [[clothing]] items or items for [[PC game|computer games]]' scenes.{{Citation needed|reason=No source provided. How does a GAN do this?|date=February 2018}} Such networks were reported to be used by [[Facebook]].<ref>{{cite web|last1=Greenemeier|first1=Larry|title=When Will Computers Have Common Sense? Ask Facebook|url=https://www.scientificamerican.com/article/when-will-computers-have-common-sense-ask-facebook/|website=Scientific American|access-date=July 31, 2016|date=June 20, 2016}}</ref>

GANs can [[3D reconstruction from multiple images|reconstruct 3D models of objects from images]],<ref>{{cite web|url=http://3dgan.csail.mit.edu/|title=3D Generative Adversarial Network|website=3dgan.csail.mit.edu}}</ref> generate novel objects as 3D point clouds,<ref>{{cite arxiv|eprint=1707.02392|last1=Achlioptas|first1=Panos|last2=Diamanti|first2=Olga|last3=Mitliagkas|first3=Ioannis|last4=Guibas|first4=Leonidas|title=Learning Representations and Generative Models for 3D Point Clouds|year=2018|class=cs.CV}}</ref> and model patterns of motion in video.<ref>{{cite web|url=https://www.cs.columbia.edu/~vondrick/tinyvideo/|title=Generating Videos with Scene Dynamics |website=carlvondrick.com|bibcode=2016arXiv160902612V |last1=Vondrick |first1=Carl |last2=Pirsiavash |first2=Hamed |last3=Torralba |first3=Antonio |year=2016 |arxiv=1609.02612}}</ref>

GANs can be used to age face photographs to show how an individual's appearance might change with age.<ref>{{cite arXiv|last1=Antipov|first1=Grigory|last2=Baccouche|first2=Moez|last3=Dugelay|first3=Jean-Luc|title=Face Aging With Conditional Generative Adversarial Networks|eprint=1702.01983|class=cs.CV|year=2017}}</ref>

GANs can denoise welding images by removing the random light reflection on the dynamic weld pool surface.<ref>{{Cite journal|last=Feng|first=Yunhe|last2=Chen|first2=Zongyao|last3=Wang|first3=Dali|last4=Chen|first4=Jian|last5=Feng|first5=Zhili|date=January 2020|title=DeepWelding: A Deep Learning Enhanced Approach to GTAW Using Multisource Sensing Images|url=https://ieeexplore.ieee.org/document/8815879/|journal=IEEE Transactions on Industrial Informatics|volume=16|issue=1|pages=465–474|doi=10.1109/TII.2019.2937563|issn=1551-3203}}</ref>

GANs can also be used to transfer map styles in cartography<ref>{{cite journal|last1=Kang|first1=Yuhao|last2=Gao|first2=Song|last3=Roth|first3=Rob|s2cid=146808465|title=Transferring Multiscale Map Styles Using Generative Adversarial Networks|url=https://geods.geography.wisc.edu/archives/1192|journal=International Journal of Cartography|volume=5|issue=2–3|pages=115–141|year=2019|doi=10.1080/23729333.2019.1615729|bibcode=2019arXiv190502200K|arxiv=1905.02200}}</ref> or augment street view imagery.<ref>{{cite journal|last1=Wijnands|first1=Jasper|last2=Nice|first2=Kerry|last3=Thompson|first3=Jason|last4=Zhao|first4=Haifeng|last5=Stevenson|first5=Mark|s2cid=155100183|title=Streetscape augmentation using generative adversarial networks: Insights related to health and wellbeing|journal=Sustainable Cities and Society|volume=49|pages=101602|year=2019|doi=10.1016/j.scs.2019.101602|arxiv=1905.06464|bibcode=2019arXiv190506464W}}</ref>

Relevance feedback on GANs can be used to generate images and replace image search systems.<ref>{{cite journal|last1=Ukkonen|first1=Antti|last2=Joona|first2=Pyry|last3=Ruotsalo|first3=Tuukka|title=Generating Images Instead of Retrieving Them: Relevance Feedback on Generative Adversarial Networks|url=https://doi.org/10.1145/3397271.3401129|journal=Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval|series=<!---->|pages=1329–1338|year=2020|doi=10.1145/3397271.3401129|s2cid=220730163|hdl=10138/328471|isbn=9781450380164|hdl-access=free}}</ref>

A variation of the GANs is used in training a network to generate optimal control inputs to nonlinear [[dynamical system]]s. Where the discriminatory network is known as a critic that checks the optimality of the solution and the generative network is known as an Adaptive network that generates the optimal control. The critic and adaptive network train each other to approximate a nonlinear optimal control.<ref>{{Cite journal|title=A single network adaptive critic (SNAC) architecture for optimal control synthesis for a class of nonlinear systems|journal = Neural Networks|volume = 19|issue = 10|pages = 1648–1660|last1=Padhi|first1=Radhakant|last2=Unnikrishnan|first2=Nishant|doi=10.1016/j.neunet.2006.08.010|pmid = 17045458|year = 2006}}</ref>

GANs have been used to visualize the effect that climate change will have on specific houses.<ref>{{cite magazine |title=AI can show us the ravages of climate change |url=https://www.technologyreview.com/f/613547/ai-can-show-us-the-ravages-of-climate-change/ |magazine=MIT Technology Review |date=May 16, 2019}}</ref>

A GAN model called Speech2Face can reconstruct an image of a person's face after listening to their voice.<ref>{{cite news |last1=Christian |first1=Jon |title=ASTOUNDING AI GUESSES WHAT YOU LOOK LIKE BASED ON YOUR VOICE |url=https://futurism.com/the-byte/ai-guesses-appearance-voice |publisher=Futurism |date=May 28, 2019}}</ref>

In 2016 GANs were used to generate new molecules for a variety of protein targets implicated in cancer, inflammation, and fibrosis. In 2019 GAN-generated molecules were validated experimentally all the way into mice.<ref>{{cite journal |last1=Zhavoronkov |first1=Alex|s2cid=201716327|date=2019|title=Deep learning enables rapid identification of potent DDR1 kinase inhibitors |journal=Nature Biotechnology |volume=37|issue=9|pages=1038–1040|doi=10.1038/s41587-019-0224-x |pmid=31477924}}</ref><ref>{{cite magazine |last1=Gregory |first1=Barber |title=A Molecule Designed By AI Exhibits 'Druglike' Qualities |url=https://www.wired.com/story/molecule-designed-ai-exhibits-druglike-qualities/ |magazine=Wired}}</ref>

Whereas the majority of GAN applications are in image processing, the work has also been done with time-series data. For example, recurrent GANs (R-GANs) have been used to generate energy data for machine learning.<ref>{{Cite journal|author1=Mohammad Navid Fekri |author2=Ananda Mohon Ghosh |author3= Katarina Grolinger |date=2020|title= Generating Energy Data for Machine Learning with Recurrent Generative Adversarial Networks|journal=Energies|volume=13|issue=1|page=130 |doi=10.3390/en13010130 |doi-access=free }}</ref>

==History==
The most direct inspiration for GANs was noise-contrastive estimation,<ref>{{cite journal |last1=Gutmann |first1=Michael |last2=Hyvärinen |first2=Aapo |title=Noise-Contrastive Estimation |journal=International Conference on AI and Statistics |url=http://proceedings.mlr.press/v9/gutmann10a/gutmann10a.pdf}}</ref> which uses the same loss function as GANs and which Goodfellow studied during his PhD in 2010–2014.

Other people had similar ideas but did not develop them similarly. An idea involving adversarial networks was published in a 2010 blog post by Olli Niemitalo.<ref name="olli2010">{{cite web
|title= A method for training artificial neural networks to generate missing data within a variable context
|last1= Niemitalo
|first1= Olli
|date= February 24, 2010
|access-date= February 22, 2019
|newspaper= Internet Archive (Wayback Machine)
|url= http://yehar.com:80/blog/?p=167
|archive-url= https://web.archive.org/web/20120312111546/http://yehar.com/blog/?p=167
|archive-date= March 12, 2012
|url-status= live
}}</ref> This idea was never implemented and did not involve [[stochasticity]] in the generator and thus was not a generative model. It is now known as a conditional GAN or cGAN.<ref name=reddit3>{{cite web | year = 2019
|title = GANs were invented in 2010?
|url = https://www.reddit.com/r/MachineLearning/comments/bnqm0p/d_gans_were_invented_in_2010/
|website = reddit r/MachineLearning | language=en-US|access-date=2019-05-28}}</ref> An idea similar to GANs was used to model animal behavior by Li, Gauci and Gross in 2013.<ref name="Li-etal-GECCO2013">{{cite conference
|title= A Coevolutionary Approach to Learn Animal Behavior Through Controlled Interaction
|last1= Li
|first1= Wei
|last2= Gauci
|first2= Melvin
|last3= Gross
|first3= Roderich
|date= July 6, 2013
|publisher= ACM
|book-title= Proceedings of the 15th Annual Conference on Genetic and Evolutionary Computation (GECCO 2013)
|pages= 223–230
|location= Amsterdam, The Netherlands
|doi= 10.1145/2463372.2465801}}</ref>

[[Adversarial machine learning]] has other uses besides generative modeling and can be applied to models other than neural networks. In control theory, adversarial learning based on neural networks was used in 2006 to train robust controllers in a game theoretic sense, by alternating the iterations between a minimizer policy, the controller, and a maximizer policy, the disturbance.<ref>{{cite journal|title=Neurodynamic Programming and Zero-Sum Games for Constrained Control Systems|last1=Abu-Khalaf|first1=Murad|last2=Lewis|first2=Frank L.|last3=Huang|first3=Jie|s2cid=15680448|journal=IEEE Transactions on Neural Networks|volume=19|issue=7|pages=1243–1252|date=July 1, 2008|doi=10.1109/TNN.2008.2000204}}</ref><ref>{{cite journal|title=Policy Iterations on the Hamilton–Jacobi–Isaacs Equation for ''H''<sub>∞</sub> State Feedback Control With Input Saturation|journal=IEEE Transactions on Automatic Control |last1=Abu-Khalaf|first1=Murad|last2=Lewis|first2=Frank L.|last3=Huang|first3=Jie|s2cid=1338976|date=December 1, 2006|doi=10.1109/TAC.2006.884959}}</ref>

In 2017, a GAN was used for image enhancement focusing on realistic textures rather than pixel-accuracy, producing a higher image quality at high magnification.<ref>{{cite arXiv|last1=Sajjadi|first1=Mehdi S. M. |last2=Schölkopf|first2=Bernhard|last3=Hirsch|first3=Michael|date=2016-12-23|title=EnhanceNet: Single Image Super-Resolution Through Automated Texture Synthesis|eprint=1612.07919|class=cs.CV}}</ref> In 2017, the first faces were generated.<ref>{{cite web|url=https://medium.com/@alagraphy/this-person-does-not-exist-neither-will-anything-if-artificial-intelligence-keeps-learning-1a9fcba728f|title=This Person Does Not Exist: Neither Will Anything Eventually with AI|date=March 20, 2019}}</ref> These were exhibited in February 2018 at the Grand Palais.<ref>{{cite web|url=https://www.issuewire.com/artificial-intelligence-enters-the-history-of-art-1620667772563815|title=ARTificial Intelligence enters the History of Art|date=December 28, 2018}}</ref><ref>{{cite web|url=https://link.medium.com/MYqBrGHIKV|title=Le scandale de l'intelligence ARTificielle|author=Tom Février|date=2019-02-17}}</ref> Faces generated by [[StyleGAN]]<ref>{{cite web|url=https://github.com/NVlabs/stylegan|title=StyleGAN: Official TensorFlow Implementation|date=March 2, 2019|via=GitHub}}</ref> in 2019 drew comparisons with [[deepfake]]s.<ref name=TPDNEitboowo2019>{{cite web|url=https://www.inverse.com/article/53280-this-person-does-not-exist-gans-website=website=Inverse|title=This Person Does Not Exist Is the Best One-Off Website of 2019|last=Paez|first=Danny|date=2019-02-13|access-date=2019-02-16}}</ref><ref name=TPDNE>{{cite web|url=https://boingboing.net/2019/02/15/this-person-does-not-exist.html|title=This Person Does Not Exist|last=BESCHIZZA|first=ROB|date=2019-02-15|website=Boing-Boing|access-date=2019-02-16}}</ref><ref name="Style-based GANs – Generating and Tuning Realistic Artificial Faces">{{cite web|url=https://www.lyrn.ai/2018/12/26/a-style-based-generator-architecture-for-generative-adversarial-networks/|title=Style-based GANs – Generating and Tuning Realistic Artificial Faces|last=Horev|first=Rani|date=2018-12-26|website=Lyrn.AI|access-date=2019-02-16}}</ref>

Beginning in 2017, GAN technology began to make its presence felt in the fine arts arena with the appearance of a newly developed implementation which was said to have crossed the threshold of being able to generate unique and appealing abstract paintings, and thus dubbed a "CAN", for "creative adversarial network".<ref>{{cite arXiv |eprint=1706.07068|title=CAN: Creative Adversarial Networks, Generating "Art" by Learning About Styles and Deviating from Style Norms|first1=Ahmed |last1=Elgammal |first2=Bingchen |last2=Liu |first3=Mohamed |last3=Elhoseiny |first4=Marian |last4=Mazzone |class=cs.AI |year=2017}}</ref> A GAN system was used to create the 2018 painting ''[[Edmond de Belamy]],'' which sold for US$432,500.<ref>{{cite news|url=https://www.nytimes.com/2018/10/25/arts/design/ai-art-sold-christies.html|title=AI Art at Christie's Sells for $432,500|last1=Cohn|first1=Gabe|date=2018-10-25|newspaper=The New York Times}}</ref> An early 2019 article by members of the original CAN team discussed further progress with that system, and gave consideration as well to the overall prospects for an AI-enabled art.<ref>{{cite journal |author1=Mazzone, Marian |author2=Ahmed Elgammal|date=21 February 2019|title=Art, Creativity, and the Potential of Artificial Intelligence|journal=Arts|volume=8|pages=26|doi=10.3390/arts8010026|doi-access=free}}</ref>

In May 2019, researchers at Samsung demonstrated a GAN-based system that produces videos of a person speaking, given only a single photo of that person.<ref>{{cite magazine |last1=Kulp |first1=Patrick |title=Samsung's AI Lab Can Create Fake Video Footage From a Single Headshot |url=https://www.adweek.com/digital/samsungs-ai-lab-can-create-fake-video-footage-from-a-single-headshot/ |magazine=AdWeek |date=May 23, 2019}}</ref>

In August 2019, a large dataset consisting of 12,197 MIDI songs each with paired lyrics and melody alignment was created for neural melody generation from lyrics using conditional GAN-LSTM (refer to sources at GitHub [https://github.com/yy1lab/Lyrics-Conditioned-Neural-Melody-Generation AI Melody Generation from Lyrics]).<ref>{{cite journal |arxiv=1908.05551 |title=Conditional LSTM-GAN for Melody Generation from Lyrics
|first1=Yi|last1=Yu |first2=Simon |last2=Canales |journal=ACM Transactions on Multimedia Computing, Communications, and Applications
|year=2021
|volume=17
|pages=1–20
|doi=10.1145/3424116
|s2cid=199668828
}}</ref>

In May 2020, [[Nvidia]] researchers taught an AI system (termed "GameGAN") to recreate the game of ''[[Pac-Man]]'' simply by watching it being played.<ref>{{cite news|url=https://www.theverge.com/2020/5/22/21266251/nvidia-ai-gamegan-recreate-pac-man-virutal-environment |title=Nvidia's AI recreates Pac-Man from scratch just by watching it being played|date=2020-05-22|newspaper=The Verge}}</ref><ref>{{cite arXiv |eprint=2005.12126|title=Learning to Simulate Dynamic Environments with GameGAN|year=2020|author1=Seung Wook Kim|last2=Zhou|first2=Yuhao|last3=Philion|first3=Jonah|last4=Torralba|first4=Antonio|last5=Fidler|first5=Sanja|class=cs.CV}}</ref>

== Classification ==

=== Bidirectional GAN===
While the standard GAN model learns a mapping from a latent space to the data distribution, inverse models such as Bidirectional GAN (BiGAN)<ref>{{cite arXiv | first1=Jeff|last1=Donahue | first2=Philipp|last2=Krähenbühl | first3=Trevor|last3=Darrell |author-link3=Trevor_Darrell | title=Adversarial Feature Learning| year=2016 |class=cs.LG | eprint=1605.09782}}</ref>
and Adversarial Autoencoders<ref>{{cite arXiv | first1=Alireza|last1=Makhzani | first2=Jonathon|last2=Shlens | first3=Navdeep|last3=Jaitly | first4=Ian|last4=Goodfellow | first5=Brendan|last5=Frey |author-link4=Ian_Goodfellow |author-link5=Brendan_Frey | title=Adversarial Autoencoders| year=2016 |class=cs.LG | eprint=1511.05644}}</ref>
also learn a mapping from data to the latent space. This inverse mapping allows real or generated data examples to be projected back into the latent space, similar to the encoder of a [[variational autoencoder]]. Applications of bidirectional models include [[semi-supervised learning]],<ref>{{cite arXiv | first1=Vincent | last1=Dumoulin | first2=Ishmael | last2=Belghazi | first3=Ben|last3=Poole | first4=Olivier|last4=Mastropietro | first5=Alex|last5=Arjovsky | first6=Aaron|last6=Courville | title=Adversarially Learned Inference | year=2016 | class=stat.ML | eprint=1606.00704}}</ref> [[explainable artificial intelligence|interpretable machine learning]],<ref>{{cite arXiv | author1=Xi Chen | author2=Yan Duan | author3=Rein Houthooft | author4=John Schulman | author5=Ilya Sutskever |author-link5=Ilya_Sutskever | author6=Pieter Abeel |author-link6=Pieter_Abbeel| title=InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets| year=2016 | class=cs.LG | eprint=1606.03657}}</ref> and [[neural machine translation]].<ref>{{Cite web|author1=Zhirui Zhang |author2=Shujie Liu |author3=Mu Li |author4=Ming Zhou |author5=Enhong Chen|date=October 2018|title=Bidirectional Generative Adversarial Networks for Neural Machine Translation |url=https://www.aclweb.org/anthology/K18-1019.pdf|volume=Proceedings of the 22nd Conference on Computational Natural Language Learning|pages=190–199}}</ref>

==References==
{{reflist}}

==External links==
{{Portal|Art}}
* {{cite news|url=https://www.technologyreview.com/s/603216/5-big-predictions-for-artificial-intelligence-in-2017/|title=5 Big Predictions for Artificial Intelligence in 2017|last=Knight|first=Will|newspaper=MIT Technology Review|access-date=2017-01-05}}
* {{cite arxiv|eprint=1812.04948|last1=Karras|first1=Tero|last2=Laine|first2=Samuli|last3=Aila|first3=Timo|title=A Style-Based Generator Architecture for Generative Adversarial Networks|year=2018|class=cs.NE}}
* [https://www.thispersondoesnotexist.com/ This Person Does Not Exist]{{snd}} photorealistic images of people who do not exist, generated by [[StyleGAN]]
* [https://thiscatdoesnotexist.com/ This Cat Does Not Exist]{{snd}} photorealistic images of cats who do not exist, generated by [[StyleGAN]]
* {{cite arxiv|eprint=1906.01529|last1=Wang|first1=Zhengwei|last2=She|first2=Qi|last3=Ward|first3=Tomas E.|title=Generative Adversarial Networks in Computer Vision: A Survey and Taxonomy|year=2019|class=cs.LG}}

{{Differentiable computing}}

[[Category:Artificial neural networks]]
[[Category:Cognitive science]]
[[Category:Unsupervised learning]]