{{cleanup|date=March 2017|reason=Article needs linked into other articles in WP.}}

'''Instance selection''' (or dataset reduction, or dataset condensation) is an important [[data pre-processing]] step that can be applied in many [[machine learning]] (or [[data mining]]) tasks.<ref name=GARCIA_2015>S. García, J. Luengo, and F. Herrera, Data preprocessing in data mining. Springer, 2015.</ref> Approaches for instance selection can be applied for reducing the original dataset to a manageable volume, leading to a reduction of the computational resources that are necessary for performing the learning process. Algorithms of instance selection can also be applied for removing noisy instances, before applying learning algorithms. This step can improve the accuracy in classification problems.

Algorithm for instance selection should identify a subset of the total available data to achieve the original purpose of the data mining (or machine learning) application as if the whole data had been used. Considering this, the optimal outcome of IS would be the minimum data subset that can accomplish the same task with no performance loss, in comparison with the performance achieved when the task is performed using the whole available data. Therefore, every instance selection strategy should deal with a trade-off between the reduction rate of the dataset and the classification quality.

== Instance selection algorithms ==

The literature provides several different algorithms for instance selection. They can be distinguished from each other according to several different criteria. Considering this, instance selection algorithms can be grouped in two main classes, according to what instances they select: algorithms that preserve the instances at the boundaries of classes and algorithms that preserve the internal instances of the classes. Within the category of algorithms that select instances at the boundaries it is possible to cite DROP3,<ref name=DROP_2000>D. R. Wilson and T. R. Martinez, Reduction techniques for instance-based learning algorithms, Machine learning, vol. 38, no. 3, pp. 257–286, 2000.</ref> ICF<ref name=ICF_2002>H. Brighton and C. Mellish, Advances in instance selection for instance-based learning algorithms, Data mining and knowledge discovery, vol. 6, no. 2, pp. 153–172, 2002.</ref> and LSBo.<ref name=LSBo_LSSm_2015>E. Leyva, A. González, and R. Pérez, Three new instance selection methods based on local sets: A comparative study with several approaches from a bi-objective perspective, Pattern Recognition, vol. 48, no. 4, pp. 1523–1537, 2015.</ref> On the other hand, within the category of algorithms that select internal instances, it is possible to mention ENN<ref name=ENN_1972>D. L. Wilson, “Asymptotic properties of nearest neighbor rules using edited data,” Systems, Man and Cybernetics, IEEE Transactions on, no. 3, pp. 408–421, 1972.</ref> and LSSm.<ref name=LSBo_LSSm_2015 /> In general, algorithm such as ENN and LSSm are used for removing harmful (noisy) instances from the dataset. They do not reduce the data as the algorithms that select border instances, but they remove instances at the boundaries that have a negative impact on the data mining task. They can be used by other instance selection algorithms, as a filtering step. For example, the ENN algorithm is used by DROP3 as the first step, and the LSSm algorithm is used by LSBo.

There is also another group of algorithms that adopt different selection criteria. For example, the algorithms LDIS,<ref name=LDIS_2015>Carbonera, Joel Luis, and Mara Abel. A density-based approach for instance selection. IEEE 27th International Conference on Tools with Artificial Intelligence (ICTAI), 2015.</ref> CDIS<ref name=CDIS_2016>Carbonera, Joel Luis, and Mara Abel. A novel density-based approach for instance selection. IEEE 28th International Conference on Tools with Artificial Intelligence (ICTAI), 2016.</ref> and XLDIS<ref>{{Citation|last=Carbonera|first=Joel Luís|chapter=An Efficient Approach for Instance Selection|date=2017|pages=228–243|publisher=Springer International Publishing|isbn=9783319642826|doi=10.1007/978-3-319-64283-3_17|title=Big Data Analytics and Knowledge Discovery|volume=10440|series=Lecture Notes in Computer Science}}</ref> select the densest instances in a given arbitrary neighborhood. The selected instances can include both, border and internal instances. The LDIS and CDIS algorithms are very simple and select subsets that are very representative of the original dataset. Besides that, since they search by the representative instances in each class separately, they are faster (in terms of time complexity and effective running time) than other algorithms, such as DROP3 and ICF.

Besides that, there is a third category of algorithms that, instead of selecting actual instances of the dataset, select prototypes (that can be synthetic instances). In this category it is possible to include PSSA,<ref>{{Citation|last=Carbonera|first=Joel Luís|title=An Efficient Prototype Selection Algorithm Based on Spatial Abstraction|date=2018|work=Big Data Analytics and Knowledge Discovery|pages=177–192|publisher=Springer International Publishing|isbn=9783319985381|last2=Abel|first2=Mara|doi=10.1007/978-3-319-98539-8_14}}</ref> PSDSP<ref>{{Citation|last=Carbonera|first=Joel Luís|title=An Efficient Prototype Selection Algorithm Based on Dense Spatial Partitions|date=2018|work=Artificial Intelligence and Soft Computing|pages=288–300|publisher=Springer International Publishing|isbn=9783319912615|last2=Abel|first2=Mara|doi=10.1007/978-3-319-91262-2_26}}</ref> and PSSP.<ref name="Carbonera">{{Cite book|last=Carbonera|first=Joel Luis|last2=Abel|first2=Mara|date=November 2017|title=Efficient Prototype Selection Supported by Subspace Partitions|journal=2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI)|publisher=IEEE|doi=10.1109/ictai.2017.00142|isbn=9781538638767}}</ref> The three algorithms adopt the notion of spatial partition (a hyperrectangle) for identifying similar instances and extract prototypes for each set of similar instances. In general, these approaches can also be modified for selecting actual instances of the datasets. The algorithm ISDSP<ref name="Carbonera"/> adopts a similar approach for selecting actual instances (instead of prototypes).

==References==
{{reflist}}

[[Category:Machine learning]]
[[Category:Data mining]]